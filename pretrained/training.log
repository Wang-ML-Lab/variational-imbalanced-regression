2023-05-20 17:15:50,626 | Args: Namespace(augment=True, batch_size=64, best_loss=100000.0, bucket_num=100, bucket_start=3, data_dir='./data/', dataset='agedb', epoch=90, evaluate=False, fds=True, fds_kernel='gaussian', fds_ks=5, fds_mmt=0.9, fds_sigma=2, gpu=6, img_size=224, lambda_recons=0.7, lambda_reg=0.01, lds=True, lds_kernel='gaussian', lds_ks=5, lds_sigma=2, loss='l1', lr=0.001, model='resnet50', momentum=0.9, optimizer='adam', pretrained='', print_freq=10, resume='', retrain_fc=False, reweight='sqrt_inv', schedule=[60, 80], seeds=1223, start_epoch=0, start_smooth=1, start_update=0, store_name='0.01_1223_0.7_agedb_resnet50_lds_gau_5_2_prm_gau_5_2_0_1_0.9_adam_l1_0.001_64_cdm_recons', store_root='/data/local/ziyan/checkpoint', use_cdm=True, use_edl=True, use_prm=True, use_recons=True, weight_decay=0.0001, workers=32)
2023-05-20 17:15:50,626 | Store name: 0.01_1223_0.7_agedb_resnet50_lds_gau_5_2_prm_gau_5_2_0_1_0.9_adam_l1_0.001_64_cdm_recons
2023-05-20 17:15:50,896 | =====> Preparing data...
2023-05-20 17:15:50,897 | File (.csv): agedb.csv
2023-05-20 17:15:50,928 | Using re-weighting: [SQRT_INV]
2023-05-20 17:15:50,928 | Using LDS: [GAUSSIAN] (5/2)
2023-05-20 17:15:50,946 | Training data size: 12208
2023-05-20 17:15:50,946 | Validation data size: 2140
2023-05-20 17:15:50,946 | Test data size: 2140
2023-05-20 17:15:50,947 | =====> Building model...
2023-05-20 17:15:56,268 | use PRM
2023-05-20 17:15:56,268 | Using FDS: [GAUSSIAN] (5/2)
2023-05-20 17:15:56,607 | this_lr: 
2023-05-20 17:15:56,607 | 0.001
2023-05-20 17:16:06,411 | Epoch: [0][  0/191]	Time   9.80 (  9.80)	Data 2.0436 (2.0436)	Loss (EDL) 35.080 (35.080)
2023-05-20 17:16:10,939 | Epoch: [0][ 10/191]	Time   0.45 (  1.30)	Data 0.0001 (0.1859)	Loss (EDL) 10.245 (20.948)
2023-05-20 17:16:15,531 | Epoch: [0][ 20/191]	Time   0.46 (  0.90)	Data 0.0001 (0.0975)	Loss (EDL) 6.265 (14.378)
2023-05-20 17:16:20,127 | Epoch: [0][ 30/191]	Time   0.46 (  0.76)	Data 0.0001 (0.0661)	Loss (EDL) 5.549 (11.607)
2023-05-20 17:16:24,726 | Epoch: [0][ 40/191]	Time   0.45 (  0.69)	Data 0.0002 (0.0500)	Loss (EDL) 5.664 (10.192)
2023-05-20 17:16:29,390 | Epoch: [0][ 50/191]	Time   0.46 (  0.64)	Data 0.0001 (0.0402)	Loss (EDL) 5.285 (9.269)
2023-05-20 17:16:34,064 | Epoch: [0][ 60/191]	Time   0.47 (  0.61)	Data 0.0001 (0.0337)	Loss (EDL) 5.249 (8.675)
2023-05-20 17:16:38,740 | Epoch: [0][ 70/191]	Time   0.47 (  0.59)	Data 0.0002 (0.0290)	Loss (EDL) 6.742 (8.234)
2023-05-20 17:16:43,391 | Epoch: [0][ 80/191]	Time   0.46 (  0.58)	Data 0.0002 (0.0254)	Loss (EDL) 5.299 (7.881)
2023-05-20 17:16:48,057 | Epoch: [0][ 90/191]	Time   0.47 (  0.57)	Data 0.0002 (0.0226)	Loss (EDL) 6.619 (7.613)
2023-05-20 17:16:52,670 | Epoch: [0][100/191]	Time   0.47 (  0.56)	Data 0.0002 (0.0204)	Loss (EDL) 4.670 (7.379)
2023-05-20 17:16:57,281 | Epoch: [0][110/191]	Time   0.46 (  0.55)	Data 0.0001 (0.0186)	Loss (EDL) 5.174 (7.191)
2023-05-20 17:17:01,908 | Epoch: [0][120/191]	Time   0.47 (  0.54)	Data 0.0002 (0.0171)	Loss (EDL) 4.962 (7.012)
2023-05-20 17:17:06,501 | Epoch: [0][130/191]	Time   0.45 (  0.53)	Data 0.0001 (0.0158)	Loss (EDL) 5.100 (6.863)
2023-05-20 17:17:11,034 | Epoch: [0][140/191]	Time   0.45 (  0.53)	Data 0.0001 (0.0147)	Loss (EDL) 5.075 (6.752)
2023-05-20 17:17:15,564 | Epoch: [0][150/191]	Time   0.46 (  0.52)	Data 0.0001 (0.0137)	Loss (EDL) 4.951 (6.638)
2023-05-20 17:17:20,103 | Epoch: [0][160/191]	Time   0.45 (  0.52)	Data 0.0001 (0.0129)	Loss (EDL) 5.059 (6.560)
2023-05-20 17:17:24,790 | Epoch: [0][170/191]	Time   0.45 (  0.52)	Data 0.0001 (0.0121)	Loss (EDL) 4.894 (6.468)
2023-05-20 17:17:29,313 | Epoch: [0][180/191]	Time   0.46 (  0.51)	Data 0.0001 (0.0115)	Loss (EDL) 4.763 (6.389)
2023-05-20 17:17:33,776 | Epoch: [0][190/191]	Time   0.38 (  0.51)	Data 0.0001 (0.0109)	Loss (EDL) 4.880 (6.325)
2023-05-20 17:17:34,007 | Create Epoch [0] features of all training data...
2023-05-20 17:17:59,010 | Updated running statistics with Epoch [0] features!
2023-05-20 17:18:02,603 | Val: [ 0/34]	Time  3.466 ( 3.466)	Loss (L1) 16.109 (16.109)	Loss (EDL) 5.459 (5.459)	Loss (NIG_NLL) 4.591 (4.591)	Loss (NIG_Reg) 86.806 (86.806)
2023-05-20 17:18:03,836 | Val: [10/34]	Time  0.100 ( 0.427)	Loss (L1) 15.911 (15.314)	Loss (EDL) 5.407 (5.330)	Loss (NIG_NLL) 4.552 (4.507)	Loss (NIG_Reg) 85.432 (82.326)
2023-05-20 17:18:04,844 | Val: [20/34]	Time  0.100 ( 0.272)	Loss (L1) 17.103 (15.485)	Loss (EDL) 5.629 (5.362)	Loss (NIG_NLL) 4.710 (4.529)	Loss (NIG_Reg) 91.867 (83.236)
2023-05-20 17:18:05,843 | Val: [30/34]	Time  0.100 ( 0.216)	Loss (L1) 17.311 (15.460)	Loss (EDL) 5.637 (5.356)	Loss (NIG_NLL) 4.707 (4.525)	Loss (NIG_Reg) 93.024 (83.118)
2023-05-20 17:18:06,485 |  * Overall: MSE 352.107	L1 15.391	G-Mean 10.556	EDL 5.345	NIG_NLL 4.518	NIG_Reg 82.740
2023-05-20 17:18:06,485 |  * Many: MSE 209.044	L1 11.836	G-Mean 8.166	EDL 4.805	NIG_NLL 4.168	NIG_Reg 63.662
2023-05-20 17:18:06,485 |  * Median: MSE 595.077	L1 22.262	G-Mean 18.298	EDL 6.417	NIG_NLL 5.220	NIG_Reg 119.645
2023-05-20 17:18:06,485 |  * Low: MSE 1031.347	L1 29.959	G-Mean 26.070	EDL 7.487	NIG_NLL 5.879	NIG_Reg 160.866
2023-05-20 17:18:06,486 | Best EDL Loss: 15.391
2023-05-20 17:18:06,489 | ===> Saving current best checkpoint...
2023-05-20 17:18:12,091 | Epoch #0: Train loss [6.3252]; Val loss: MSE [352.1072], L1 [15.3910], G-Mean [10.5564], EDL [5.3452], NIG_NLL [4.518], NIG_Reg [82.740]
2023-05-20 17:18:12,092 | this_lr: 
2023-05-20 17:18:12,093 | 0.001
2023-05-20 17:18:17,468 | Epoch: [1][  0/191]	Time   5.37 (  5.37)	Data 4.4434 (4.4434)	Loss (EDL) 5.898 (5.898)
2023-05-20 17:18:23,258 | Epoch: [1][ 10/191]	Time   0.59 (  1.01)	Data 0.0003 (0.4043)	Loss (EDL) 4.963 (5.253)
2023-05-20 17:18:28,997 | Epoch: [1][ 20/191]	Time   0.56 (  0.80)	Data 0.0002 (0.2119)	Loss (EDL) 4.913 (5.153)
2023-05-20 17:18:34,667 | Epoch: [1][ 30/191]	Time   0.57 (  0.73)	Data 0.0001 (0.1436)	Loss (EDL) 5.856 (5.164)
2023-05-20 17:18:40,358 | Epoch: [1][ 40/191]	Time   0.56 (  0.69)	Data 0.0001 (0.1086)	Loss (EDL) 5.953 (5.181)
2023-05-20 17:18:45,949 | Epoch: [1][ 50/191]	Time   0.57 (  0.66)	Data 0.0002 (0.0874)	Loss (EDL) 5.008 (5.150)
2023-05-20 17:18:51,792 | Epoch: [1][ 60/191]	Time   0.55 (  0.65)	Data 0.0002 (0.0731)	Loss (EDL) 5.815 (5.145)
2023-05-20 17:18:57,370 | Epoch: [1][ 70/191]	Time   0.55 (  0.64)	Data 0.0006 (0.0629)	Loss (EDL) 5.140 (5.129)
2023-05-20 17:19:02,987 | Epoch: [1][ 80/191]	Time   0.58 (  0.63)	Data 0.0005 (0.0552)	Loss (EDL) 5.200 (5.126)
2023-05-20 17:19:08,664 | Epoch: [1][ 90/191]	Time   0.61 (  0.62)	Data 0.0002 (0.0491)	Loss (EDL) 4.951 (5.123)
2023-05-20 17:19:14,205 | Epoch: [1][100/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0443)	Loss (EDL) 4.762 (5.105)
2023-05-20 17:19:19,839 | Epoch: [1][110/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0403)	Loss (EDL) 4.773 (5.098)
2023-05-20 17:19:25,382 | Epoch: [1][120/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0370)	Loss (EDL) 4.884 (5.081)
2023-05-20 17:19:31,290 | Epoch: [1][130/191]	Time   0.55 (  0.60)	Data 0.0003 (0.0342)	Loss (EDL) 5.091 (5.074)
2023-05-20 17:19:36,709 | Epoch: [1][140/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0318)	Loss (EDL) 5.318 (5.065)
2023-05-20 17:19:42,150 | Epoch: [1][150/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0297)	Loss (EDL) 5.094 (5.055)
2023-05-20 17:19:47,594 | Epoch: [1][160/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0279)	Loss (EDL) 4.559 (5.041)
2023-05-20 17:19:53,058 | Epoch: [1][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0263)	Loss (EDL) 5.392 (5.056)
2023-05-20 17:19:58,563 | Epoch: [1][180/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0248)	Loss (EDL) 4.754 (5.050)
2023-05-20 17:20:04,197 | Epoch: [1][190/191]	Time   0.48 (  0.59)	Data 0.0003 (0.0235)	Loss (EDL) 4.852 (5.048)
2023-05-20 17:20:04,540 | Create Epoch [1] features of all training data...
2023-05-20 17:20:33,929 | Updated smoothed statistics on Epoch [1]!
2023-05-20 17:20:34,001 | Updated running statistics with Epoch [1] features!
2023-05-20 17:20:37,897 | Val: [ 0/34]	Time  3.599 ( 3.599)	Loss (L1) 13.446 (13.446)	Loss (EDL) 5.031 (5.031)	Loss (NIG_NLL) 4.311 (4.311)	Loss (NIG_Reg) 72.037 (72.037)
2023-05-20 17:20:39,019 | Val: [10/34]	Time  0.102 ( 0.429)	Loss (L1) 13.347 (12.891)	Loss (EDL) 5.027 (4.954)	Loss (NIG_NLL) 4.313 (4.264)	Loss (NIG_Reg) 71.410 (68.948)
2023-05-20 17:20:40,021 | Val: [20/34]	Time  0.100 ( 0.273)	Loss (L1) 15.626 (13.394)	Loss (EDL) 5.388 (5.024)	Loss (NIG_NLL) 4.551 (4.308)	Loss (NIG_Reg) 83.669 (71.627)
2023-05-20 17:20:41,024 | Val: [30/34]	Time  0.101 ( 0.217)	Loss (L1) 15.308 (13.495)	Loss (EDL) 5.279 (5.037)	Loss (NIG_NLL) 4.462 (4.315)	Loss (NIG_Reg) 81.752 (72.161)
2023-05-20 17:20:41,654 |  * Overall: MSE 274.255	L1 13.426	G-Mean 9.032	EDL 5.027	NIG_NLL 4.309	NIG_Reg 71.790
2023-05-20 17:20:41,654 |  * Many: MSE 157.010	L1 10.158	G-Mean 6.841	EDL 4.562	NIG_NLL 4.019	NIG_Reg 54.362
2023-05-20 17:20:41,654 |  * Median: MSE 518.691	L1 20.471	G-Mean 16.756	EDL 6.036	NIG_NLL 4.942	NIG_Reg 109.350
2023-05-20 17:20:41,654 |  * Low: MSE 705.596	L1 24.806	G-Mean 22.558	EDL 6.628	NIG_NLL 5.303	NIG_Reg 132.517
2023-05-20 17:20:41,654 | Best EDL Loss: 13.426
2023-05-20 17:20:41,657 | ===> Saving current best checkpoint...
2023-05-20 17:20:48,731 | Epoch #1: Train loss [5.0480]; Val loss: MSE [274.2546], L1 [13.4260], G-Mean [9.0318], EDL [5.0271], NIG_NLL [4.309], NIG_Reg [71.790]
2023-05-20 17:20:48,733 | this_lr: 
2023-05-20 17:20:48,733 | 0.001
2023-05-20 17:20:52,815 | Epoch: [2][  0/191]	Time   4.08 (  4.08)	Data 3.1149 (3.1149)	Loss (EDL) 5.127 (5.127)
2023-05-20 17:20:58,515 | Epoch: [2][ 10/191]	Time   0.58 (  0.89)	Data 0.0001 (0.2834)	Loss (EDL) 4.665 (4.880)
2023-05-20 17:21:04,345 | Epoch: [2][ 20/191]	Time   0.57 (  0.74)	Data 0.0001 (0.1485)	Loss (EDL) 4.912 (4.900)
2023-05-20 17:21:09,923 | Epoch: [2][ 30/191]	Time   0.54 (  0.68)	Data 0.0003 (0.1007)	Loss (EDL) 4.742 (4.888)
2023-05-20 17:21:15,476 | Epoch: [2][ 40/191]	Time   0.56 (  0.65)	Data 0.0002 (0.0762)	Loss (EDL) 5.179 (4.896)
2023-05-20 17:21:21,122 | Epoch: [2][ 50/191]	Time   0.55 (  0.64)	Data 0.0003 (0.0613)	Loss (EDL) 5.004 (4.874)
2023-05-20 17:21:26,707 | Epoch: [2][ 60/191]	Time   0.58 (  0.62)	Data 0.0003 (0.0513)	Loss (EDL) 4.759 (4.867)
2023-05-20 17:21:32,482 | Epoch: [2][ 70/191]	Time   0.61 (  0.62)	Data 0.0004 (0.0441)	Loss (EDL) 4.956 (4.881)
2023-05-20 17:21:38,393 | Epoch: [2][ 80/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0387)	Loss (EDL) 5.146 (4.895)
2023-05-20 17:21:44,061 | Epoch: [2][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0345)	Loss (EDL) 4.955 (4.880)
2023-05-20 17:21:49,778 | Epoch: [2][100/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0311)	Loss (EDL) 5.118 (4.888)
2023-05-20 17:21:55,411 | Epoch: [2][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0283)	Loss (EDL) 4.581 (4.897)
2023-05-20 17:22:01,005 | Epoch: [2][120/191]	Time   0.57 (  0.60)	Data 0.0003 (0.0260)	Loss (EDL) 5.032 (4.892)
2023-05-20 17:22:06,508 | Epoch: [2][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0240)	Loss (EDL) 4.958 (4.899)
2023-05-20 17:22:12,010 | Epoch: [2][140/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0224)	Loss (EDL) 4.691 (4.892)
2023-05-20 17:22:17,480 | Epoch: [2][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0209)	Loss (EDL) 4.825 (4.891)
2023-05-20 17:22:23,156 | Epoch: [2][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0196)	Loss (EDL) 4.714 (4.889)
2023-05-20 17:22:28,614 | Epoch: [2][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0185)	Loss (EDL) 5.426 (4.889)
2023-05-20 17:22:34,081 | Epoch: [2][180/191]	Time   0.55 (  0.58)	Data 0.0002 (0.0175)	Loss (EDL) 4.733 (4.886)
2023-05-20 17:22:39,467 | Epoch: [2][190/191]	Time   0.45 (  0.58)	Data 0.0002 (0.0166)	Loss (EDL) 4.755 (4.884)
2023-05-20 17:22:39,779 | Create Epoch [2] features of all training data...
2023-05-20 17:23:09,281 | Updated smoothed statistics on Epoch [2]!
2023-05-20 17:23:09,378 | Updated running statistics with Epoch [2] features!
2023-05-20 17:23:13,841 | Val: [ 0/34]	Time  3.974 ( 3.974)	Loss (L1) 12.381 (12.381)	Loss (EDL) 4.892 (4.892)	Loss (NIG_NLL) 4.227 (4.227)	Loss (NIG_Reg) 66.485 (66.485)
2023-05-20 17:23:15,213 | Val: [10/34]	Time  0.101 ( 0.486)	Loss (L1) 11.943 (12.265)	Loss (EDL) 4.837 (4.863)	Loss (NIG_NLL) 4.197 (4.206)	Loss (NIG_Reg) 64.014 (65.664)
2023-05-20 17:23:16,222 | Val: [20/34]	Time  0.100 ( 0.303)	Loss (L1) 15.051 (12.490)	Loss (EDL) 5.290 (4.896)	Loss (NIG_NLL) 4.484 (4.228)	Loss (NIG_Reg) 80.640 (66.858)
2023-05-20 17:23:17,233 | Val: [30/34]	Time  0.101 ( 0.238)	Loss (L1) 15.467 (12.471)	Loss (EDL) 5.287 (4.890)	Loss (NIG_NLL) 4.461 (4.223)	Loss (NIG_Reg) 82.591 (66.743)
2023-05-20 17:23:17,909 |  * Overall: MSE 241.714	L1 12.420	G-Mean 8.220	EDL 4.883	NIG_NLL 4.218	NIG_Reg 66.468
2023-05-20 17:23:17,910 |  * Many: MSE 158.482	L1 9.901	G-Mean 6.411	EDL 4.532	NIG_NLL 4.001	NIG_Reg 53.069
2023-05-20 17:23:17,910 |  * Median: MSE 400.298	L1 17.587	G-Mean 14.304	EDL 5.606	NIG_NLL 4.667	NIG_Reg 93.927
2023-05-20 17:23:17,910 |  * Low: MSE 589.250	L1 21.918	G-Mean 18.586	EDL 6.198	NIG_NLL 5.028	NIG_Reg 117.069
2023-05-20 17:23:17,911 | Best EDL Loss: 12.420
2023-05-20 17:23:17,918 | ===> Saving current best checkpoint...
2023-05-20 17:23:25,842 | Epoch #2: Train loss [4.8839]; Val loss: MSE [241.7143], L1 [12.4196], G-Mean [8.2203], EDL [4.8829], NIG_NLL [4.218], NIG_Reg [66.468]
2023-05-20 17:23:25,843 | this_lr: 
2023-05-20 17:23:25,843 | 0.001
2023-05-20 17:23:31,072 | Epoch: [3][  0/191]	Time   5.23 (  5.23)	Data 4.3090 (4.3090)	Loss (EDL) 4.734 (4.734)
2023-05-20 17:23:36,786 | Epoch: [3][ 10/191]	Time   0.59 (  0.99)	Data 0.0002 (0.3919)	Loss (EDL) 5.336 (4.787)
2023-05-20 17:23:42,468 | Epoch: [3][ 20/191]	Time   0.56 (  0.79)	Data 0.0002 (0.2054)	Loss (EDL) 4.881 (4.863)
2023-05-20 17:23:48,232 | Epoch: [3][ 30/191]	Time   0.56 (  0.72)	Data 0.0001 (0.1392)	Loss (EDL) 4.554 (4.917)
2023-05-20 17:23:53,820 | Epoch: [3][ 40/191]	Time   0.57 (  0.68)	Data 0.0002 (0.1053)	Loss (EDL) 4.781 (4.933)
2023-05-20 17:23:59,516 | Epoch: [3][ 50/191]	Time   0.57 (  0.66)	Data 0.0002 (0.0847)	Loss (EDL) 5.176 (4.955)
2023-05-20 17:24:05,634 | Epoch: [3][ 60/191]	Time   0.58 (  0.65)	Data 0.0001 (0.0709)	Loss (EDL) 4.666 (4.931)
2023-05-20 17:24:11,426 | Epoch: [3][ 70/191]	Time   0.56 (  0.64)	Data 0.0002 (0.0610)	Loss (EDL) 4.828 (4.918)
2023-05-20 17:24:17,066 | Epoch: [3][ 80/191]	Time   0.57 (  0.63)	Data 0.0003 (0.0535)	Loss (EDL) 4.961 (4.946)
2023-05-20 17:24:22,721 | Epoch: [3][ 90/191]	Time   0.56 (  0.62)	Data 0.0003 (0.0476)	Loss (EDL) 4.619 (4.941)
2023-05-20 17:24:28,445 | Epoch: [3][100/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0430)	Loss (EDL) 5.253 (4.955)
2023-05-20 17:24:34,152 | Epoch: [3][110/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0391)	Loss (EDL) 4.656 (4.940)
2023-05-20 17:24:39,787 | Epoch: [3][120/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0359)	Loss (EDL) 4.579 (4.945)
2023-05-20 17:24:45,875 | Epoch: [3][130/191]	Time   0.55 (  0.61)	Data 0.0001 (0.0332)	Loss (EDL) 4.650 (4.944)
2023-05-20 17:24:51,397 | Epoch: [3][140/191]	Time   0.56 (  0.61)	Data 0.0003 (0.0308)	Loss (EDL) 5.090 (4.937)
2023-05-20 17:24:56,975 | Epoch: [3][150/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0288)	Loss (EDL) 4.866 (4.926)
2023-05-20 17:25:02,537 | Epoch: [3][160/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0270)	Loss (EDL) 4.517 (4.918)
2023-05-20 17:25:08,225 | Epoch: [3][170/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0255)	Loss (EDL) 5.397 (4.912)
2023-05-20 17:25:13,889 | Epoch: [3][180/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0241)	Loss (EDL) 4.684 (4.912)
2023-05-20 17:25:19,409 | Epoch: [3][190/191]	Time   0.48 (  0.59)	Data 0.0002 (0.0228)	Loss (EDL) 4.690 (4.907)
2023-05-20 17:25:19,736 | Create Epoch [3] features of all training data...
2023-05-20 17:25:50,049 | Updated smoothed statistics on Epoch [3]!
2023-05-20 17:25:50,132 | Updated running statistics with Epoch [3] features!
2023-05-20 17:25:54,161 | Val: [ 0/34]	Time  3.597 ( 3.597)	Loss (L1) 12.793 (12.793)	Loss (EDL) 4.928 (4.928)	Loss (NIG_NLL) 4.244 (4.244)	Loss (NIG_Reg) 68.390 (68.390)
2023-05-20 17:25:55,180 | Val: [10/34]	Time  0.101 ( 0.420)	Loss (L1) 12.522 (12.159)	Loss (EDL) 4.938 (4.851)	Loss (NIG_NLL) 4.269 (4.202)	Loss (NIG_Reg) 66.932 (64.903)
2023-05-20 17:25:56,190 | Val: [20/34]	Time  0.100 ( 0.268)	Loss (L1) 14.370 (12.218)	Loss (EDL) 5.217 (4.867)	Loss (NIG_NLL) 4.449 (4.214)	Loss (NIG_Reg) 76.799 (65.224)
2023-05-20 17:25:57,195 | Val: [30/34]	Time  0.100 ( 0.214)	Loss (L1) 14.298 (12.119)	Loss (EDL) 5.141 (4.852)	Loss (NIG_NLL) 4.380 (4.205)	Loss (NIG_Reg) 76.123 (64.687)
2023-05-20 17:25:57,852 |  * Overall: MSE 227.918	L1 12.052	G-Mean 7.906	EDL 4.842	NIG_NLL 4.198	NIG_Reg 64.331
2023-05-20 17:25:57,852 |  * Many: MSE 149.799	L1 9.712	G-Mean 6.301	EDL 4.505	NIG_NLL 3.987	NIG_Reg 51.880
2023-05-20 17:25:57,852 |  * Median: MSE 367.125	L1 16.468	G-Mean 12.501	EDL 5.489	NIG_NLL 4.611	NIG_Reg 87.813
2023-05-20 17:25:57,852 |  * Low: MSE 580.737	L1 21.937	G-Mean 19.005	EDL 6.228	NIG_NLL 5.058	NIG_Reg 116.985
2023-05-20 17:25:57,852 | Best EDL Loss: 12.052
2023-05-20 17:25:57,856 | ===> Saving current best checkpoint...
2023-05-20 17:26:05,060 | Epoch #3: Train loss [4.9069]; Val loss: MSE [227.9179], L1 [12.0519], G-Mean [7.9064], EDL [4.8418], NIG_NLL [4.198], NIG_Reg [64.331]
2023-05-20 17:26:05,061 | this_lr: 
2023-05-20 17:26:05,061 | 0.001
2023-05-20 17:26:09,028 | Epoch: [4][  0/191]	Time   3.96 (  3.96)	Data 2.8815 (2.8815)	Loss (EDL) 4.862 (4.862)
2023-05-20 17:26:14,595 | Epoch: [4][ 10/191]	Time   0.56 (  0.87)	Data 0.0002 (0.2622)	Loss (EDL) 4.641 (4.763)
2023-05-20 17:26:20,197 | Epoch: [4][ 20/191]	Time   0.56 (  0.72)	Data 0.0001 (0.1374)	Loss (EDL) 4.735 (4.737)
2023-05-20 17:26:26,138 | Epoch: [4][ 30/191]	Time   0.55 (  0.68)	Data 0.0001 (0.0932)	Loss (EDL) 4.725 (4.767)
2023-05-20 17:26:31,658 | Epoch: [4][ 40/191]	Time   0.56 (  0.65)	Data 0.0002 (0.0705)	Loss (EDL) 5.034 (4.787)
2023-05-20 17:26:37,333 | Epoch: [4][ 50/191]	Time   0.56 (  0.63)	Data 0.0001 (0.0567)	Loss (EDL) 4.815 (4.792)
2023-05-20 17:26:42,892 | Epoch: [4][ 60/191]	Time   0.56 (  0.62)	Data 0.0001 (0.0474)	Loss (EDL) 4.524 (4.817)
2023-05-20 17:26:48,505 | Epoch: [4][ 70/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0408)	Loss (EDL) 4.904 (4.816)
2023-05-20 17:26:54,090 | Epoch: [4][ 80/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0358)	Loss (EDL) 4.628 (4.807)
2023-05-20 17:26:59,835 | Epoch: [4][ 90/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0319)	Loss (EDL) 5.010 (4.797)
2023-05-20 17:27:05,462 | Epoch: [4][100/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0287)	Loss (EDL) 4.860 (4.814)
2023-05-20 17:27:11,155 | Epoch: [4][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0262)	Loss (EDL) 4.823 (4.819)
2023-05-20 17:27:16,734 | Epoch: [4][120/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0240)	Loss (EDL) 4.907 (4.832)
2023-05-20 17:27:22,217 | Epoch: [4][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0222)	Loss (EDL) 5.273 (4.840)
2023-05-20 17:27:27,655 | Epoch: [4][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0207)	Loss (EDL) 4.576 (4.841)
2023-05-20 17:27:33,175 | Epoch: [4][150/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0193)	Loss (EDL) 4.947 (4.838)
2023-05-20 17:27:38,688 | Epoch: [4][160/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0181)	Loss (EDL) 5.019 (4.844)
2023-05-20 17:27:44,416 | Epoch: [4][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0171)	Loss (EDL) 4.476 (4.837)
2023-05-20 17:27:49,881 | Epoch: [4][180/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0161)	Loss (EDL) 4.940 (4.839)
2023-05-20 17:27:55,338 | Epoch: [4][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0153)	Loss (EDL) 5.134 (4.834)
2023-05-20 17:27:55,664 | Create Epoch [4] features of all training data...
2023-05-20 17:28:25,705 | Updated smoothed statistics on Epoch [4]!
2023-05-20 17:28:25,805 | Updated running statistics with Epoch [4] features!
2023-05-20 17:28:30,585 | Val: [ 0/34]	Time  4.256 ( 4.256)	Loss (L1) 11.338 (11.338)	Loss (EDL) 4.750 (4.750)	Loss (NIG_NLL) 4.142 (4.142)	Loss (NIG_Reg) 60.796 (60.796)
2023-05-20 17:28:31,724 | Val: [10/34]	Time  0.101 ( 0.490)	Loss (L1) 12.503 (11.057)	Loss (EDL) 4.903 (4.695)	Loss (NIG_NLL) 4.234 (4.104)	Loss (NIG_Reg) 66.944 (59.103)
2023-05-20 17:28:32,752 | Val: [20/34]	Time  0.104 ( 0.306)	Loss (L1) 14.030 (11.468)	Loss (EDL) 5.137 (4.753)	Loss (NIG_NLL) 4.388 (4.140)	Loss (NIG_Reg) 74.866 (61.283)
2023-05-20 17:28:33,772 | Val: [30/34]	Time  0.101 ( 0.240)	Loss (L1) 14.423 (11.496)	Loss (EDL) 5.159 (4.759)	Loss (NIG_NLL) 4.390 (4.145)	Loss (NIG_Reg) 76.869 (61.429)
2023-05-20 17:28:34,469 |  * Overall: MSE 208.173	L1 11.431	G-Mean 7.511	EDL 4.750	NIG_NLL 4.139	NIG_Reg 61.083
2023-05-20 17:28:34,470 |  * Many: MSE 139.440	L1 9.357	G-Mean 6.080	EDL 4.441	NIG_NLL 3.941	NIG_Reg 50.041
2023-05-20 17:28:34,470 |  * Median: MSE 328.326	L1 15.370	G-Mean 11.687	EDL 5.342	NIG_NLL 4.522	NIG_Reg 81.976
2023-05-20 17:28:34,470 |  * Low: MSE 525.045	L1 20.130	G-Mean 16.262	EDL 6.024	NIG_NLL 4.948	NIG_Reg 107.582
2023-05-20 17:28:34,471 | Best EDL Loss: 11.431
2023-05-20 17:28:34,475 | ===> Saving current best checkpoint...
2023-05-20 17:28:42,486 | Epoch #4: Train loss [4.8341]; Val loss: MSE [208.1733], L1 [11.4313], G-Mean [7.5107], EDL [4.7496], NIG_NLL [4.139], NIG_Reg [61.083]
2023-05-20 17:28:42,487 | this_lr: 
2023-05-20 17:28:42,487 | 0.001
2023-05-20 17:28:47,786 | Epoch: [5][  0/191]	Time   5.30 (  5.30)	Data 4.3038 (4.3038)	Loss (EDL) 6.061 (6.061)
2023-05-20 17:28:53,468 | Epoch: [5][ 10/191]	Time   0.55 (  1.00)	Data 0.0002 (0.3915)	Loss (EDL) 4.407 (4.861)
2023-05-20 17:28:59,233 | Epoch: [5][ 20/191]	Time   0.57 (  0.80)	Data 0.0002 (0.2052)	Loss (EDL) 4.871 (4.797)
2023-05-20 17:29:04,897 | Epoch: [5][ 30/191]	Time   0.55 (  0.72)	Data 0.0001 (0.1391)	Loss (EDL) 4.763 (4.756)
2023-05-20 17:29:10,484 | Epoch: [5][ 40/191]	Time   0.58 (  0.68)	Data 0.0001 (0.1053)	Loss (EDL) 4.853 (4.772)
2023-05-20 17:29:16,084 | Epoch: [5][ 50/191]	Time   0.54 (  0.66)	Data 0.0002 (0.0847)	Loss (EDL) 4.873 (4.771)
2023-05-20 17:29:21,965 | Epoch: [5][ 60/191]	Time   0.55 (  0.65)	Data 0.0003 (0.0709)	Loss (EDL) 4.500 (4.766)
2023-05-20 17:29:27,563 | Epoch: [5][ 70/191]	Time   0.57 (  0.63)	Data 0.0003 (0.0609)	Loss (EDL) 5.079 (4.788)
2023-05-20 17:29:33,207 | Epoch: [5][ 80/191]	Time   0.57 (  0.63)	Data 0.0003 (0.0535)	Loss (EDL) 4.741 (4.791)
2023-05-20 17:29:38,772 | Epoch: [5][ 90/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0476)	Loss (EDL) 4.610 (4.779)
2023-05-20 17:29:44,304 | Epoch: [5][100/191]	Time   0.53 (  0.61)	Data 0.0002 (0.0429)	Loss (EDL) 4.620 (4.785)
2023-05-20 17:29:49,843 | Epoch: [5][110/191]	Time   0.55 (  0.61)	Data 0.0004 (0.0391)	Loss (EDL) 4.637 (4.771)
2023-05-20 17:29:55,410 | Epoch: [5][120/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0359)	Loss (EDL) 5.218 (4.780)
2023-05-20 17:30:01,312 | Epoch: [5][130/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0332)	Loss (EDL) 4.362 (4.785)
2023-05-20 17:30:06,862 | Epoch: [5][140/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0308)	Loss (EDL) 4.741 (4.776)
2023-05-20 17:30:12,374 | Epoch: [5][150/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0288)	Loss (EDL) 4.321 (4.771)
2023-05-20 17:30:17,806 | Epoch: [5][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0270)	Loss (EDL) 4.379 (4.765)
2023-05-20 17:30:23,302 | Epoch: [5][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0255)	Loss (EDL) 4.849 (4.765)
2023-05-20 17:30:28,764 | Epoch: [5][180/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0241)	Loss (EDL) 4.801 (4.764)
2023-05-20 17:30:34,234 | Epoch: [5][190/191]	Time   0.48 (  0.59)	Data 0.0002 (0.0228)	Loss (EDL) 4.581 (4.759)
2023-05-20 17:30:34,567 | Create Epoch [5] features of all training data...
2023-05-20 17:31:03,963 | Updated smoothed statistics on Epoch [5]!
2023-05-20 17:31:04,040 | Updated running statistics with Epoch [5] features!
2023-05-20 17:31:07,892 | Val: [ 0/34]	Time  3.547 ( 3.547)	Loss (L1) 12.335 (12.335)	Loss (EDL) 4.862 (4.862)	Loss (NIG_NLL) 4.202 (4.202)	Loss (NIG_Reg) 65.953 (65.953)
2023-05-20 17:31:09,042 | Val: [10/34]	Time  0.100 ( 0.427)	Loss (L1) 12.293 (11.330)	Loss (EDL) 4.862 (4.729)	Loss (NIG_NLL) 4.206 (4.125)	Loss (NIG_Reg) 65.578 (60.416)
2023-05-20 17:31:10,047 | Val: [20/34]	Time  0.101 ( 0.272)	Loss (L1) 13.626 (11.572)	Loss (EDL) 5.107 (4.771)	Loss (NIG_NLL) 4.381 (4.154)	Loss (NIG_Reg) 72.612 (61.705)
2023-05-20 17:31:11,056 | Val: [30/34]	Time  0.104 ( 0.217)	Loss (L1) 14.643 (11.573)	Loss (EDL) 5.166 (4.771)	Loss (NIG_NLL) 4.387 (4.154)	Loss (NIG_Reg) 77.915 (61.702)
2023-05-20 17:31:11,695 |  * Overall: MSE 211.699	L1 11.518	G-Mean 7.588	EDL 4.760	NIG_NLL 4.146	NIG_Reg 61.409
2023-05-20 17:31:11,695 |  * Many: MSE 157.805	L1 9.891	G-Mean 6.495	EDL 4.508	NIG_NLL 3.981	NIG_Reg 52.772
2023-05-20 17:31:11,695 |  * Median: MSE 313.984	L1 14.686	G-Mean 10.396	EDL 5.255	NIG_NLL 4.474	NIG_Reg 78.188
2023-05-20 17:31:11,696 |  * Low: MSE 437.840	L1 18.121	G-Mean 13.789	EDL 5.767	NIG_NLL 4.802	NIG_Reg 96.583
2023-05-20 17:31:11,697 | Best EDL Loss: 11.431
2023-05-20 17:31:11,704 | Epoch #5: Train loss [4.7591]; Val loss: MSE [211.6994], L1 [11.5182], G-Mean [7.5877], EDL [4.7601], NIG_NLL [4.146], NIG_Reg [61.409]
2023-05-20 17:31:11,704 | this_lr: 
2023-05-20 17:31:11,705 | 0.001
2023-05-20 17:31:16,171 | Epoch: [6][  0/191]	Time   4.46 (  4.46)	Data 3.5138 (3.5138)	Loss (EDL) 4.585 (4.585)
2023-05-20 17:31:21,849 | Epoch: [6][ 10/191]	Time   0.56 (  0.92)	Data 0.0001 (0.3196)	Loss (EDL) 4.606 (4.719)
2023-05-20 17:31:27,511 | Epoch: [6][ 20/191]	Time   0.58 (  0.75)	Data 0.0001 (0.1675)	Loss (EDL) 4.763 (4.749)
2023-05-20 17:31:33,402 | Epoch: [6][ 30/191]	Time   0.56 (  0.70)	Data 0.0001 (0.1135)	Loss (EDL) 4.468 (4.731)
2023-05-20 17:31:39,116 | Epoch: [6][ 40/191]	Time   0.57 (  0.67)	Data 0.0001 (0.0859)	Loss (EDL) 4.504 (4.728)
2023-05-20 17:31:44,764 | Epoch: [6][ 50/191]	Time   0.57 (  0.65)	Data 0.0001 (0.0691)	Loss (EDL) 4.429 (4.728)
2023-05-20 17:31:50,363 | Epoch: [6][ 60/191]	Time   0.56 (  0.63)	Data 0.0001 (0.0578)	Loss (EDL) 4.803 (4.721)
2023-05-20 17:31:55,970 | Epoch: [6][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0497)	Loss (EDL) 4.673 (4.730)
2023-05-20 17:32:01,622 | Epoch: [6][ 80/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0436)	Loss (EDL) 4.866 (4.723)
2023-05-20 17:32:07,335 | Epoch: [6][ 90/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0388)	Loss (EDL) 4.875 (4.733)
2023-05-20 17:32:13,256 | Epoch: [6][100/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0350)	Loss (EDL) 4.867 (4.736)
2023-05-20 17:32:18,887 | Epoch: [6][110/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0319)	Loss (EDL) 4.814 (4.734)
2023-05-20 17:32:24,508 | Epoch: [6][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0293)	Loss (EDL) 4.474 (4.742)
2023-05-20 17:32:30,116 | Epoch: [6][130/191]	Time   0.53 (  0.60)	Data 0.0002 (0.0271)	Loss (EDL) 4.495 (4.738)
2023-05-20 17:32:35,600 | Epoch: [6][140/191]	Time   0.60 (  0.59)	Data 0.0001 (0.0251)	Loss (EDL) 6.529 (4.744)
2023-05-20 17:32:41,050 | Epoch: [6][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0235)	Loss (EDL) 4.771 (4.749)
2023-05-20 17:32:46,597 | Epoch: [6][160/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0221)	Loss (EDL) 4.703 (4.753)
2023-05-20 17:32:52,104 | Epoch: [6][170/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0208)	Loss (EDL) 4.408 (4.754)
2023-05-20 17:32:58,093 | Epoch: [6][180/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0196)	Loss (EDL) 4.368 (4.753)
2023-05-20 17:33:03,468 | Epoch: [6][190/191]	Time   0.46 (  0.59)	Data 0.0001 (0.0186)	Loss (EDL) 4.917 (4.756)
2023-05-20 17:33:03,789 | Create Epoch [6] features of all training data...
2023-05-20 17:33:33,872 | Updated smoothed statistics on Epoch [6]!
2023-05-20 17:33:33,938 | Updated running statistics with Epoch [6] features!
2023-05-20 17:33:37,798 | Val: [ 0/34]	Time  3.529 ( 3.529)	Loss (L1) 11.127 (11.127)	Loss (EDL) 4.733 (4.733)	Loss (NIG_NLL) 4.139 (4.139)	Loss (NIG_Reg) 59.432 (59.432)
2023-05-20 17:33:39,088 | Val: [10/34]	Time  0.100 ( 0.438)	Loss (L1) 10.822 (10.418)	Loss (EDL) 4.688 (4.609)	Loss (NIG_NLL) 4.110 (4.054)	Loss (NIG_Reg) 57.707 (55.514)
2023-05-20 17:33:40,096 | Val: [20/34]	Time  0.101 ( 0.277)	Loss (L1) 13.750 (10.879)	Loss (EDL) 5.122 (4.678)	Loss (NIG_NLL) 4.389 (4.098)	Loss (NIG_Reg) 73.219 (57.967)
2023-05-20 17:33:41,102 | Val: [30/34]	Time  0.101 ( 0.220)	Loss (L1) 13.762 (10.857)	Loss (EDL) 5.041 (4.674)	Loss (NIG_NLL) 4.309 (4.096)	Loss (NIG_Reg) 73.150 (57.844)
2023-05-20 17:33:41,752 |  * Overall: MSE 186.708	L1 10.838	G-Mean 7.115	EDL 4.671	NIG_NLL 4.093	NIG_Reg 57.741
2023-05-20 17:33:41,753 |  * Many: MSE 124.807	L1 8.892	G-Mean 5.858	EDL 4.374	NIG_NLL 3.900	NIG_Reg 47.403
2023-05-20 17:33:41,753 |  * Median: MSE 309.190	L1 14.783	G-Mean 10.614	EDL 5.278	NIG_NLL 4.492	NIG_Reg 78.642
2023-05-20 17:33:41,753 |  * Low: MSE 432.607	L1 18.305	G-Mean 14.745	EDL 5.789	NIG_NLL 4.813	NIG_Reg 97.570
2023-05-20 17:33:41,753 | Best EDL Loss: 10.838
2023-05-20 17:33:41,757 | ===> Saving current best checkpoint...
2023-05-20 17:33:48,927 | Epoch #6: Train loss [4.7557]; Val loss: MSE [186.7077], L1 [10.8381], G-Mean [7.1146], EDL [4.6706], NIG_NLL [4.093], NIG_Reg [57.741]
2023-05-20 17:33:48,929 | this_lr: 
2023-05-20 17:33:48,929 | 0.001
2023-05-20 17:33:53,115 | Epoch: [7][  0/191]	Time   4.18 (  4.18)	Data 3.2221 (3.2221)	Loss (EDL) 4.574 (4.574)
2023-05-20 17:33:58,654 | Epoch: [7][ 10/191]	Time   0.54 (  0.88)	Data 0.0002 (0.2932)	Loss (EDL) 4.786 (4.645)
2023-05-20 17:34:04,218 | Epoch: [7][ 20/191]	Time   0.56 (  0.73)	Data 0.0001 (0.1537)	Loss (EDL) 4.735 (4.590)
2023-05-20 17:34:09,757 | Epoch: [7][ 30/191]	Time   0.54 (  0.67)	Data 0.0001 (0.1042)	Loss (EDL) 4.513 (4.568)
2023-05-20 17:34:15,399 | Epoch: [7][ 40/191]	Time   0.56 (  0.65)	Data 0.0002 (0.0788)	Loss (EDL) 5.217 (4.587)
2023-05-20 17:34:20,956 | Epoch: [7][ 50/191]	Time   0.56 (  0.63)	Data 0.0003 (0.0634)	Loss (EDL) 4.578 (4.606)
2023-05-20 17:34:26,719 | Epoch: [7][ 60/191]	Time   0.58 (  0.62)	Data 0.0001 (0.0531)	Loss (EDL) 4.818 (4.635)
2023-05-20 17:34:32,429 | Epoch: [7][ 70/191]	Time   0.57 (  0.61)	Data 0.0004 (0.0456)	Loss (EDL) 4.708 (4.649)
2023-05-20 17:34:38,635 | Epoch: [7][ 80/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0400)	Loss (EDL) 4.932 (4.671)
2023-05-20 17:34:44,371 | Epoch: [7][ 90/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0357)	Loss (EDL) 4.876 (4.698)
2023-05-20 17:34:50,026 | Epoch: [7][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0322)	Loss (EDL) 4.768 (4.707)
2023-05-20 17:34:55,652 | Epoch: [7][110/191]	Time   0.57 (  0.60)	Data 0.0001 (0.0293)	Loss (EDL) 4.640 (4.713)
2023-05-20 17:35:01,323 | Epoch: [7][120/191]	Time   0.57 (  0.60)	Data 0.0003 (0.0269)	Loss (EDL) 5.041 (4.727)
2023-05-20 17:35:06,800 | Epoch: [7][130/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0249)	Loss (EDL) 4.835 (4.718)
2023-05-20 17:35:12,334 | Epoch: [7][140/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0231)	Loss (EDL) 4.407 (4.701)
2023-05-20 17:35:18,283 | Epoch: [7][150/191]	Time   0.58 (  0.59)	Data 0.0001 (0.0216)	Loss (EDL) 4.335 (4.695)
2023-05-20 17:35:23,722 | Epoch: [7][160/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0203)	Loss (EDL) 4.494 (4.695)
2023-05-20 17:35:29,247 | Epoch: [7][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0191)	Loss (EDL) 4.608 (4.709)
2023-05-20 17:35:34,699 | Epoch: [7][180/191]	Time   0.55 (  0.58)	Data 0.0002 (0.0181)	Loss (EDL) 4.754 (4.704)
2023-05-20 17:35:40,008 | Epoch: [7][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0171)	Loss (EDL) 4.472 (4.706)
2023-05-20 17:35:40,318 | Create Epoch [7] features of all training data...
2023-05-20 17:36:10,126 | Updated smoothed statistics on Epoch [7]!
2023-05-20 17:36:10,194 | Updated running statistics with Epoch [7] features!
2023-05-20 17:36:13,812 | Val: [ 0/34]	Time  3.311 ( 3.311)	Loss (L1) 10.601 (10.601)	Loss (EDL) 4.667 (4.667)	Loss (NIG_NLL) 4.100 (4.100)	Loss (NIG_Reg) 56.710 (56.710)
2023-05-20 17:36:14,841 | Val: [10/34]	Time  0.100 ( 0.395)	Loss (L1) 12.209 (10.894)	Loss (EDL) 4.845 (4.673)	Loss (NIG_NLL) 4.194 (4.092)	Loss (NIG_Reg) 65.125 (58.117)
2023-05-20 17:36:15,845 | Val: [20/34]	Time  0.101 ( 0.255)	Loss (L1) 13.326 (10.984)	Loss (EDL) 5.049 (4.695)	Loss (NIG_NLL) 4.339 (4.109)	Loss (NIG_Reg) 71.030 (58.595)
2023-05-20 17:36:16,851 | Val: [30/34]	Time  0.101 ( 0.205)	Loss (L1) 12.533 (10.925)	Loss (EDL) 4.885 (4.687)	Loss (NIG_NLL) 4.218 (4.104)	Loss (NIG_Reg) 66.649 (58.273)
2023-05-20 17:36:17,518 |  * Overall: MSE 188.023	L1 10.862	G-Mean 7.151	EDL 4.676	NIG_NLL 4.096	NIG_Reg 57.938
2023-05-20 17:36:17,519 |  * Many: MSE 136.622	L1 9.310	G-Mean 6.179	EDL 4.417	NIG_NLL 3.921	NIG_Reg 49.680
2023-05-20 17:36:17,519 |  * Median: MSE 285.724	L1 13.911	G-Mean 9.652	EDL 5.189	NIG_NLL 4.448	NIG_Reg 74.092
2023-05-20 17:36:17,519 |  * Low: MSE 403.297	L1 17.087	G-Mean 12.421	EDL 5.697	NIG_NLL 4.784	NIG_Reg 91.254
2023-05-20 17:36:17,520 | Best EDL Loss: 10.838
2023-05-20 17:36:17,526 | Epoch #7: Train loss [4.7056]; Val loss: MSE [188.0232], L1 [10.8621], G-Mean [7.1514], EDL [4.6757], NIG_NLL [4.096], NIG_Reg [57.938]
2023-05-20 17:36:17,526 | this_lr: 
2023-05-20 17:36:17,526 | 0.001
2023-05-20 17:36:22,124 | Epoch: [8][  0/191]	Time   4.60 (  4.60)	Data 3.6926 (3.6926)	Loss (EDL) 4.861 (4.861)
2023-05-20 17:36:27,716 | Epoch: [8][ 10/191]	Time   0.58 (  0.93)	Data 0.0001 (0.3359)	Loss (EDL) 4.694 (4.777)
2023-05-20 17:36:33,289 | Epoch: [8][ 20/191]	Time   0.55 (  0.75)	Data 0.0001 (0.1760)	Loss (EDL) 4.478 (4.718)
2023-05-20 17:36:38,964 | Epoch: [8][ 30/191]	Time   0.56 (  0.69)	Data 0.0002 (0.1193)	Loss (EDL) 4.734 (4.719)
2023-05-20 17:36:44,653 | Epoch: [8][ 40/191]	Time   0.57 (  0.66)	Data 0.0003 (0.0903)	Loss (EDL) 4.544 (4.728)
2023-05-20 17:36:50,545 | Epoch: [8][ 50/191]	Time   0.58 (  0.65)	Data 0.0002 (0.0726)	Loss (EDL) 4.568 (4.750)
2023-05-20 17:36:56,148 | Epoch: [8][ 60/191]	Time   0.57 (  0.63)	Data 0.0003 (0.0608)	Loss (EDL) 4.602 (4.732)
2023-05-20 17:37:01,707 | Epoch: [8][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0522)	Loss (EDL) 5.350 (4.721)
2023-05-20 17:37:07,299 | Epoch: [8][ 80/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0458)	Loss (EDL) 4.801 (4.728)
2023-05-20 17:37:12,935 | Epoch: [8][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0408)	Loss (EDL) 4.611 (4.718)
2023-05-20 17:37:18,515 | Epoch: [8][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0368)	Loss (EDL) 5.028 (4.704)
2023-05-20 17:37:24,145 | Epoch: [8][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0335)	Loss (EDL) 4.394 (4.694)
2023-05-20 17:37:29,964 | Epoch: [8][120/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0307)	Loss (EDL) 4.405 (4.686)
2023-05-20 17:37:35,508 | Epoch: [8][130/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0284)	Loss (EDL) 4.290 (4.679)
2023-05-20 17:37:41,010 | Epoch: [8][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0264)	Loss (EDL) 4.512 (4.679)
2023-05-20 17:37:46,497 | Epoch: [8][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0247)	Loss (EDL) 4.779 (4.679)
2023-05-20 17:37:52,034 | Epoch: [8][160/191]	Time   0.58 (  0.59)	Data 0.0003 (0.0232)	Loss (EDL) 4.502 (4.676)
2023-05-20 17:37:57,489 | Epoch: [8][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0218)	Loss (EDL) 4.701 (4.677)
2023-05-20 17:38:03,076 | Epoch: [8][180/191]	Time   0.55 (  0.58)	Data 0.0002 (0.0206)	Loss (EDL) 4.682 (4.676)
2023-05-20 17:38:08,458 | Epoch: [8][190/191]	Time   0.47 (  0.58)	Data 0.0002 (0.0196)	Loss (EDL) 4.694 (4.683)
2023-05-20 17:38:08,818 | Create Epoch [8] features of all training data...
2023-05-20 17:38:38,048 | Updated smoothed statistics on Epoch [8]!
2023-05-20 17:38:38,121 | Updated running statistics with Epoch [8] features!
2023-05-20 17:38:41,812 | Val: [ 0/34]	Time  3.401 ( 3.401)	Loss (L1) 12.193 (12.193)	Loss (EDL) 4.871 (4.871)	Loss (NIG_NLL) 4.219 (4.219)	Loss (NIG_Reg) 65.215 (65.215)
2023-05-20 17:38:43,071 | Val: [10/34]	Time  0.100 ( 0.424)	Loss (L1) 11.746 (11.850)	Loss (EDL) 4.798 (4.792)	Loss (NIG_NLL) 4.172 (4.161)	Loss (NIG_Reg) 62.590 (63.158)
2023-05-20 17:38:44,078 | Val: [20/34]	Time  0.100 ( 0.270)	Loss (L1) 14.333 (12.252)	Loss (EDL) 5.207 (4.857)	Loss (NIG_NLL) 4.444 (4.204)	Loss (NIG_Reg) 76.282 (65.298)
2023-05-20 17:38:45,083 | Val: [30/34]	Time  0.100 ( 0.215)	Loss (L1) 14.322 (12.269)	Loss (EDL) 5.137 (4.857)	Loss (NIG_NLL) 4.376 (4.203)	Loss (NIG_Reg) 76.138 (65.371)
2023-05-20 17:38:45,741 |  * Overall: MSE 234.677	L1 12.252	G-Mean 8.079	EDL 4.854	NIG_NLL 4.201	NIG_Reg 65.282
2023-05-20 17:38:45,742 |  * Many: MSE 133.152	L1 9.213	G-Mean 6.002	EDL 4.422	NIG_NLL 3.930	NIG_Reg 49.190
2023-05-20 17:38:45,742 |  * Median: MSE 449.833	L1 19.072	G-Mean 16.318	EDL 5.827	NIG_NLL 4.813	NIG_Reg 101.349
2023-05-20 17:38:45,742 |  * Low: MSE 598.522	L1 22.087	G-Mean 19.126	EDL 6.244	NIG_NLL 5.069	NIG_Reg 117.519
2023-05-20 17:38:45,743 | Best EDL Loss: 10.838
2023-05-20 17:38:45,747 | Epoch #8: Train loss [4.6830]; Val loss: MSE [234.6769], L1 [12.2518], G-Mean [8.0788], EDL [4.8537], NIG_NLL [4.201], NIG_Reg [65.282]
2023-05-20 17:38:45,747 | this_lr: 
2023-05-20 17:38:45,747 | 0.001
2023-05-20 17:38:50,127 | Epoch: [9][  0/191]	Time   4.38 (  4.38)	Data 3.3532 (3.3532)	Loss (EDL) 4.749 (4.749)
2023-05-20 17:38:55,988 | Epoch: [9][ 10/191]	Time   0.60 (  0.93)	Data 0.0003 (0.3051)	Loss (EDL) 4.599 (4.638)
2023-05-20 17:39:01,595 | Epoch: [9][ 20/191]	Time   0.57 (  0.75)	Data 0.0001 (0.1599)	Loss (EDL) 4.840 (4.689)
2023-05-20 17:39:07,180 | Epoch: [9][ 30/191]	Time   0.54 (  0.69)	Data 0.0001 (0.1084)	Loss (EDL) 4.638 (4.669)
2023-05-20 17:39:12,894 | Epoch: [9][ 40/191]	Time   0.60 (  0.66)	Data 0.0001 (0.0820)	Loss (EDL) 4.302 (4.692)
2023-05-20 17:39:18,589 | Epoch: [9][ 50/191]	Time   0.60 (  0.64)	Data 0.0002 (0.0660)	Loss (EDL) 4.602 (4.689)
2023-05-20 17:39:24,270 | Epoch: [9][ 60/191]	Time   0.55 (  0.63)	Data 0.0002 (0.0552)	Loss (EDL) 4.583 (4.687)
2023-05-20 17:39:29,915 | Epoch: [9][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0475)	Loss (EDL) 4.648 (4.660)
2023-05-20 17:39:35,767 | Epoch: [9][ 80/191]	Time   0.56 (  0.62)	Data 0.0003 (0.0417)	Loss (EDL) 4.558 (4.649)
2023-05-20 17:39:41,386 | Epoch: [9][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0371)	Loss (EDL) 4.972 (4.660)
2023-05-20 17:39:46,960 | Epoch: [9][100/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0335)	Loss (EDL) 4.459 (4.646)
2023-05-20 17:39:52,545 | Epoch: [9][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0305)	Loss (EDL) 4.638 (4.651)
2023-05-20 17:39:58,073 | Epoch: [9][120/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0280)	Loss (EDL) 4.492 (4.646)
2023-05-20 17:40:03,784 | Epoch: [9][130/191]	Time   0.58 (  0.60)	Data 0.0001 (0.0259)	Loss (EDL) 5.040 (4.642)
2023-05-20 17:40:09,362 | Epoch: [9][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0241)	Loss (EDL) 4.348 (4.631)
2023-05-20 17:40:14,775 | Epoch: [9][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0225)	Loss (EDL) 5.010 (4.631)
2023-05-20 17:40:20,617 | Epoch: [9][160/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0211)	Loss (EDL) 4.302 (4.633)
2023-05-20 17:40:26,014 | Epoch: [9][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0199)	Loss (EDL) 4.696 (4.640)
2023-05-20 17:40:31,487 | Epoch: [9][180/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0188)	Loss (EDL) 4.530 (4.640)
2023-05-20 17:40:36,893 | Epoch: [9][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0178)	Loss (EDL) 4.482 (4.644)
2023-05-20 17:40:37,212 | Create Epoch [9] features of all training data...
2023-05-20 17:41:06,858 | Updated smoothed statistics on Epoch [9]!
2023-05-20 17:41:06,923 | Updated running statistics with Epoch [9] features!
2023-05-20 17:41:10,638 | Val: [ 0/34]	Time  3.425 ( 3.425)	Loss (L1) 12.334 (12.334)	Loss (EDL) 4.877 (4.877)	Loss (NIG_NLL) 4.219 (4.219)	Loss (NIG_Reg) 65.820 (65.820)
2023-05-20 17:41:11,809 | Val: [10/34]	Time  0.100 ( 0.418)	Loss (L1) 10.803 (10.929)	Loss (EDL) 4.641 (4.663)	Loss (NIG_NLL) 4.066 (4.081)	Loss (NIG_Reg) 57.539 (58.190)
2023-05-20 17:41:12,818 | Val: [20/34]	Time  0.101 ( 0.267)	Loss (L1) 13.988 (11.081)	Loss (EDL) 5.167 (4.706)	Loss (NIG_NLL) 4.423 (4.116)	Loss (NIG_Reg) 74.372 (59.007)
2023-05-20 17:41:13,827 | Val: [30/34]	Time  0.100 ( 0.213)	Loss (L1) 12.897 (11.021)	Loss (EDL) 4.914 (4.692)	Loss (NIG_NLL) 4.228 (4.105)	Loss (NIG_Reg) 68.521 (58.675)
2023-05-20 17:41:14,481 |  * Overall: MSE 192.797	L1 10.909	G-Mean 7.212	EDL 4.675	NIG_NLL 4.094	NIG_Reg 58.078
2023-05-20 17:41:14,481 |  * Many: MSE 145.217	L1 9.474	G-Mean 6.258	EDL 4.446	NIG_NLL 3.942	NIG_Reg 50.486
2023-05-20 17:41:14,481 |  * Median: MSE 277.958	L1 13.491	G-Mean 9.347	EDL 5.108	NIG_NLL 4.391	NIG_Reg 71.696
2023-05-20 17:41:14,481 |  * Low: MSE 406.656	L1 17.323	G-Mean 13.448	EDL 5.633	NIG_NLL 4.712	NIG_Reg 92.121
2023-05-20 17:41:14,482 | Best EDL Loss: 10.838
2023-05-20 17:41:14,485 | Epoch #9: Train loss [4.6440]; Val loss: MSE [192.7971], L1 [10.9088], G-Mean [7.2125], EDL [4.6747], NIG_NLL [4.094], NIG_Reg [58.078]
2023-05-20 17:41:14,485 | this_lr: 
2023-05-20 17:41:14,485 | 0.001
2023-05-20 17:41:19,037 | Epoch: [10][  0/191]	Time   4.55 (  4.55)	Data 3.5685 (3.5685)	Loss (EDL) 4.836 (4.836)
2023-05-20 17:41:24,703 | Epoch: [10][ 10/191]	Time   0.59 (  0.93)	Data 0.0002 (0.3246)	Loss (EDL) 4.375 (4.553)
2023-05-20 17:41:30,261 | Epoch: [10][ 20/191]	Time   0.57 (  0.75)	Data 0.0001 (0.1701)	Loss (EDL) 4.365 (4.574)
2023-05-20 17:41:35,867 | Epoch: [10][ 30/191]	Time   0.57 (  0.69)	Data 0.0002 (0.1153)	Loss (EDL) 4.723 (4.574)
2023-05-20 17:41:41,482 | Epoch: [10][ 40/191]	Time   0.55 (  0.66)	Data 0.0001 (0.0873)	Loss (EDL) 5.171 (4.625)
2023-05-20 17:41:47,064 | Epoch: [10][ 50/191]	Time   0.56 (  0.64)	Data 0.0002 (0.0702)	Loss (EDL) 4.626 (4.621)
2023-05-20 17:41:52,824 | Epoch: [10][ 60/191]	Time   0.57 (  0.63)	Data 0.0002 (0.0587)	Loss (EDL) 4.953 (4.623)
2023-05-20 17:41:58,398 | Epoch: [10][ 70/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0505)	Loss (EDL) 4.735 (4.625)
2023-05-20 17:42:04,011 | Epoch: [10][ 80/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0443)	Loss (EDL) 4.403 (4.627)
2023-05-20 17:42:09,537 | Epoch: [10][ 90/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0394)	Loss (EDL) 4.802 (4.621)
2023-05-20 17:42:15,176 | Epoch: [10][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0356)	Loss (EDL) 4.593 (4.613)
2023-05-20 17:42:20,796 | Epoch: [10][110/191]	Time   0.55 (  0.60)	Data 0.0004 (0.0324)	Loss (EDL) 4.550 (4.605)
2023-05-20 17:42:26,366 | Epoch: [10][120/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0297)	Loss (EDL) 4.359 (4.607)
2023-05-20 17:42:32,191 | Epoch: [10][130/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0275)	Loss (EDL) 4.676 (4.616)
2023-05-20 17:42:37,625 | Epoch: [10][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0255)	Loss (EDL) 4.749 (4.616)
2023-05-20 17:42:43,138 | Epoch: [10][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0239)	Loss (EDL) 4.863 (4.610)
2023-05-20 17:42:48,590 | Epoch: [10][160/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0224)	Loss (EDL) 4.587 (4.607)
2023-05-20 17:42:54,112 | Epoch: [10][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0211)	Loss (EDL) 4.555 (4.612)
2023-05-20 17:42:59,607 | Epoch: [10][180/191]	Time   0.54 (  0.58)	Data 0.0002 (0.0199)	Loss (EDL) 4.897 (4.610)
2023-05-20 17:43:04,973 | Epoch: [10][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0189)	Loss (EDL) 4.410 (4.604)
2023-05-20 17:43:05,316 | Create Epoch [10] features of all training data...
2023-05-20 17:43:35,209 | Updated smoothed statistics on Epoch [10]!
2023-05-20 17:43:35,281 | Updated running statistics with Epoch [10] features!
2023-05-20 17:43:39,301 | Val: [ 0/34]	Time  3.737 ( 3.737)	Loss (L1) 10.824 (10.824)	Loss (EDL) 4.681 (4.681)	Loss (NIG_NLL) 4.103 (4.103)	Loss (NIG_Reg) 57.845 (57.845)
2023-05-20 17:43:40,312 | Val: [10/34]	Time  0.100 ( 0.432)	Loss (L1) 11.833 (10.801)	Loss (EDL) 4.821 (4.655)	Loss (NIG_NLL) 4.190 (4.079)	Loss (NIG_Reg) 63.059 (57.550)
2023-05-20 17:43:41,316 | Val: [20/34]	Time  0.100 ( 0.274)	Loss (L1) 14.275 (11.152)	Loss (EDL) 5.204 (4.715)	Loss (NIG_NLL) 4.445 (4.121)	Loss (NIG_Reg) 75.883 (59.402)
2023-05-20 17:43:42,319 | Val: [30/34]	Time  0.100 ( 0.218)	Loss (L1) 14.148 (11.174)	Loss (EDL) 5.110 (4.715)	Loss (NIG_NLL) 4.358 (4.120)	Loss (NIG_Reg) 75.190 (59.511)
2023-05-20 17:43:42,951 |  * Overall: MSE 198.934	L1 11.147	G-Mean 7.358	EDL 4.711	NIG_NLL 4.117	NIG_Reg 59.367
2023-05-20 17:43:42,952 |  * Many: MSE 142.482	L1 9.482	G-Mean 6.270	EDL 4.453	NIG_NLL 3.947	NIG_Reg 50.557
2023-05-20 17:43:42,952 |  * Median: MSE 309.151	L1 14.526	G-Mean 10.420	EDL 5.240	NIG_NLL 4.469	NIG_Reg 77.168
2023-05-20 17:43:42,952 |  * Low: MSE 427.284	L1 17.526	G-Mean 12.749	EDL 5.680	NIG_NLL 4.746	NIG_Reg 93.343
2023-05-20 17:43:42,953 | Best EDL Loss: 10.838
2023-05-20 17:43:42,959 | Epoch #10: Train loss [4.6039]; Val loss: MSE [198.9336], L1 [11.1468], G-Mean [7.3580], EDL [4.7106], NIG_NLL [4.117], NIG_Reg [59.367]
2023-05-20 17:43:42,960 | this_lr: 
2023-05-20 17:43:42,960 | 0.001
2023-05-20 17:43:47,427 | Epoch: [11][  0/191]	Time   4.46 (  4.46)	Data 3.5150 (3.5150)	Loss (EDL) 4.599 (4.599)
2023-05-20 17:43:53,129 | Epoch: [11][ 10/191]	Time   0.54 (  0.92)	Data 0.0001 (0.3198)	Loss (EDL) 5.118 (4.611)
2023-05-20 17:43:58,692 | Epoch: [11][ 20/191]	Time   0.55 (  0.75)	Data 0.0001 (0.1676)	Loss (EDL) 5.873 (4.660)
2023-05-20 17:44:04,454 | Epoch: [11][ 30/191]	Time   0.53 (  0.69)	Data 0.0001 (0.1136)	Loss (EDL) 4.358 (4.623)
2023-05-20 17:44:10,079 | Epoch: [11][ 40/191]	Time   0.59 (  0.66)	Data 0.0001 (0.0860)	Loss (EDL) 5.586 (4.646)
2023-05-20 17:44:15,726 | Epoch: [11][ 50/191]	Time   0.54 (  0.64)	Data 0.0002 (0.0691)	Loss (EDL) 4.427 (4.647)
2023-05-20 17:44:21,282 | Epoch: [11][ 60/191]	Time   0.57 (  0.63)	Data 0.0004 (0.0579)	Loss (EDL) 4.580 (4.637)
2023-05-20 17:44:26,923 | Epoch: [11][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0497)	Loss (EDL) 4.204 (4.627)
2023-05-20 17:44:32,621 | Epoch: [11][ 80/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0436)	Loss (EDL) 4.226 (4.616)
2023-05-20 17:44:38,478 | Epoch: [11][ 90/191]	Time   0.55 (  0.61)	Data 0.0001 (0.0389)	Loss (EDL) 4.444 (4.605)
2023-05-20 17:44:44,066 | Epoch: [11][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0350)	Loss (EDL) 5.059 (4.601)
2023-05-20 17:44:49,678 | Epoch: [11][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0319)	Loss (EDL) 4.771 (4.601)
2023-05-20 17:44:55,262 | Epoch: [11][120/191]	Time   0.55 (  0.60)	Data 0.0003 (0.0293)	Loss (EDL) 4.293 (4.596)
2023-05-20 17:45:00,813 | Epoch: [11][130/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0271)	Loss (EDL) 4.388 (4.599)
2023-05-20 17:45:06,345 | Epoch: [11][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0252)	Loss (EDL) 4.577 (4.598)
2023-05-20 17:45:11,841 | Epoch: [11][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0235)	Loss (EDL) 4.672 (4.593)
2023-05-20 17:45:17,286 | Epoch: [11][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0221)	Loss (EDL) 4.579 (4.583)
2023-05-20 17:45:22,939 | Epoch: [11][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0208)	Loss (EDL) 4.472 (4.580)
2023-05-20 17:45:28,498 | Epoch: [11][180/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0196)	Loss (EDL) 4.468 (4.576)
2023-05-20 17:45:33,878 | Epoch: [11][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0186)	Loss (EDL) 4.421 (4.577)
2023-05-20 17:45:34,194 | Create Epoch [11] features of all training data...
2023-05-20 17:46:03,656 | Updated smoothed statistics on Epoch [11]!
2023-05-20 17:46:03,736 | Updated running statistics with Epoch [11] features!
2023-05-20 17:46:07,415 | Val: [ 0/34]	Time  3.375 ( 3.375)	Loss (L1) 10.505 (10.505)	Loss (EDL) 4.630 (4.630)	Loss (NIG_NLL) 4.071 (4.071)	Loss (NIG_Reg) 55.995 (55.995)
2023-05-20 17:46:08,744 | Val: [10/34]	Time  0.100 ( 0.428)	Loss (L1) 9.181 (10.238)	Loss (EDL) 4.450 (4.582)	Loss (NIG_NLL) 3.961 (4.037)	Loss (NIG_Reg) 48.937 (54.498)
2023-05-20 17:46:09,750 | Val: [20/34]	Time  0.100 ( 0.272)	Loss (L1) 12.381 (10.405)	Loss (EDL) 4.940 (4.613)	Loss (NIG_NLL) 4.282 (4.059)	Loss (NIG_Reg) 65.814 (55.378)
2023-05-20 17:46:10,757 | Val: [30/34]	Time  0.100 ( 0.217)	Loss (L1) 12.498 (10.401)	Loss (EDL) 4.876 (4.611)	Loss (NIG_NLL) 4.212 (4.057)	Loss (NIG_Reg) 66.397 (55.354)
2023-05-20 17:46:11,470 |  * Overall: MSE 172.686	L1 10.307	G-Mean 6.750	EDL 4.595	NIG_NLL 4.046	NIG_Reg 54.854
2023-05-20 17:46:11,470 |  * Many: MSE 142.500	L1 9.350	G-Mean 6.087	EDL 4.422	NIG_NLL 3.925	NIG_Reg 49.778
2023-05-20 17:46:11,470 |  * Median: MSE 222.309	L1 11.750	G-Mean 8.008	EDL 4.869	NIG_NLL 4.245	NIG_Reg 62.446
2023-05-20 17:46:11,470 |  * Low: MSE 320.550	L1 15.357	G-Mean 11.160	EDL 5.459	NIG_NLL 4.641	NIG_Reg 81.801
2023-05-20 17:46:11,471 | Best EDL Loss: 10.307
2023-05-20 17:46:11,475 | ===> Saving current best checkpoint...
2023-05-20 17:46:18,439 | Epoch #11: Train loss [4.5767]; Val loss: MSE [172.6864], L1 [10.3075], G-Mean [6.7496], EDL [4.5945], NIG_NLL [4.046], NIG_Reg [54.854]
2023-05-20 17:46:18,440 | this_lr: 
2023-05-20 17:46:18,440 | 0.001
2023-05-20 17:46:22,376 | Epoch: [12][  0/191]	Time   3.93 (  3.93)	Data 2.8796 (2.8796)	Loss (EDL) 4.424 (4.424)
2023-05-20 17:46:27,981 | Epoch: [12][ 10/191]	Time   0.54 (  0.87)	Data 0.0001 (0.2620)	Loss (EDL) 4.709 (4.682)
2023-05-20 17:46:33,618 | Epoch: [12][ 20/191]	Time   0.57 (  0.72)	Data 0.0001 (0.1374)	Loss (EDL) 4.641 (4.625)
2023-05-20 17:46:39,187 | Epoch: [12][ 30/191]	Time   0.55 (  0.67)	Data 0.0001 (0.0932)	Loss (EDL) 4.517 (4.611)
2023-05-20 17:46:44,746 | Epoch: [12][ 40/191]	Time   0.57 (  0.64)	Data 0.0002 (0.0705)	Loss (EDL) 4.233 (4.557)
2023-05-20 17:46:50,364 | Epoch: [12][ 50/191]	Time   0.56 (  0.63)	Data 0.0003 (0.0567)	Loss (EDL) 4.503 (4.558)
2023-05-20 17:46:55,894 | Epoch: [12][ 60/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0475)	Loss (EDL) 4.264 (4.554)
2023-05-20 17:47:01,795 | Epoch: [12][ 70/191]	Time   0.56 (  0.61)	Data 0.0004 (0.0408)	Loss (EDL) 4.147 (4.555)
2023-05-20 17:47:07,385 | Epoch: [12][ 80/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0358)	Loss (EDL) 4.536 (4.567)
2023-05-20 17:47:13,007 | Epoch: [12][ 90/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0319)	Loss (EDL) 4.370 (4.566)
2023-05-20 17:47:18,671 | Epoch: [12][100/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0288)	Loss (EDL) 4.710 (4.565)
2023-05-20 17:47:24,332 | Epoch: [12][110/191]	Time   0.58 (  0.59)	Data 0.0002 (0.0262)	Loss (EDL) 4.533 (4.555)
2023-05-20 17:47:29,906 | Epoch: [12][120/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0241)	Loss (EDL) 4.514 (4.559)
2023-05-20 17:47:35,415 | Epoch: [12][130/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0222)	Loss (EDL) 4.216 (4.555)
2023-05-20 17:47:41,110 | Epoch: [12][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0207)	Loss (EDL) 4.397 (4.563)
2023-05-20 17:47:46,583 | Epoch: [12][150/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0193)	Loss (EDL) 4.741 (4.561)
2023-05-20 17:47:52,040 | Epoch: [12][160/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0181)	Loss (EDL) 4.501 (4.559)
2023-05-20 17:47:57,541 | Epoch: [12][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0171)	Loss (EDL) 4.140 (4.561)
2023-05-20 17:48:03,037 | Epoch: [12][180/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0161)	Loss (EDL) 4.495 (4.558)
2023-05-20 17:48:08,469 | Epoch: [12][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0153)	Loss (EDL) 4.684 (4.556)
2023-05-20 17:48:08,819 | Create Epoch [12] features of all training data...
2023-05-20 17:48:37,739 | Updated smoothed statistics on Epoch [12]!
2023-05-20 17:48:37,805 | Updated running statistics with Epoch [12] features!
2023-05-20 17:48:41,663 | Val: [ 0/34]	Time  3.574 ( 3.574)	Loss (L1) 9.785 (9.785)	Loss (EDL) 4.505 (4.505)	Loss (NIG_NLL) 3.984 (3.984)	Loss (NIG_Reg) 52.187 (52.187)
2023-05-20 17:48:42,843 | Val: [10/34]	Time  0.103 ( 0.432)	Loss (L1) 10.006 (9.452)	Loss (EDL) 4.538 (4.462)	Loss (NIG_NLL) 4.005 (3.959)	Loss (NIG_Reg) 53.263 (50.315)
2023-05-20 17:48:43,846 | Val: [20/34]	Time  0.100 ( 0.274)	Loss (L1) 12.028 (9.866)	Loss (EDL) 4.869 (4.524)	Loss (NIG_NLL) 4.229 (3.999)	Loss (NIG_Reg) 63.975 (52.505)
2023-05-20 17:48:44,850 | Val: [30/34]	Time  0.100 ( 0.218)	Loss (L1) 11.227 (9.840)	Loss (EDL) 4.669 (4.517)	Loss (NIG_NLL) 4.073 (3.993)	Loss (NIG_Reg) 59.606 (52.360)
2023-05-20 17:48:45,529 |  * Overall: MSE 153.256	L1 9.751	G-Mean 6.378	EDL 4.502	NIG_NLL 3.984	NIG_Reg 51.886
2023-05-20 17:48:45,529 |  * Many: MSE 121.543	L1 8.608	G-Mean 5.521	EDL 4.301	NIG_NLL 3.842	NIG_Reg 45.813
2023-05-20 17:48:45,529 |  * Median: MSE 212.513	L1 11.935	G-Mean 8.641	EDL 4.899	NIG_NLL 4.265	NIG_Reg 63.434
2023-05-20 17:48:45,529 |  * Low: MSE 288.896	L1 14.504	G-Mean 10.770	EDL 5.311	NIG_NLL 4.538	NIG_Reg 77.309
2023-05-20 17:48:45,529 | Best EDL Loss: 9.751
2023-05-20 17:48:45,533 | ===> Saving current best checkpoint...
2023-05-20 17:48:52,541 | Epoch #12: Train loss [4.5558]; Val loss: MSE [153.2557], L1 [9.7507], G-Mean [6.3782], EDL [4.5024], NIG_NLL [3.984], NIG_Reg [51.886]
2023-05-20 17:48:52,542 | this_lr: 
2023-05-20 17:48:52,542 | 0.001
2023-05-20 17:48:56,616 | Epoch: [13][  0/191]	Time   4.07 (  4.07)	Data 3.1764 (3.1764)	Loss (EDL) 4.133 (4.133)
2023-05-20 17:49:02,231 | Epoch: [13][ 10/191]	Time   0.57 (  0.88)	Data 0.0002 (0.2890)	Loss (EDL) 4.377 (4.482)
2023-05-20 17:49:07,850 | Epoch: [13][ 20/191]	Time   0.59 (  0.73)	Data 0.0002 (0.1515)	Loss (EDL) 4.536 (4.512)
2023-05-20 17:49:13,723 | Epoch: [13][ 30/191]	Time   0.56 (  0.68)	Data 0.0001 (0.1027)	Loss (EDL) 5.064 (4.580)
2023-05-20 17:49:19,259 | Epoch: [13][ 40/191]	Time   0.54 (  0.65)	Data 0.0001 (0.0777)	Loss (EDL) 4.472 (4.543)
2023-05-20 17:49:24,846 | Epoch: [13][ 50/191]	Time   0.55 (  0.63)	Data 0.0002 (0.0625)	Loss (EDL) 4.288 (4.527)
2023-05-20 17:49:30,401 | Epoch: [13][ 60/191]	Time   0.57 (  0.62)	Data 0.0001 (0.0523)	Loss (EDL) 4.517 (4.520)
2023-05-20 17:49:36,014 | Epoch: [13][ 70/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0450)	Loss (EDL) 4.273 (4.515)
2023-05-20 17:49:41,667 | Epoch: [13][ 80/191]	Time   0.61 (  0.61)	Data 0.0002 (0.0394)	Loss (EDL) 4.396 (4.515)
2023-05-20 17:49:47,234 | Epoch: [13][ 90/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0351)	Loss (EDL) 4.513 (4.505)
2023-05-20 17:49:53,020 | Epoch: [13][100/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0317)	Loss (EDL) 4.491 (4.496)
2023-05-20 17:49:58,578 | Epoch: [13][110/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0288)	Loss (EDL) 4.687 (4.499)
2023-05-20 17:50:04,350 | Epoch: [13][120/191]	Time   0.57 (  0.59)	Data 0.0002 (0.0265)	Loss (EDL) 4.587 (4.485)
2023-05-20 17:50:09,942 | Epoch: [13][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0245)	Loss (EDL) 4.917 (4.490)
2023-05-20 17:50:15,549 | Epoch: [13][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0228)	Loss (EDL) 4.811 (4.490)
2023-05-20 17:50:21,166 | Epoch: [13][150/191]	Time   0.59 (  0.59)	Data 0.0001 (0.0213)	Loss (EDL) 4.554 (4.491)
2023-05-20 17:50:26,635 | Epoch: [13][160/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0200)	Loss (EDL) 4.202 (4.490)
2023-05-20 17:50:32,091 | Epoch: [13][170/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0188)	Loss (EDL) 4.416 (4.496)
2023-05-20 17:50:37,838 | Epoch: [13][180/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0178)	Loss (EDL) 4.466 (4.501)
2023-05-20 17:50:43,259 | Epoch: [13][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0169)	Loss (EDL) 4.241 (4.508)
2023-05-20 17:50:43,563 | Create Epoch [13] features of all training data...
2023-05-20 17:51:13,299 | Updated smoothed statistics on Epoch [13]!
2023-05-20 17:51:13,366 | Updated running statistics with Epoch [13] features!
2023-05-20 17:51:17,095 | Val: [ 0/34]	Time  3.433 ( 3.433)	Loss (L1) 9.543 (9.543)	Loss (EDL) 4.452 (4.452)	Loss (NIG_NLL) 3.944 (3.944)	Loss (NIG_Reg) 50.790 (50.790)
2023-05-20 17:51:18,171 | Val: [10/34]	Time  0.102 ( 0.410)	Loss (L1) 9.453 (9.354)	Loss (EDL) 4.490 (4.446)	Loss (NIG_NLL) 3.987 (3.949)	Loss (NIG_Reg) 50.261 (49.729)
2023-05-20 17:51:19,183 | Val: [20/34]	Time  0.100 ( 0.263)	Loss (L1) 12.052 (9.677)	Loss (EDL) 4.865 (4.493)	Loss (NIG_NLL) 4.225 (3.978)	Loss (NIG_Reg) 63.993 (51.438)
2023-05-20 17:51:20,189 | Val: [30/34]	Time  0.101 ( 0.211)	Loss (L1) 11.365 (9.699)	Loss (EDL) 4.685 (4.498)	Loss (NIG_NLL) 4.082 (3.983)	Loss (NIG_Reg) 60.310 (51.552)
2023-05-20 17:51:20,832 |  * Overall: MSE 148.650	L1 9.626	G-Mean 6.305	EDL 4.486	NIG_NLL 3.974	NIG_Reg 51.166
2023-05-20 17:51:20,832 |  * Many: MSE 109.306	L1 8.243	G-Mean 5.379	EDL 4.261	NIG_NLL 3.823	NIG_Reg 43.826
2023-05-20 17:51:20,833 |  * Median: MSE 207.539	L1 11.892	G-Mean 8.253	EDL 4.883	NIG_NLL 4.251	NIG_Reg 63.145
2023-05-20 17:51:20,833 |  * Low: MSE 357.370	L1 16.426	G-Mean 13.421	EDL 5.512	NIG_NLL 4.638	NIG_Reg 87.354
2023-05-20 17:51:20,833 | Best EDL Loss: 9.626
2023-05-20 17:51:20,838 | ===> Saving current best checkpoint...
2023-05-20 17:51:27,844 | Epoch #13: Train loss [4.5085]; Val loss: MSE [148.6496], L1 [9.6263], G-Mean [6.3050], EDL [4.4860], NIG_NLL [3.974], NIG_Reg [51.166]
2023-05-20 17:51:27,846 | this_lr: 
2023-05-20 17:51:27,846 | 0.001
2023-05-20 17:51:32,189 | Epoch: [14][  0/191]	Time   4.34 (  4.34)	Data 3.3983 (3.3983)	Loss (EDL) 4.491 (4.491)
2023-05-20 17:51:37,783 | Epoch: [14][ 10/191]	Time   0.55 (  0.90)	Data 0.0001 (0.3091)	Loss (EDL) 4.360 (4.479)
2023-05-20 17:51:43,446 | Epoch: [14][ 20/191]	Time   0.60 (  0.74)	Data 0.0002 (0.1620)	Loss (EDL) 4.653 (4.492)
2023-05-20 17:51:49,016 | Epoch: [14][ 30/191]	Time   0.56 (  0.68)	Data 0.0001 (0.1098)	Loss (EDL) 4.087 (4.472)
2023-05-20 17:51:54,571 | Epoch: [14][ 40/191]	Time   0.57 (  0.65)	Data 0.0002 (0.0831)	Loss (EDL) 4.800 (4.456)
2023-05-20 17:52:00,136 | Epoch: [14][ 50/191]	Time   0.56 (  0.63)	Data 0.0002 (0.0668)	Loss (EDL) 4.390 (4.457)
2023-05-20 17:52:05,715 | Epoch: [14][ 60/191]	Time   0.54 (  0.62)	Data 0.0001 (0.0559)	Loss (EDL) 4.521 (4.486)
2023-05-20 17:52:11,351 | Epoch: [14][ 70/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0481)	Loss (EDL) 4.180 (4.486)
2023-05-20 17:52:17,281 | Epoch: [14][ 80/191]	Time   0.86 (  0.61)	Data 0.0002 (0.0422)	Loss (EDL) 4.228 (4.483)
2023-05-20 17:52:22,884 | Epoch: [14][ 90/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0376)	Loss (EDL) 4.346 (4.477)
2023-05-20 17:52:28,440 | Epoch: [14][100/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0339)	Loss (EDL) 4.621 (4.468)
2023-05-20 17:52:34,091 | Epoch: [14][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0309)	Loss (EDL) 4.363 (4.462)
2023-05-20 17:52:39,726 | Epoch: [14][120/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0283)	Loss (EDL) 4.436 (4.462)
2023-05-20 17:52:45,236 | Epoch: [14][130/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0262)	Loss (EDL) 4.776 (4.470)
2023-05-20 17:52:50,748 | Epoch: [14][140/191]	Time   0.57 (  0.59)	Data 0.0002 (0.0244)	Loss (EDL) 4.622 (4.468)
2023-05-20 17:52:56,328 | Epoch: [14][150/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0228)	Loss (EDL) 4.434 (4.472)
2023-05-20 17:53:02,170 | Epoch: [14][160/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0213)	Loss (EDL) 4.372 (4.472)
2023-05-20 17:53:07,626 | Epoch: [14][170/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0201)	Loss (EDL) 4.474 (4.478)
2023-05-20 17:53:13,128 | Epoch: [14][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0190)	Loss (EDL) 4.595 (4.478)
2023-05-20 17:53:18,623 | Epoch: [14][190/191]	Time   0.49 (  0.58)	Data 0.0002 (0.0180)	Loss (EDL) 4.458 (4.474)
2023-05-20 17:53:18,993 | Create Epoch [14] features of all training data...
2023-05-20 17:53:48,307 | Updated smoothed statistics on Epoch [14]!
2023-05-20 17:53:48,373 | Updated running statistics with Epoch [14] features!
2023-05-20 17:53:52,081 | Val: [ 0/34]	Time  3.425 ( 3.425)	Loss (L1) 9.462 (9.462)	Loss (EDL) 4.497 (4.497)	Loss (NIG_NLL) 3.993 (3.993)	Loss (NIG_Reg) 50.382 (50.382)
2023-05-20 17:53:53,315 | Val: [10/34]	Time  0.100 ( 0.424)	Loss (L1) 10.492 (9.410)	Loss (EDL) 4.608 (4.453)	Loss (NIG_NLL) 4.050 (3.953)	Loss (NIG_Reg) 55.729 (50.008)
2023-05-20 17:53:54,318 | Val: [20/34]	Time  0.100 ( 0.270)	Loss (L1) 12.159 (9.644)	Loss (EDL) 4.948 (4.496)	Loss (NIG_NLL) 4.302 (3.984)	Loss (NIG_Reg) 64.575 (51.251)
2023-05-20 17:53:55,325 | Val: [30/34]	Time  0.101 ( 0.215)	Loss (L1) 10.920 (9.579)	Loss (EDL) 4.602 (4.481)	Loss (NIG_NLL) 4.022 (3.972)	Loss (NIG_Reg) 57.951 (50.899)
2023-05-20 17:53:55,946 |  * Overall: MSE 151.863	L1 9.502	G-Mean 6.034	EDL 4.469	NIG_NLL 3.964	NIG_Reg 50.492
2023-05-20 17:53:55,946 |  * Many: MSE 120.136	L1 8.486	G-Mean 5.366	EDL 4.284	NIG_NLL 3.833	NIG_Reg 45.106
2023-05-20 17:53:55,946 |  * Median: MSE 222.581	L1 11.666	G-Mean 7.668	EDL 4.876	NIG_NLL 4.257	NIG_Reg 61.935
2023-05-20 17:53:55,946 |  * Low: MSE 255.939	L1 13.115	G-Mean 9.408	EDL 5.087	NIG_NLL 4.390	NIG_Reg 69.713
2023-05-20 17:53:55,947 | Best EDL Loss: 9.502
2023-05-20 17:53:55,950 | ===> Saving current best checkpoint...
2023-05-20 17:54:03,187 | Epoch #14: Train loss [4.4740]; Val loss: MSE [151.8627], L1 [9.5020], G-Mean [6.0337], EDL [4.4687], NIG_NLL [3.964], NIG_Reg [50.492]
2023-05-20 17:54:03,188 | this_lr: 
2023-05-20 17:54:03,188 | 0.001
2023-05-20 17:54:06,838 | Epoch: [15][  0/191]	Time   3.65 (  3.65)	Data 2.6816 (2.6816)	Loss (EDL) 4.155 (4.155)
2023-05-20 17:54:12,522 | Epoch: [15][ 10/191]	Time   0.56 (  0.85)	Data 0.0001 (0.2440)	Loss (EDL) 4.459 (4.449)
2023-05-20 17:54:18,129 | Epoch: [15][ 20/191]	Time   0.58 (  0.71)	Data 0.0004 (0.1279)	Loss (EDL) 4.133 (4.460)
2023-05-20 17:54:23,861 | Epoch: [15][ 30/191]	Time   0.57 (  0.67)	Data 0.0003 (0.0868)	Loss (EDL) 4.913 (4.510)
2023-05-20 17:54:29,482 | Epoch: [15][ 40/191]	Time   0.59 (  0.64)	Data 0.0002 (0.0657)	Loss (EDL) 4.244 (4.500)
2023-05-20 17:54:35,075 | Epoch: [15][ 50/191]	Time   0.57 (  0.63)	Data 0.0003 (0.0529)	Loss (EDL) 4.106 (4.491)
2023-05-20 17:54:41,286 | Epoch: [15][ 60/191]	Time   0.58 (  0.62)	Data 0.0002 (0.0442)	Loss (EDL) 4.537 (4.498)
2023-05-20 17:54:46,899 | Epoch: [15][ 70/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0381)	Loss (EDL) 4.269 (4.493)
2023-05-20 17:54:52,575 | Epoch: [15][ 80/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0334)	Loss (EDL) 4.698 (4.490)
2023-05-20 17:54:58,213 | Epoch: [15][ 90/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0298)	Loss (EDL) 4.511 (4.477)
2023-05-20 17:55:03,774 | Epoch: [15][100/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0268)	Loss (EDL) 4.347 (4.463)
2023-05-20 17:55:09,341 | Epoch: [15][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0244)	Loss (EDL) 4.402 (4.453)
2023-05-20 17:55:14,866 | Epoch: [15][120/191]	Time   0.58 (  0.59)	Data 0.0003 (0.0224)	Loss (EDL) 4.946 (4.442)
2023-05-20 17:55:20,730 | Epoch: [15][130/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0207)	Loss (EDL) 4.076 (4.443)
2023-05-20 17:55:26,166 | Epoch: [15][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0193)	Loss (EDL) 4.889 (4.457)
2023-05-20 17:55:31,718 | Epoch: [15][150/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0180)	Loss (EDL) 4.474 (4.455)
2023-05-20 17:55:37,271 | Epoch: [15][160/191]	Time   0.56 (  0.58)	Data 0.0003 (0.0169)	Loss (EDL) 4.548 (4.454)
2023-05-20 17:55:42,784 | Epoch: [15][170/191]	Time   0.57 (  0.58)	Data 0.0002 (0.0159)	Loss (EDL) 4.629 (4.459)
2023-05-20 17:55:48,323 | Epoch: [15][180/191]	Time   0.57 (  0.58)	Data 0.0003 (0.0151)	Loss (EDL) 4.601 (4.462)
2023-05-20 17:55:53,743 | Epoch: [15][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0143)	Loss (EDL) 4.337 (4.457)
2023-05-20 17:55:54,081 | Create Epoch [15] features of all training data...
2023-05-20 17:56:23,820 | Updated smoothed statistics on Epoch [15]!
2023-05-20 17:56:23,886 | Updated running statistics with Epoch [15] features!
2023-05-20 17:56:27,627 | Val: [ 0/34]	Time  3.453 ( 3.453)	Loss (L1) 9.659 (9.659)	Loss (EDL) 4.491 (4.491)	Loss (NIG_NLL) 3.977 (3.977)	Loss (NIG_Reg) 51.411 (51.411)
2023-05-20 17:56:28,802 | Val: [10/34]	Time  0.100 ( 0.421)	Loss (L1) 9.413 (9.347)	Loss (EDL) 4.453 (4.438)	Loss (NIG_NLL) 3.952 (3.941)	Loss (NIG_Reg) 50.042 (49.667)
2023-05-20 17:56:29,808 | Val: [20/34]	Time  0.101 ( 0.268)	Loss (L1) 11.499 (9.541)	Loss (EDL) 4.805 (4.475)	Loss (NIG_NLL) 4.194 (3.968)	Loss (NIG_Reg) 61.044 (50.696)
2023-05-20 17:56:30,815 | Val: [30/34]	Time  0.100 ( 0.214)	Loss (L1) 11.182 (9.525)	Loss (EDL) 4.627 (4.466)	Loss (NIG_NLL) 4.033 (3.960)	Loss (NIG_Reg) 59.335 (50.610)
2023-05-20 17:56:31,473 |  * Overall: MSE 142.652	L1 9.456	G-Mean 6.301	EDL 4.453	NIG_NLL 3.951	NIG_Reg 50.242
2023-05-20 17:56:31,474 |  * Many: MSE 113.200	L1 8.405	G-Mean 5.546	EDL 4.268	NIG_NLL 3.822	NIG_Reg 44.667
2023-05-20 17:56:31,474 |  * Median: MSE 189.819	L1 11.242	G-Mean 7.958	EDL 4.788	NIG_NLL 4.191	NIG_Reg 59.687
2023-05-20 17:56:31,474 |  * Low: MSE 290.371	L1 14.444	G-Mean 11.041	EDL 5.274	NIG_NLL 4.506	NIG_Reg 76.785
2023-05-20 17:56:31,474 | Best EDL Loss: 9.456
2023-05-20 17:56:31,477 | ===> Saving current best checkpoint...
2023-05-20 17:56:38,519 | Epoch #15: Train loss [4.4573]; Val loss: MSE [142.6518], L1 [9.4563], G-Mean [6.3013], EDL [4.4532], NIG_NLL [3.951], NIG_Reg [50.242]
2023-05-20 17:56:38,520 | this_lr: 
2023-05-20 17:56:38,520 | 0.001
2023-05-20 17:56:42,533 | Epoch: [16][  0/191]	Time   4.01 (  4.01)	Data 3.0700 (3.0700)	Loss (EDL) 4.306 (4.306)
2023-05-20 17:56:48,195 | Epoch: [16][ 10/191]	Time   0.54 (  0.88)	Data 0.0001 (0.2794)	Loss (EDL) 4.483 (4.415)
2023-05-20 17:56:54,000 | Epoch: [16][ 20/191]	Time   0.57 (  0.74)	Data 0.0001 (0.1465)	Loss (EDL) 4.427 (4.423)
2023-05-20 17:56:59,595 | Epoch: [16][ 30/191]	Time   0.56 (  0.68)	Data 0.0001 (0.0993)	Loss (EDL) 4.260 (4.408)
2023-05-20 17:57:05,218 | Epoch: [16][ 40/191]	Time   0.56 (  0.65)	Data 0.0001 (0.0751)	Loss (EDL) 4.633 (4.422)
2023-05-20 17:57:10,825 | Epoch: [16][ 50/191]	Time   0.57 (  0.63)	Data 0.0002 (0.0604)	Loss (EDL) 4.310 (4.419)
2023-05-20 17:57:16,451 | Epoch: [16][ 60/191]	Time   0.57 (  0.62)	Data 0.0001 (0.0506)	Loss (EDL) 4.425 (4.412)
2023-05-20 17:57:22,019 | Epoch: [16][ 70/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0435)	Loss (EDL) 4.282 (4.413)
2023-05-20 17:57:27,670 | Epoch: [16][ 80/191]	Time   0.56 (  0.61)	Data 0.0003 (0.0381)	Loss (EDL) 5.058 (4.444)
2023-05-20 17:57:33,486 | Epoch: [16][ 90/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0340)	Loss (EDL) 4.763 (4.451)
2023-05-20 17:57:39,135 | Epoch: [16][100/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0306)	Loss (EDL) 4.750 (4.461)
2023-05-20 17:57:44,643 | Epoch: [16][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0279)	Loss (EDL) 4.736 (4.463)
2023-05-20 17:57:50,314 | Epoch: [16][120/191]	Time   0.57 (  0.59)	Data 0.0002 (0.0256)	Loss (EDL) 4.260 (4.465)
2023-05-20 17:57:55,821 | Epoch: [16][130/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0237)	Loss (EDL) 4.666 (4.466)
2023-05-20 17:58:01,290 | Epoch: [16][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0220)	Loss (EDL) 4.541 (4.461)
2023-05-20 17:58:06,725 | Epoch: [16][150/191]	Time   0.57 (  0.58)	Data 0.0001 (0.0206)	Loss (EDL) 4.074 (4.454)
2023-05-20 17:58:12,217 | Epoch: [16][160/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0193)	Loss (EDL) 4.377 (4.454)
2023-05-20 17:58:18,070 | Epoch: [16][170/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0182)	Loss (EDL) 4.388 (4.452)
2023-05-20 17:58:23,618 | Epoch: [16][180/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0172)	Loss (EDL) 4.240 (4.453)
2023-05-20 17:58:29,178 | Epoch: [16][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0163)	Loss (EDL) 4.633 (4.455)
2023-05-20 17:58:29,553 | Create Epoch [16] features of all training data...
2023-05-20 17:58:59,130 | Updated smoothed statistics on Epoch [16]!
2023-05-20 17:58:59,197 | Updated running statistics with Epoch [16] features!
2023-05-20 17:59:02,938 | Val: [ 0/34]	Time  3.416 ( 3.416)	Loss (L1) 9.064 (9.064)	Loss (EDL) 4.416 (4.416)	Loss (NIG_NLL) 3.932 (3.932)	Loss (NIG_Reg) 48.330 (48.330)
2023-05-20 17:59:04,022 | Val: [10/34]	Time  0.101 ( 0.409)	Loss (L1) 9.362 (8.954)	Loss (EDL) 4.472 (4.373)	Loss (NIG_NLL) 3.974 (3.897)	Loss (NIG_Reg) 49.783 (47.604)
2023-05-20 17:59:05,030 | Val: [20/34]	Time  0.100 ( 0.262)	Loss (L1) 10.950 (9.171)	Loss (EDL) 4.726 (4.421)	Loss (NIG_NLL) 4.145 (3.934)	Loss (NIG_Reg) 58.132 (48.747)
2023-05-20 17:59:06,036 | Val: [30/34]	Time  0.101 ( 0.210)	Loss (L1) 10.666 (9.257)	Loss (EDL) 4.577 (4.429)	Loss (NIG_NLL) 4.011 (3.937)	Loss (NIG_Reg) 56.634 (49.199)
2023-05-20 17:59:06,692 |  * Overall: MSE 138.570	L1 9.208	G-Mean 6.080	EDL 4.419	NIG_NLL 3.930	NIG_Reg 48.942
2023-05-20 17:59:06,692 |  * Many: MSE 111.727	L1 8.279	G-Mean 5.446	EDL 4.242	NIG_NLL 3.802	NIG_Reg 44.008
2023-05-20 17:59:06,692 |  * Median: MSE 173.078	L1 10.635	G-Mean 7.486	EDL 4.717	NIG_NLL 4.153	NIG_Reg 56.474
2023-05-20 17:59:06,692 |  * Low: MSE 296.659	L1 14.042	G-Mean 9.690	EDL 5.272	NIG_NLL 4.525	NIG_Reg 74.712
2023-05-20 17:59:06,692 | Best EDL Loss: 9.208
2023-05-20 17:59:06,695 | ===> Saving current best checkpoint...
2023-05-20 17:59:13,657 | Epoch #16: Train loss [4.4551]; Val loss: MSE [138.5699], L1 [9.2084], G-Mean [6.0805], EDL [4.4194], NIG_NLL [3.930], NIG_Reg [48.942]
2023-05-20 17:59:13,658 | this_lr: 
2023-05-20 17:59:13,658 | 0.001
2023-05-20 17:59:17,765 | Epoch: [17][  0/191]	Time   4.10 (  4.10)	Data 3.1032 (3.1032)	Loss (EDL) 4.312 (4.312)
2023-05-20 17:59:23,266 | Epoch: [17][ 10/191]	Time   0.55 (  0.87)	Data 0.0001 (0.2823)	Loss (EDL) 4.430 (4.385)
2023-05-20 17:59:28,834 | Epoch: [17][ 20/191]	Time   0.54 (  0.72)	Data 0.0001 (0.1480)	Loss (EDL) 4.457 (4.328)
2023-05-20 17:59:34,499 | Epoch: [17][ 30/191]	Time   0.56 (  0.67)	Data 0.0002 (0.1003)	Loss (EDL) 4.184 (4.329)
2023-05-20 17:59:40,064 | Epoch: [17][ 40/191]	Time   0.57 (  0.64)	Data 0.0002 (0.0759)	Loss (EDL) 4.300 (4.334)
2023-05-20 17:59:45,669 | Epoch: [17][ 50/191]	Time   0.57 (  0.63)	Data 0.0003 (0.0610)	Loss (EDL) 4.170 (4.344)
2023-05-20 17:59:51,238 | Epoch: [17][ 60/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0511)	Loss (EDL) 4.215 (4.355)
2023-05-20 17:59:57,104 | Epoch: [17][ 70/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0439)	Loss (EDL) 4.230 (4.348)
2023-05-20 18:00:02,724 | Epoch: [17][ 80/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0385)	Loss (EDL) 4.550 (4.349)
2023-05-20 18:00:08,417 | Epoch: [17][ 90/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0343)	Loss (EDL) 4.243 (4.353)
2023-05-20 18:00:14,111 | Epoch: [17][100/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0309)	Loss (EDL) 4.727 (4.358)
2023-05-20 18:00:19,664 | Epoch: [17][110/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0282)	Loss (EDL) 4.369 (4.355)
2023-05-20 18:00:25,326 | Epoch: [17][120/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0259)	Loss (EDL) 4.431 (4.359)
2023-05-20 18:00:30,920 | Epoch: [17][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0239)	Loss (EDL) 4.319 (4.364)
2023-05-20 18:00:36,662 | Epoch: [17][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0223)	Loss (EDL) 5.177 (4.377)
2023-05-20 18:00:42,199 | Epoch: [17][150/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0208)	Loss (EDL) 4.378 (4.387)
2023-05-20 18:00:47,737 | Epoch: [17][160/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0195)	Loss (EDL) 4.217 (4.391)
2023-05-20 18:00:53,264 | Epoch: [17][170/191]	Time   0.57 (  0.58)	Data 0.0001 (0.0184)	Loss (EDL) 4.364 (4.391)
2023-05-20 18:00:58,739 | Epoch: [17][180/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0174)	Loss (EDL) 4.289 (4.392)
2023-05-20 18:01:04,174 | Epoch: [17][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0165)	Loss (EDL) 4.678 (4.393)
2023-05-20 18:01:04,512 | Create Epoch [17] features of all training data...
2023-05-20 18:01:34,167 | Updated smoothed statistics on Epoch [17]!
2023-05-20 18:01:34,233 | Updated running statistics with Epoch [17] features!
2023-05-20 18:01:38,038 | Val: [ 0/34]	Time  3.508 ( 3.508)	Loss (L1) 8.730 (8.730)	Loss (EDL) 4.394 (4.394)	Loss (NIG_NLL) 3.930 (3.930)	Loss (NIG_Reg) 46.398 (46.398)
2023-05-20 18:01:39,265 | Val: [10/34]	Time  0.100 ( 0.430)	Loss (L1) 10.594 (9.128)	Loss (EDL) 4.627 (4.415)	Loss (NIG_NLL) 4.064 (3.931)	Loss (NIG_Reg) 56.245 (48.466)
2023-05-20 18:01:40,272 | Val: [20/34]	Time  0.103 ( 0.273)	Loss (L1) 11.463 (9.394)	Loss (EDL) 4.805 (4.463)	Loss (NIG_NLL) 4.197 (3.964)	Loss (NIG_Reg) 60.814 (49.878)
2023-05-20 18:01:41,276 | Val: [30/34]	Time  0.100 ( 0.218)	Loss (L1) 10.319 (9.352)	Loss (EDL) 4.546 (4.447)	Loss (NIG_NLL) 3.998 (3.951)	Loss (NIG_Reg) 54.739 (49.653)
2023-05-20 18:01:41,943 |  * Overall: MSE 140.993	L1 9.295	G-Mean 6.098	EDL 4.435	NIG_NLL 3.942	NIG_Reg 49.350
2023-05-20 18:01:41,943 |  * Many: MSE 104.811	L1 8.033	G-Mean 5.280	EDL 4.206	NIG_NLL 3.779	NIG_Reg 42.657
2023-05-20 18:01:41,943 |  * Median: MSE 211.465	L1 11.908	G-Mean 8.234	EDL 4.929	NIG_NLL 4.297	NIG_Reg 63.190
2023-05-20 18:01:41,943 |  * Low: MSE 287.829	L1 13.988	G-Mean 10.363	EDL 5.240	NIG_NLL 4.497	NIG_Reg 74.284
2023-05-20 18:01:41,943 | Best EDL Loss: 9.208
2023-05-20 18:01:41,947 | Epoch #17: Train loss [4.3929]; Val loss: MSE [140.9934], L1 [9.2952], G-Mean [6.0984], EDL [4.4354], NIG_NLL [3.942], NIG_Reg [49.350]
2023-05-20 18:01:41,947 | this_lr: 
2023-05-20 18:01:41,947 | 0.001
2023-05-20 18:01:46,513 | Epoch: [18][  0/191]	Time   4.56 (  4.56)	Data 3.5886 (3.5886)	Loss (EDL) 4.474 (4.474)
2023-05-20 18:01:52,139 | Epoch: [18][ 10/191]	Time   0.56 (  0.93)	Data 0.0002 (0.3265)	Loss (EDL) 4.226 (4.271)
2023-05-20 18:01:57,826 | Epoch: [18][ 20/191]	Time   0.57 (  0.76)	Data 0.0004 (0.1711)	Loss (EDL) 4.493 (4.378)
2023-05-20 18:02:03,481 | Epoch: [18][ 30/191]	Time   0.56 (  0.69)	Data 0.0001 (0.1160)	Loss (EDL) 4.408 (4.415)
2023-05-20 18:02:09,283 | Epoch: [18][ 40/191]	Time   0.56 (  0.67)	Data 0.0001 (0.0877)	Loss (EDL) 4.317 (4.434)
2023-05-20 18:02:14,893 | Epoch: [18][ 50/191]	Time   0.56 (  0.65)	Data 0.0001 (0.0706)	Loss (EDL) 4.416 (4.423)
2023-05-20 18:02:20,495 | Epoch: [18][ 60/191]	Time   0.57 (  0.63)	Data 0.0002 (0.0590)	Loss (EDL) 4.342 (4.437)
2023-05-20 18:02:26,187 | Epoch: [18][ 70/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0508)	Loss (EDL) 4.344 (4.436)
2023-05-20 18:02:31,795 | Epoch: [18][ 80/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0445)	Loss (EDL) 4.299 (4.433)
2023-05-20 18:02:37,468 | Epoch: [18][ 90/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0397)	Loss (EDL) 4.652 (4.424)
2023-05-20 18:02:43,193 | Epoch: [18][100/191]	Time   0.55 (  0.61)	Data 0.0003 (0.0358)	Loss (EDL) 4.321 (4.417)
2023-05-20 18:02:49,048 | Epoch: [18][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0326)	Loss (EDL) 4.677 (4.413)
2023-05-20 18:02:54,764 | Epoch: [18][120/191]	Time   0.60 (  0.60)	Data 0.0002 (0.0299)	Loss (EDL) 4.270 (4.409)
2023-05-20 18:03:00,438 | Epoch: [18][130/191]	Time   0.56 (  0.60)	Data 0.0001 (0.0276)	Loss (EDL) 4.339 (4.406)
2023-05-20 18:03:05,972 | Epoch: [18][140/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0257)	Loss (EDL) 4.081 (4.396)
2023-05-20 18:03:11,510 | Epoch: [18][150/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0240)	Loss (EDL) 4.432 (4.397)
2023-05-20 18:03:17,082 | Epoch: [18][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0225)	Loss (EDL) 4.025 (4.396)
2023-05-20 18:03:22,630 | Epoch: [18][170/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0212)	Loss (EDL) 4.117 (4.394)
2023-05-20 18:03:28,207 | Epoch: [18][180/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0200)	Loss (EDL) 4.370 (4.390)
2023-05-20 18:03:33,896 | Epoch: [18][190/191]	Time   0.73 (  0.59)	Data 0.0001 (0.0190)	Loss (EDL) 4.153 (4.386)
2023-05-20 18:03:34,234 | Create Epoch [18] features of all training data...
2023-05-20 18:04:04,043 | Updated smoothed statistics on Epoch [18]!
2023-05-20 18:04:04,111 | Updated running statistics with Epoch [18] features!
2023-05-20 18:04:07,763 | Val: [ 0/34]	Time  3.385 ( 3.385)	Loss (L1) 8.490 (8.490)	Loss (EDL) 4.318 (4.318)	Loss (NIG_NLL) 3.866 (3.866)	Loss (NIG_Reg) 45.181 (45.181)
2023-05-20 18:04:09,188 | Val: [10/34]	Time  0.100 ( 0.437)	Loss (L1) 8.365 (8.992)	Loss (EDL) 4.310 (4.392)	Loss (NIG_NLL) 3.866 (3.915)	Loss (NIG_Reg) 44.438 (47.761)
2023-05-20 18:04:10,189 | Val: [20/34]	Time  0.100 ( 0.277)	Loss (L1) 11.347 (9.174)	Loss (EDL) 4.786 (4.426)	Loss (NIG_NLL) 4.184 (3.939)	Loss (NIG_Reg) 60.202 (48.720)
2023-05-20 18:04:11,193 | Val: [30/34]	Time  0.101 ( 0.220)	Loss (L1) 9.916 (9.250)	Loss (EDL) 4.467 (4.434)	Loss (NIG_NLL) 3.941 (3.943)	Loss (NIG_Reg) 52.604 (49.124)
2023-05-20 18:04:11,825 |  * Overall: MSE 139.461	L1 9.176	G-Mean 5.903	EDL 4.420	NIG_NLL 3.933	NIG_Reg 48.731
2023-05-20 18:04:11,825 |  * Many: MSE 100.914	L1 7.849	G-Mean 5.099	EDL 4.175	NIG_NLL 3.758	NIG_Reg 41.691
2023-05-20 18:04:11,825 |  * Median: MSE 212.240	L1 11.827	G-Mean 7.928	EDL 4.931	NIG_NLL 4.304	NIG_Reg 62.758
2023-05-20 18:04:11,825 |  * Low: MSE 302.251	L1 14.387	G-Mean 10.411	EDL 5.323	NIG_NLL 4.559	NIG_Reg 76.431
2023-05-20 18:04:11,826 | Best EDL Loss: 9.176
2023-05-20 18:04:11,829 | ===> Saving current best checkpoint...
2023-05-20 18:04:18,813 | Epoch #18: Train loss [4.3859]; Val loss: MSE [139.4609], L1 [9.1764], G-Mean [5.9029], EDL [4.4202], NIG_NLL [3.933], NIG_Reg [48.731]
2023-05-20 18:04:18,815 | this_lr: 
2023-05-20 18:04:18,815 | 0.001
2023-05-20 18:04:22,931 | Epoch: [19][  0/191]	Time   4.11 (  4.11)	Data 3.1255 (3.1255)	Loss (EDL) 4.193 (4.193)
2023-05-20 18:04:28,500 | Epoch: [19][ 10/191]	Time   0.55 (  0.88)	Data 0.0001 (0.2844)	Loss (EDL) 4.179 (4.172)
2023-05-20 18:04:34,087 | Epoch: [19][ 20/191]	Time   0.55 (  0.73)	Data 0.0001 (0.1491)	Loss (EDL) 4.618 (4.255)
2023-05-20 18:04:39,784 | Epoch: [19][ 30/191]	Time   0.57 (  0.68)	Data 0.0002 (0.1011)	Loss (EDL) 4.274 (4.261)
2023-05-20 18:04:45,391 | Epoch: [19][ 40/191]	Time   0.57 (  0.65)	Data 0.0001 (0.0765)	Loss (EDL) 4.551 (4.317)
2023-05-20 18:04:51,070 | Epoch: [19][ 50/191]	Time   0.57 (  0.63)	Data 0.0002 (0.0615)	Loss (EDL) 4.515 (4.345)
2023-05-20 18:04:56,672 | Epoch: [19][ 60/191]	Time   0.55 (  0.62)	Data 0.0003 (0.0515)	Loss (EDL) 4.229 (4.345)
2023-05-20 18:05:02,261 | Epoch: [19][ 70/191]	Time   0.56 (  0.61)	Data 0.0003 (0.0443)	Loss (EDL) 4.513 (4.356)
2023-05-20 18:05:07,881 | Epoch: [19][ 80/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0388)	Loss (EDL) 4.189 (4.355)
2023-05-20 18:05:13,557 | Epoch: [19][ 90/191]	Time   0.59 (  0.60)	Data 0.0002 (0.0346)	Loss (EDL) 4.325 (4.360)
2023-05-20 18:05:19,686 | Epoch: [19][100/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0312)	Loss (EDL) 4.049 (4.357)
2023-05-20 18:05:25,327 | Epoch: [19][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0284)	Loss (EDL) 4.843 (4.358)
2023-05-20 18:05:31,071 | Epoch: [19][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0261)	Loss (EDL) 4.154 (4.370)
2023-05-20 18:05:36,659 | Epoch: [19][130/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0241)	Loss (EDL) 4.341 (4.363)
2023-05-20 18:05:42,110 | Epoch: [19][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0224)	Loss (EDL) 4.324 (4.374)
2023-05-20 18:05:47,530 | Epoch: [19][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0209)	Loss (EDL) 4.255 (4.372)
2023-05-20 18:05:53,120 | Epoch: [19][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0197)	Loss (EDL) 4.307 (4.367)
2023-05-20 18:05:58,636 | Epoch: [19][170/191]	Time   0.55 (  0.58)	Data 0.0002 (0.0185)	Loss (EDL) 4.367 (4.363)
2023-05-20 18:06:04,477 | Epoch: [19][180/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0175)	Loss (EDL) 4.316 (4.366)
2023-05-20 18:06:09,844 | Epoch: [19][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0166)	Loss (EDL) 4.259 (4.365)
2023-05-20 18:06:10,168 | Create Epoch [19] features of all training data...
2023-05-20 18:06:39,873 | Updated smoothed statistics on Epoch [19]!
2023-05-20 18:06:39,949 | Updated running statistics with Epoch [19] features!
2023-05-20 18:06:43,610 | Val: [ 0/34]	Time  3.375 ( 3.375)	Loss (L1) 8.866 (8.866)	Loss (EDL) 4.350 (4.350)	Loss (NIG_NLL) 3.878 (3.878)	Loss (NIG_Reg) 47.204 (47.204)
2023-05-20 18:06:44,710 | Val: [10/34]	Time  0.100 ( 0.407)	Loss (L1) 10.399 (9.681)	Loss (EDL) 4.594 (4.479)	Loss (NIG_NLL) 4.041 (3.965)	Loss (NIG_Reg) 55.242 (51.443)
2023-05-20 18:06:45,714 | Val: [20/34]	Time  0.100 ( 0.261)	Loss (L1) 11.891 (9.844)	Loss (EDL) 4.825 (4.517)	Loss (NIG_NLL) 4.194 (3.994)	Loss (NIG_Reg) 63.101 (52.301)
2023-05-20 18:06:46,719 | Val: [30/34]	Time  0.100 ( 0.209)	Loss (L1) 11.174 (9.970)	Loss (EDL) 4.620 (4.530)	Loss (NIG_NLL) 4.027 (4.001)	Loss (NIG_Reg) 59.310 (52.968)
2023-05-20 18:06:47,347 |  * Overall: MSE 157.979	L1 9.946	G-Mean 6.693	EDL 4.524	NIG_NLL 3.996	NIG_Reg 52.841
2023-05-20 18:06:47,347 |  * Many: MSE 131.227	L1 8.988	G-Mean 5.973	EDL 4.339	NIG_NLL 3.862	NIG_Reg 47.752
2023-05-20 18:06:47,347 |  * Median: MSE 196.208	L1 11.593	G-Mean 8.454	EDL 4.851	NIG_NLL 4.235	NIG_Reg 61.543
2023-05-20 18:06:47,347 |  * Low: MSE 304.917	L1 14.442	G-Mean 10.273	EDL 5.365	NIG_NLL 4.597	NIG_Reg 76.842
2023-05-20 18:06:47,347 | Best EDL Loss: 9.176
2023-05-20 18:06:47,351 | Epoch #19: Train loss [4.3647]; Val loss: MSE [157.9792], L1 [9.9462], G-Mean [6.6930], EDL [4.5240], NIG_NLL [3.996], NIG_Reg [52.841]
2023-05-20 18:06:47,351 | this_lr: 
2023-05-20 18:06:47,351 | 0.001
2023-05-20 18:06:51,807 | Epoch: [20][  0/191]	Time   4.45 (  4.45)	Data 3.5353 (3.5353)	Loss (EDL) 4.424 (4.424)
2023-05-20 18:06:57,374 | Epoch: [20][ 10/191]	Time   0.58 (  0.91)	Data 0.0001 (0.3216)	Loss (EDL) 4.295 (4.270)
2023-05-20 18:07:03,013 | Epoch: [20][ 20/191]	Time   0.55 (  0.75)	Data 0.0001 (0.1686)	Loss (EDL) 4.262 (4.278)
2023-05-20 18:07:08,603 | Epoch: [20][ 30/191]	Time   0.55 (  0.69)	Data 0.0008 (0.1143)	Loss (EDL) 4.370 (4.296)
2023-05-20 18:07:14,290 | Epoch: [20][ 40/191]	Time   0.58 (  0.66)	Data 0.0002 (0.0865)	Loss (EDL) 4.355 (4.294)
2023-05-20 18:07:19,943 | Epoch: [20][ 50/191]	Time   0.55 (  0.64)	Data 0.0002 (0.0696)	Loss (EDL) 4.324 (4.284)
2023-05-20 18:07:25,492 | Epoch: [20][ 60/191]	Time   0.56 (  0.63)	Data 0.0003 (0.0582)	Loss (EDL) 4.140 (4.292)
2023-05-20 18:07:31,118 | Epoch: [20][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0500)	Loss (EDL) 4.254 (4.304)
2023-05-20 18:07:37,212 | Epoch: [20][ 80/191]	Time   0.58 (  0.62)	Data 0.0002 (0.0439)	Loss (EDL) 4.383 (4.301)
2023-05-20 18:07:42,727 | Epoch: [20][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0391)	Loss (EDL) 4.466 (4.308)
2023-05-20 18:07:48,400 | Epoch: [20][100/191]	Time   0.59 (  0.60)	Data 0.0002 (0.0353)	Loss (EDL) 4.786 (4.317)
2023-05-20 18:07:54,079 | Epoch: [20][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0321)	Loss (EDL) 4.600 (4.316)
2023-05-20 18:07:59,630 | Epoch: [20][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0295)	Loss (EDL) 4.496 (4.332)
2023-05-20 18:08:05,219 | Epoch: [20][130/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0272)	Loss (EDL) 5.030 (4.351)
2023-05-20 18:08:10,771 | Epoch: [20][140/191]	Time   0.59 (  0.59)	Data 0.0002 (0.0253)	Loss (EDL) 4.665 (4.363)
2023-05-20 18:08:16,350 | Epoch: [20][150/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0237)	Loss (EDL) 4.453 (4.367)
2023-05-20 18:08:22,202 | Epoch: [20][160/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0222)	Loss (EDL) 4.324 (4.366)
2023-05-20 18:08:27,785 | Epoch: [20][170/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0209)	Loss (EDL) 4.315 (4.364)
2023-05-20 18:08:33,314 | Epoch: [20][180/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0198)	Loss (EDL) 4.117 (4.363)
2023-05-20 18:08:38,680 | Epoch: [20][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0187)	Loss (EDL) 4.414 (4.361)
2023-05-20 18:08:39,006 | Create Epoch [20] features of all training data...
2023-05-20 18:09:08,552 | Updated smoothed statistics on Epoch [20]!
2023-05-20 18:09:08,618 | Updated running statistics with Epoch [20] features!
2023-05-20 18:09:12,306 | Val: [ 0/34]	Time  3.429 ( 3.429)	Loss (L1) 8.264 (8.264)	Loss (EDL) 4.288 (4.288)	Loss (NIG_NLL) 3.849 (3.849)	Loss (NIG_Reg) 43.908 (43.908)
2023-05-20 18:09:13,499 | Val: [10/34]	Time  0.101 ( 0.420)	Loss (L1) 8.406 (8.760)	Loss (EDL) 4.319 (4.333)	Loss (NIG_NLL) 3.873 (3.868)	Loss (NIG_Reg) 44.656 (46.509)
2023-05-20 18:09:14,505 | Val: [20/34]	Time  0.100 ( 0.268)	Loss (L1) 9.885 (8.754)	Loss (EDL) 4.533 (4.341)	Loss (NIG_NLL) 4.009 (3.876)	Loss (NIG_Reg) 52.447 (46.474)
2023-05-20 18:09:15,517 | Val: [30/34]	Time  0.101 ( 0.214)	Loss (L1) 10.600 (8.859)	Loss (EDL) 4.574 (4.355)	Loss (NIG_NLL) 4.012 (3.885)	Loss (NIG_Reg) 56.229 (47.030)
2023-05-20 18:09:16,141 |  * Overall: MSE 127.914	L1 8.789	G-Mean 5.651	EDL 4.343	NIG_NLL 3.876	NIG_Reg 46.658
2023-05-20 18:09:16,141 |  * Many: MSE 105.922	L1 7.975	G-Mean 5.071	EDL 4.190	NIG_NLL 3.766	NIG_Reg 42.344
2023-05-20 18:09:16,141 |  * Median: MSE 161.199	L1 10.192	G-Mean 6.997	EDL 4.623	NIG_NLL 4.082	NIG_Reg 54.073
2023-05-20 18:09:16,141 |  * Low: MSE 243.572	L1 12.598	G-Mean 8.715	EDL 5.014	NIG_NLL 4.345	NIG_Reg 66.892
2023-05-20 18:09:16,141 | Best EDL Loss: 8.789
2023-05-20 18:09:16,145 | ===> Saving current best checkpoint...
2023-05-20 18:09:23,342 | Epoch #20: Train loss [4.3611]; Val loss: MSE [127.9144], L1 [8.7894], G-Mean [5.6512], EDL [4.3427], NIG_NLL [3.876], NIG_Reg [46.658]
2023-05-20 18:09:23,343 | this_lr: 
2023-05-20 18:09:23,343 | 0.001
2023-05-20 18:09:27,306 | Epoch: [21][  0/191]	Time   3.96 (  3.96)	Data 3.0447 (3.0447)	Loss (EDL) 4.077 (4.077)
2023-05-20 18:09:32,869 | Epoch: [21][ 10/191]	Time   0.54 (  0.87)	Data 0.0001 (0.2770)	Loss (EDL) 4.298 (4.234)
2023-05-20 18:09:38,490 | Epoch: [21][ 20/191]	Time   0.55 (  0.72)	Data 0.0001 (0.1452)	Loss (EDL) 4.336 (4.253)
2023-05-20 18:09:44,054 | Epoch: [21][ 30/191]	Time   0.56 (  0.67)	Data 0.0001 (0.0984)	Loss (EDL) 4.354 (4.261)
2023-05-20 18:09:49,722 | Epoch: [21][ 40/191]	Time   0.57 (  0.64)	Data 0.0001 (0.0745)	Loss (EDL) 4.893 (4.312)
2023-05-20 18:09:55,342 | Epoch: [21][ 50/191]	Time   0.55 (  0.63)	Data 0.0001 (0.0599)	Loss (EDL) 4.439 (4.325)
2023-05-20 18:10:01,152 | Epoch: [21][ 60/191]	Time   0.59 (  0.62)	Data 0.0002 (0.0501)	Loss (EDL) 4.222 (4.315)
2023-05-20 18:10:06,822 | Epoch: [21][ 70/191]	Time   0.55 (  0.61)	Data 0.0003 (0.0431)	Loss (EDL) 4.140 (4.309)
2023-05-20 18:10:12,463 | Epoch: [21][ 80/191]	Time   0.61 (  0.61)	Data 0.0002 (0.0378)	Loss (EDL) 4.472 (4.316)
2023-05-20 18:10:18,073 | Epoch: [21][ 90/191]	Time   0.57 (  0.60)	Data 0.0005 (0.0337)	Loss (EDL) 4.619 (4.311)
2023-05-20 18:10:23,772 | Epoch: [21][100/191]	Time   0.60 (  0.60)	Data 0.0003 (0.0304)	Loss (EDL) 4.493 (4.318)
2023-05-20 18:10:29,402 | Epoch: [21][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0277)	Loss (EDL) 4.171 (4.316)
2023-05-20 18:10:35,010 | Epoch: [21][120/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0254)	Loss (EDL) 4.108 (4.309)
2023-05-20 18:10:41,078 | Epoch: [21][130/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0235)	Loss (EDL) 4.108 (4.315)
2023-05-20 18:10:46,615 | Epoch: [21][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0218)	Loss (EDL) 3.738 (4.309)
2023-05-20 18:10:52,097 | Epoch: [21][150/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0204)	Loss (EDL) 3.950 (4.311)
2023-05-20 18:10:57,570 | Epoch: [21][160/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0191)	Loss (EDL) 4.729 (4.314)
2023-05-20 18:11:03,079 | Epoch: [21][170/191]	Time   0.57 (  0.58)	Data 0.0001 (0.0180)	Loss (EDL) 4.620 (4.311)
2023-05-20 18:11:08,622 | Epoch: [21][180/191]	Time   0.55 (  0.58)	Data 0.0002 (0.0170)	Loss (EDL) 4.405 (4.305)
2023-05-20 18:11:14,048 | Epoch: [21][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0162)	Loss (EDL) 4.107 (4.305)
2023-05-20 18:11:14,400 | Create Epoch [21] features of all training data...
2023-05-20 18:11:43,908 | Updated smoothed statistics on Epoch [21]!
2023-05-20 18:11:43,974 | Updated running statistics with Epoch [21] features!
2023-05-20 18:11:47,758 | Val: [ 0/34]	Time  3.445 ( 3.445)	Loss (L1) 8.096 (8.096)	Loss (EDL) 4.261 (4.261)	Loss (NIG_NLL) 3.831 (3.831)	Loss (NIG_Reg) 43.035 (43.035)
2023-05-20 18:11:49,059 | Val: [10/34]	Time  0.106 ( 0.431)	Loss (L1) 8.688 (8.603)	Loss (EDL) 4.328 (4.317)	Loss (NIG_NLL) 3.867 (3.860)	Loss (NIG_Reg) 46.141 (45.678)
2023-05-20 18:11:50,066 | Val: [20/34]	Time  0.101 ( 0.274)	Loss (L1) 10.047 (8.725)	Loss (EDL) 4.557 (4.346)	Loss (NIG_NLL) 4.024 (3.883)	Loss (NIG_Reg) 53.306 (46.319)
2023-05-20 18:11:51,072 | Val: [30/34]	Time  0.100 ( 0.218)	Loss (L1) 9.814 (8.631)	Loss (EDL) 4.436 (4.324)	Loss (NIG_NLL) 3.915 (3.866)	Loss (NIG_Reg) 52.073 (45.820)
2023-05-20 18:11:51,720 |  * Overall: MSE 120.693	L1 8.576	G-Mean 5.679	EDL 4.313	NIG_NLL 3.858	NIG_Reg 45.532
2023-05-20 18:11:51,720 |  * Many: MSE 103.818	L1 7.977	G-Mean 5.345	EDL 4.177	NIG_NLL 3.754	NIG_Reg 42.350
2023-05-20 18:11:51,720 |  * Median: MSE 131.498	L1 9.064	G-Mean 5.897	EDL 4.490	NIG_NLL 4.009	NIG_Reg 48.092
2023-05-20 18:11:51,720 |  * Low: MSE 250.194	L1 12.894	G-Mean 9.079	EDL 5.103	NIG_NLL 4.418	NIG_Reg 68.504
2023-05-20 18:11:51,721 | Best EDL Loss: 8.576
2023-05-20 18:11:51,725 | ===> Saving current best checkpoint...
2023-05-20 18:11:58,652 | Epoch #21: Train loss [4.3049]; Val loss: MSE [120.6934], L1 [8.5765], G-Mean [5.6793], EDL [4.3129], NIG_NLL [3.858], NIG_Reg [45.532]
2023-05-20 18:11:58,653 | this_lr: 
2023-05-20 18:11:58,653 | 0.001
2023-05-20 18:12:02,943 | Epoch: [22][  0/191]	Time   4.29 (  4.29)	Data 3.2436 (3.2436)	Loss (EDL) 4.291 (4.291)
2023-05-20 18:12:08,553 | Epoch: [22][ 10/191]	Time   0.55 (  0.90)	Data 0.0001 (0.2951)	Loss (EDL) 4.317 (4.332)
2023-05-20 18:12:14,324 | Epoch: [22][ 20/191]	Time   0.55 (  0.75)	Data 0.0001 (0.1547)	Loss (EDL) 4.201 (4.295)
2023-05-20 18:12:19,901 | Epoch: [22][ 30/191]	Time   0.57 (  0.69)	Data 0.0001 (0.1048)	Loss (EDL) 4.644 (4.288)
2023-05-20 18:12:25,550 | Epoch: [22][ 40/191]	Time   0.55 (  0.66)	Data 0.0001 (0.0793)	Loss (EDL) 4.431 (4.274)
2023-05-20 18:12:31,153 | Epoch: [22][ 50/191]	Time   0.58 (  0.64)	Data 0.0001 (0.0638)	Loss (EDL) 4.183 (4.267)
2023-05-20 18:12:36,739 | Epoch: [22][ 60/191]	Time   0.55 (  0.62)	Data 0.0001 (0.0534)	Loss (EDL) 4.296 (4.265)
2023-05-20 18:12:42,367 | Epoch: [22][ 70/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0459)	Loss (EDL) 4.032 (4.269)
2023-05-20 18:12:48,167 | Epoch: [22][ 80/191]	Time   0.76 (  0.61)	Data 0.0002 (0.0403)	Loss (EDL) 4.404 (4.272)
2023-05-20 18:12:53,839 | Epoch: [22][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0359)	Loss (EDL) 4.803 (4.281)
2023-05-20 18:12:59,538 | Epoch: [22][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0323)	Loss (EDL) 3.879 (4.269)
2023-05-20 18:13:05,105 | Epoch: [22][110/191]	Time   0.54 (  0.60)	Data 0.0003 (0.0295)	Loss (EDL) 4.358 (4.273)
2023-05-20 18:13:10,792 | Epoch: [22][120/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0270)	Loss (EDL) 4.503 (4.274)
2023-05-20 18:13:16,462 | Epoch: [22][130/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0250)	Loss (EDL) 4.243 (4.274)
2023-05-20 18:13:21,995 | Epoch: [22][140/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0232)	Loss (EDL) 4.544 (4.274)
2023-05-20 18:13:27,492 | Epoch: [22][150/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0217)	Loss (EDL) 4.165 (4.271)
2023-05-20 18:13:33,050 | Epoch: [22][160/191]	Time   0.53 (  0.59)	Data 0.0002 (0.0204)	Loss (EDL) 4.350 (4.273)
2023-05-20 18:13:38,801 | Epoch: [22][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0192)	Loss (EDL) 4.179 (4.278)
2023-05-20 18:13:44,314 | Epoch: [22][180/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0181)	Loss (EDL) 4.485 (4.282)
2023-05-20 18:13:49,735 | Epoch: [22][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0172)	Loss (EDL) 4.236 (4.283)
2023-05-20 18:13:50,070 | Create Epoch [22] features of all training data...
2023-05-20 18:14:19,417 | Updated smoothed statistics on Epoch [22]!
2023-05-20 18:14:19,489 | Updated running statistics with Epoch [22] features!
2023-05-20 18:14:23,316 | Val: [ 0/34]	Time  3.548 ( 3.548)	Loss (L1) 8.315 (8.315)	Loss (EDL) 4.299 (4.299)	Loss (NIG_NLL) 3.857 (3.857)	Loss (NIG_Reg) 44.154 (44.154)
2023-05-20 18:14:24,325 | Val: [10/34]	Time  0.101 ( 0.414)	Loss (L1) 9.389 (9.011)	Loss (EDL) 4.441 (4.379)	Loss (NIG_NLL) 3.943 (3.901)	Loss (NIG_Reg) 49.823 (47.813)
2023-05-20 18:14:25,330 | Val: [20/34]	Time  0.100 ( 0.265)	Loss (L1) 11.244 (9.312)	Loss (EDL) 4.710 (4.433)	Loss (NIG_NLL) 4.114 (3.939)	Loss (NIG_Reg) 59.620 (49.408)
2023-05-20 18:14:26,334 | Val: [30/34]	Time  0.100 ( 0.212)	Loss (L1) 10.066 (9.337)	Loss (EDL) 4.494 (4.437)	Loss (NIG_NLL) 3.961 (3.942)	Loss (NIG_Reg) 53.371 (49.540)
2023-05-20 18:14:26,969 |  * Overall: MSE 139.358	L1 9.290	G-Mean 6.054	EDL 4.430	NIG_NLL 3.937	NIG_Reg 49.289
2023-05-20 18:14:26,969 |  * Many: MSE 98.298	L1 7.838	G-Mean 5.090	EDL 4.181	NIG_NLL 3.765	NIG_Reg 41.596
2023-05-20 18:14:26,969 |  * Median: MSE 207.186	L1 12.004	G-Mean 8.610	EDL 4.908	NIG_NLL 4.272	NIG_Reg 63.659
2023-05-20 18:14:26,969 |  * Low: MSE 339.565	L1 15.496	G-Mean 11.769	EDL 5.459	NIG_NLL 4.637	NIG_Reg 82.214
2023-05-20 18:14:26,970 | Best EDL Loss: 8.576
2023-05-20 18:14:26,974 | Epoch #22: Train loss [4.2829]; Val loss: MSE [139.3578], L1 [9.2899], G-Mean [6.0545], EDL [4.4301], NIG_NLL [3.937], NIG_Reg [49.289]
2023-05-20 18:14:26,974 | this_lr: 
2023-05-20 18:14:26,974 | 0.001
2023-05-20 18:14:31,603 | Epoch: [23][  0/191]	Time   4.63 (  4.63)	Data 3.6795 (3.6795)	Loss (EDL) 4.444 (4.444)
2023-05-20 18:14:37,190 | Epoch: [23][ 10/191]	Time   0.54 (  0.93)	Data 0.0001 (0.3347)	Loss (EDL) 4.133 (4.166)
2023-05-20 18:14:42,786 | Epoch: [23][ 20/191]	Time   0.54 (  0.75)	Data 0.0001 (0.1754)	Loss (EDL) 4.215 (4.192)
2023-05-20 18:14:48,358 | Epoch: [23][ 30/191]	Time   0.56 (  0.69)	Data 0.0001 (0.1189)	Loss (EDL) 4.212 (4.172)
2023-05-20 18:14:53,947 | Epoch: [23][ 40/191]	Time   0.55 (  0.66)	Data 0.0001 (0.0899)	Loss (EDL) 4.317 (4.180)
2023-05-20 18:14:59,516 | Epoch: [23][ 50/191]	Time   0.56 (  0.64)	Data 0.0001 (0.0723)	Loss (EDL) 4.232 (4.165)
2023-05-20 18:15:05,122 | Epoch: [23][ 60/191]	Time   0.55 (  0.63)	Data 0.0002 (0.0605)	Loss (EDL) 3.744 (4.170)
2023-05-20 18:15:10,991 | Epoch: [23][ 70/191]	Time   0.53 (  0.62)	Data 0.0001 (0.0520)	Loss (EDL) 4.123 (4.190)
2023-05-20 18:15:16,637 | Epoch: [23][ 80/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0456)	Loss (EDL) 4.109 (4.210)
2023-05-20 18:15:22,266 | Epoch: [23][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0406)	Loss (EDL) 4.272 (4.205)
2023-05-20 18:15:27,909 | Epoch: [23][100/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0366)	Loss (EDL) 4.830 (4.218)
2023-05-20 18:15:33,528 | Epoch: [23][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0333)	Loss (EDL) 4.576 (4.227)
2023-05-20 18:15:39,159 | Epoch: [23][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0306)	Loss (EDL) 4.363 (4.231)
2023-05-20 18:15:44,802 | Epoch: [23][130/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0283)	Loss (EDL) 5.279 (4.246)
2023-05-20 18:15:50,693 | Epoch: [23][140/191]	Time   0.92 (  0.59)	Data 0.0001 (0.0263)	Loss (EDL) 4.012 (4.247)
2023-05-20 18:15:56,138 | Epoch: [23][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0246)	Loss (EDL) 4.297 (4.239)
2023-05-20 18:16:01,638 | Epoch: [23][160/191]	Time   0.58 (  0.59)	Data 0.0001 (0.0231)	Loss (EDL) 4.332 (4.240)
2023-05-20 18:16:07,151 | Epoch: [23][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0217)	Loss (EDL) 4.144 (4.241)
2023-05-20 18:16:12,593 | Epoch: [23][180/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0205)	Loss (EDL) 4.232 (4.252)
2023-05-20 18:16:17,986 | Epoch: [23][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0195)	Loss (EDL) 4.262 (4.253)
2023-05-20 18:16:18,301 | Create Epoch [23] features of all training data...
2023-05-20 18:16:47,366 | Updated smoothed statistics on Epoch [23]!
2023-05-20 18:16:47,433 | Updated running statistics with Epoch [23] features!
2023-05-20 18:16:51,078 | Val: [ 0/34]	Time  3.342 ( 3.342)	Loss (L1) 8.254 (8.254)	Loss (EDL) 4.274 (4.274)	Loss (NIG_NLL) 3.835 (3.835)	Loss (NIG_Reg) 43.865 (43.865)
2023-05-20 18:16:52,368 | Val: [10/34]	Time  0.101 ( 0.421)	Loss (L1) 8.770 (8.689)	Loss (EDL) 4.378 (4.327)	Loss (NIG_NLL) 3.912 (3.866)	Loss (NIG_Reg) 46.560 (46.121)
2023-05-20 18:16:53,379 | Val: [20/34]	Time  0.100 ( 0.269)	Loss (L1) 10.138 (8.674)	Loss (EDL) 4.563 (4.332)	Loss (NIG_NLL) 4.025 (3.872)	Loss (NIG_Reg) 53.772 (46.037)
2023-05-20 18:16:54,386 | Val: [30/34]	Time  0.100 ( 0.215)	Loss (L1) 9.450 (8.634)	Loss (EDL) 4.413 (4.324)	Loss (NIG_NLL) 3.911 (3.866)	Loss (NIG_Reg) 50.115 (45.821)
2023-05-20 18:16:55,044 |  * Overall: MSE 121.134	L1 8.550	G-Mean 5.453	EDL 4.309	NIG_NLL 3.856	NIG_Reg 45.374
2023-05-20 18:16:55,044 |  * Many: MSE 96.212	L1 7.569	G-Mean 4.798	EDL 4.135	NIG_NLL 3.733	NIG_Reg 40.176
2023-05-20 18:16:55,044 |  * Median: MSE 155.983	L1 10.101	G-Mean 6.834	EDL 4.614	NIG_NLL 4.078	NIG_Reg 53.582
2023-05-20 18:16:55,044 |  * Low: MSE 260.146	L1 13.518	G-Mean 9.788	EDL 5.114	NIG_NLL 4.396	NIG_Reg 71.761
2023-05-20 18:16:55,045 | Best EDL Loss: 8.550
2023-05-20 18:16:55,049 | ===> Saving current best checkpoint...
2023-05-20 18:17:02,105 | Epoch #23: Train loss [4.2535]; Val loss: MSE [121.1345], L1 [8.5495], G-Mean [5.4533], EDL [4.3093], NIG_NLL [3.856], NIG_Reg [45.374]
2023-05-20 18:17:02,107 | this_lr: 
2023-05-20 18:17:02,107 | 0.001
2023-05-20 18:17:06,063 | Epoch: [24][  0/191]	Time   3.95 (  3.95)	Data 2.9747 (2.9747)	Loss (EDL) 4.712 (4.712)
2023-05-20 18:17:11,698 | Epoch: [24][ 10/191]	Time   0.58 (  0.87)	Data 0.0001 (0.2706)	Loss (EDL) 4.263 (4.336)
2023-05-20 18:17:17,314 | Epoch: [24][ 20/191]	Time   0.56 (  0.72)	Data 0.0002 (0.1419)	Loss (EDL) 4.787 (4.326)
2023-05-20 18:17:22,948 | Epoch: [24][ 30/191]	Time   0.58 (  0.67)	Data 0.0002 (0.0962)	Loss (EDL) 4.457 (4.351)
2023-05-20 18:17:29,036 | Epoch: [24][ 40/191]	Time   0.58 (  0.66)	Data 0.0002 (0.0728)	Loss (EDL) 4.104 (4.313)
2023-05-20 18:17:34,640 | Epoch: [24][ 50/191]	Time   0.56 (  0.64)	Data 0.0002 (0.0586)	Loss (EDL) 4.086 (4.274)
2023-05-20 18:17:40,341 | Epoch: [24][ 60/191]	Time   0.58 (  0.63)	Data 0.0001 (0.0490)	Loss (EDL) 4.447 (4.265)
2023-05-20 18:17:46,053 | Epoch: [24][ 70/191]	Time   0.57 (  0.62)	Data 0.0005 (0.0422)	Loss (EDL) 4.129 (4.264)
2023-05-20 18:17:51,792 | Epoch: [24][ 80/191]	Time   0.58 (  0.61)	Data 0.0003 (0.0370)	Loss (EDL) 4.040 (4.264)
2023-05-20 18:17:57,435 | Epoch: [24][ 90/191]	Time   0.56 (  0.61)	Data 0.0003 (0.0330)	Loss (EDL) 4.375 (4.268)
2023-05-20 18:18:03,070 | Epoch: [24][100/191]	Time   0.56 (  0.60)	Data 0.0003 (0.0298)	Loss (EDL) 4.100 (4.259)
2023-05-20 18:18:09,179 | Epoch: [24][110/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0271)	Loss (EDL) 3.906 (4.253)
2023-05-20 18:18:14,870 | Epoch: [24][120/191]	Time   0.58 (  0.60)	Data 0.0003 (0.0249)	Loss (EDL) 4.243 (4.247)
2023-05-20 18:18:20,546 | Epoch: [24][130/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0230)	Loss (EDL) 4.026 (4.235)
2023-05-20 18:18:26,035 | Epoch: [24][140/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0214)	Loss (EDL) 4.085 (4.235)
2023-05-20 18:18:31,526 | Epoch: [24][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0200)	Loss (EDL) 4.043 (4.243)
2023-05-20 18:18:37,013 | Epoch: [24][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0188)	Loss (EDL) 4.421 (4.254)
2023-05-20 18:18:42,531 | Epoch: [24][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0177)	Loss (EDL) 4.140 (4.254)
2023-05-20 18:18:48,008 | Epoch: [24][180/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0167)	Loss (EDL) 4.144 (4.248)
2023-05-20 18:18:53,729 | Epoch: [24][190/191]	Time   0.46 (  0.58)	Data 0.0002 (0.0158)	Loss (EDL) 4.380 (4.244)
2023-05-20 18:18:54,072 | Create Epoch [24] features of all training data...
2023-05-20 18:19:23,499 | Updated smoothed statistics on Epoch [24]!
2023-05-20 18:19:23,565 | Updated running statistics with Epoch [24] features!
2023-05-20 18:19:27,151 | Val: [ 0/34]	Time  3.271 ( 3.271)	Loss (L1) 8.454 (8.454)	Loss (EDL) 4.376 (4.376)	Loss (NIG_NLL) 3.926 (3.926)	Loss (NIG_Reg) 45.025 (45.025)
2023-05-20 18:19:28,326 | Val: [10/34]	Time  0.102 ( 0.404)	Loss (L1) 9.162 (8.526)	Loss (EDL) 4.389 (4.300)	Loss (NIG_NLL) 3.903 (3.847)	Loss (NIG_Reg) 48.661 (45.291)
2023-05-20 18:19:29,331 | Val: [20/34]	Time  0.101 ( 0.260)	Loss (L1) 9.872 (8.583)	Loss (EDL) 4.547 (4.312)	Loss (NIG_NLL) 4.023 (3.857)	Loss (NIG_Reg) 52.385 (45.582)
2023-05-20 18:19:30,336 | Val: [30/34]	Time  0.101 ( 0.208)	Loss (L1) 9.431 (8.563)	Loss (EDL) 4.398 (4.306)	Loss (NIG_NLL) 3.897 (3.852)	Loss (NIG_Reg) 50.029 (45.474)
2023-05-20 18:19:30,969 |  * Overall: MSE 119.642	L1 8.496	G-Mean 5.501	EDL 4.291	NIG_NLL 3.840	NIG_Reg 45.117
2023-05-20 18:19:30,970 |  * Many: MSE 97.135	L1 7.652	G-Mean 4.935	EDL 4.115	NIG_NLL 3.709	NIG_Reg 40.643
2023-05-20 18:19:30,970 |  * Median: MSE 150.491	L1 9.810	G-Mean 6.601	EDL 4.600	NIG_NLL 4.079	NIG_Reg 52.056
2023-05-20 18:19:30,970 |  * Low: MSE 246.898	L1 12.830	G-Mean 9.253	EDL 5.100	NIG_NLL 4.418	NIG_Reg 68.179
2023-05-20 18:19:30,971 | Best EDL Loss: 8.496
2023-05-20 18:19:30,974 | ===> Saving current best checkpoint...
2023-05-20 18:19:37,959 | Epoch #24: Train loss [4.2443]; Val loss: MSE [119.6419], L1 [8.4956], G-Mean [5.5006], EDL [4.2910], NIG_NLL [3.840], NIG_Reg [45.117]
2023-05-20 18:19:37,960 | this_lr: 
2023-05-20 18:19:37,960 | 0.001
2023-05-20 18:19:42,255 | Epoch: [25][  0/191]	Time   4.29 (  4.29)	Data 3.4638 (3.4638)	Loss (EDL) 4.166 (4.166)
2023-05-20 18:19:47,907 | Epoch: [25][ 10/191]	Time   0.54 (  0.90)	Data 0.0002 (0.3151)	Loss (EDL) 4.405 (4.255)
2023-05-20 18:19:53,457 | Epoch: [25][ 20/191]	Time   0.54 (  0.74)	Data 0.0001 (0.1651)	Loss (EDL) 4.155 (4.268)
2023-05-20 18:19:58,987 | Epoch: [25][ 30/191]	Time   0.56 (  0.68)	Data 0.0001 (0.1119)	Loss (EDL) 4.351 (4.257)
2023-05-20 18:20:04,730 | Epoch: [25][ 40/191]	Time   0.58 (  0.65)	Data 0.0001 (0.0847)	Loss (EDL) 4.216 (4.278)
2023-05-20 18:20:10,426 | Epoch: [25][ 50/191]	Time   0.56 (  0.64)	Data 0.0002 (0.0681)	Loss (EDL) 4.084 (4.246)
2023-05-20 18:20:15,909 | Epoch: [25][ 60/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0570)	Loss (EDL) 4.128 (4.241)
2023-05-20 18:20:21,486 | Epoch: [25][ 70/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0490)	Loss (EDL) 4.009 (4.237)
2023-05-20 18:20:27,057 | Epoch: [25][ 80/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0430)	Loss (EDL) 4.337 (4.238)
2023-05-20 18:20:32,887 | Epoch: [25][ 90/191]	Time   0.79 (  0.60)	Data 0.0002 (0.0383)	Loss (EDL) 4.548 (4.251)
2023-05-20 18:20:38,497 | Epoch: [25][100/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0345)	Loss (EDL) 4.349 (4.249)
2023-05-20 18:20:44,066 | Epoch: [25][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0314)	Loss (EDL) 4.152 (4.246)
2023-05-20 18:20:49,695 | Epoch: [25][120/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0288)	Loss (EDL) 3.973 (4.245)
2023-05-20 18:20:55,230 | Epoch: [25][130/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0267)	Loss (EDL) 4.261 (4.244)
2023-05-20 18:21:00,649 | Epoch: [25][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0248)	Loss (EDL) 3.861 (4.233)
2023-05-20 18:21:06,123 | Epoch: [25][150/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0232)	Loss (EDL) 4.153 (4.230)
2023-05-20 18:21:11,599 | Epoch: [25][160/191]	Time   0.55 (  0.58)	Data 0.0002 (0.0217)	Loss (EDL) 4.125 (4.232)
2023-05-20 18:21:17,414 | Epoch: [25][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0205)	Loss (EDL) 3.878 (4.231)
2023-05-20 18:21:22,884 | Epoch: [25][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0194)	Loss (EDL) 4.308 (4.232)
2023-05-20 18:21:28,298 | Epoch: [25][190/191]	Time   0.47 (  0.58)	Data 0.0002 (0.0184)	Loss (EDL) 4.410 (4.230)
2023-05-20 18:21:28,609 | Create Epoch [25] features of all training data...
2023-05-20 18:21:58,149 | Updated smoothed statistics on Epoch [25]!
2023-05-20 18:21:58,215 | Updated running statistics with Epoch [25] features!
2023-05-20 18:22:01,799 | Val: [ 0/34]	Time  3.322 ( 3.322)	Loss (L1) 8.010 (8.010)	Loss (EDL) 4.253 (4.253)	Loss (NIG_NLL) 3.828 (3.828)	Loss (NIG_Reg) 42.555 (42.555)
2023-05-20 18:22:03,104 | Val: [10/34]	Time  0.100 ( 0.421)	Loss (L1) 9.838 (8.769)	Loss (EDL) 4.510 (4.358)	Loss (NIG_NLL) 3.987 (3.893)	Loss (NIG_Reg) 52.236 (46.552)
2023-05-20 18:22:04,114 | Val: [20/34]	Time  0.101 ( 0.268)	Loss (L1) 11.396 (9.133)	Loss (EDL) 4.767 (4.414)	Loss (NIG_NLL) 4.163 (3.929)	Loss (NIG_Reg) 60.447 (48.479)
2023-05-20 18:22:05,126 | Val: [30/34]	Time  0.102 ( 0.214)	Loss (L1) 10.935 (9.068)	Loss (EDL) 4.646 (4.408)	Loss (NIG_NLL) 4.066 (3.927)	Loss (NIG_Reg) 57.999 (48.135)
2023-05-20 18:22:05,788 |  * Overall: MSE 135.062	L1 9.017	G-Mean 5.851	EDL 4.395	NIG_NLL 3.916	NIG_Reg 47.864
2023-05-20 18:22:05,788 |  * Many: MSE 98.785	L1 7.687	G-Mean 4.969	EDL 4.138	NIG_NLL 3.730	NIG_Reg 40.807
2023-05-20 18:22:05,788 |  * Median: MSE 213.189	L1 11.904	G-Mean 8.359	EDL 4.955	NIG_NLL 4.323	NIG_Reg 63.157
2023-05-20 18:22:05,788 |  * Low: MSE 261.620	L1 13.598	G-Mean 10.195	EDL 5.279	NIG_NLL 4.557	NIG_Reg 72.225
2023-05-20 18:22:05,789 | Best EDL Loss: 8.496
2023-05-20 18:22:05,793 | Epoch #25: Train loss [4.2301]; Val loss: MSE [135.0616], L1 [9.0173], G-Mean [5.8506], EDL [4.3951], NIG_NLL [3.916], NIG_Reg [47.864]
2023-05-20 18:22:05,793 | this_lr: 
2023-05-20 18:22:05,793 | 0.001
2023-05-20 18:22:10,523 | Epoch: [26][  0/191]	Time   4.73 (  4.73)	Data 3.7358 (3.7358)	Loss (EDL) 4.282 (4.282)
2023-05-20 18:22:16,140 | Epoch: [26][ 10/191]	Time   0.57 (  0.94)	Data 0.0003 (0.3398)	Loss (EDL) 3.924 (4.133)
2023-05-20 18:22:21,647 | Epoch: [26][ 20/191]	Time   0.56 (  0.75)	Data 0.0002 (0.1781)	Loss (EDL) 4.094 (4.185)
2023-05-20 18:22:27,306 | Epoch: [26][ 30/191]	Time   0.58 (  0.69)	Data 0.0001 (0.1207)	Loss (EDL) 4.112 (4.175)
2023-05-20 18:22:32,942 | Epoch: [26][ 40/191]	Time   0.56 (  0.66)	Data 0.0001 (0.0913)	Loss (EDL) 4.172 (4.178)
2023-05-20 18:22:38,625 | Epoch: [26][ 50/191]	Time   0.57 (  0.64)	Data 0.0002 (0.0735)	Loss (EDL) 4.140 (4.173)
2023-05-20 18:22:44,304 | Epoch: [26][ 60/191]	Time   0.56 (  0.63)	Data 0.0004 (0.0615)	Loss (EDL) 4.055 (4.193)
2023-05-20 18:22:49,886 | Epoch: [26][ 70/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0528)	Loss (EDL) 3.942 (4.196)
2023-05-20 18:22:55,758 | Epoch: [26][ 80/191]	Time   0.54 (  0.62)	Data 0.0002 (0.0463)	Loss (EDL) 4.224 (4.199)
2023-05-20 18:23:01,397 | Epoch: [26][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0413)	Loss (EDL) 4.212 (4.207)
2023-05-20 18:23:06,957 | Epoch: [26][100/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0372)	Loss (EDL) 3.997 (4.205)
2023-05-20 18:23:12,667 | Epoch: [26][110/191]	Time   0.57 (  0.60)	Data 0.0001 (0.0339)	Loss (EDL) 4.100 (4.208)
2023-05-20 18:23:18,303 | Epoch: [26][120/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0311)	Loss (EDL) 4.024 (4.209)
2023-05-20 18:23:23,905 | Epoch: [26][130/191]	Time   0.53 (  0.60)	Data 0.0001 (0.0287)	Loss (EDL) 4.515 (4.213)
2023-05-20 18:23:29,406 | Epoch: [26][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0267)	Loss (EDL) 4.222 (4.215)
2023-05-20 18:23:35,131 | Epoch: [26][150/191]	Time   0.82 (  0.59)	Data 0.0001 (0.0250)	Loss (EDL) 4.180 (4.223)
2023-05-20 18:23:40,579 | Epoch: [26][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0234)	Loss (EDL) 4.176 (4.231)
2023-05-20 18:23:45,992 | Epoch: [26][170/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0221)	Loss (EDL) 4.273 (4.235)
2023-05-20 18:23:51,465 | Epoch: [26][180/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0209)	Loss (EDL) 3.906 (4.231)
2023-05-20 18:23:56,839 | Epoch: [26][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0198)	Loss (EDL) 4.428 (4.233)
2023-05-20 18:23:57,158 | Create Epoch [26] features of all training data...
2023-05-20 18:24:26,598 | Updated smoothed statistics on Epoch [26]!
2023-05-20 18:24:26,680 | Updated running statistics with Epoch [26] features!
2023-05-20 18:24:30,446 | Val: [ 0/34]	Time  3.471 ( 3.471)	Loss (L1) 8.171 (8.171)	Loss (EDL) 4.234 (4.234)	Loss (NIG_NLL) 3.800 (3.800)	Loss (NIG_Reg) 43.399 (43.399)
2023-05-20 18:24:31,543 | Val: [10/34]	Time  0.101 ( 0.415)	Loss (L1) 8.466 (8.243)	Loss (EDL) 4.265 (4.265)	Loss (NIG_NLL) 3.816 (3.827)	Loss (NIG_Reg) 44.948 (43.751)
2023-05-20 18:24:32,554 | Val: [20/34]	Time  0.101 ( 0.266)	Loss (L1) 9.939 (8.427)	Loss (EDL) 4.530 (4.292)	Loss (NIG_NLL) 4.002 (3.845)	Loss (NIG_Reg) 52.717 (44.725)
2023-05-20 18:24:33,569 | Val: [30/34]	Time  0.104 ( 0.213)	Loss (L1) 9.602 (8.365)	Loss (EDL) 4.436 (4.279)	Loss (NIG_NLL) 3.927 (3.835)	Loss (NIG_Reg) 50.924 (44.392)
2023-05-20 18:24:34,200 |  * Overall: MSE 114.434	L1 8.322	G-Mean 5.324	EDL 4.269	NIG_NLL 3.828	NIG_Reg 44.163
2023-05-20 18:24:34,200 |  * Many: MSE 89.112	L1 7.301	G-Mean 4.648	EDL 4.069	NIG_NLL 3.682	NIG_Reg 38.757
2023-05-20 18:24:34,200 |  * Median: MSE 154.670	L1 10.040	G-Mean 6.804	EDL 4.643	NIG_NLL 4.110	NIG_Reg 53.253
2023-05-20 18:24:34,200 |  * Low: MSE 242.313	L1 13.207	G-Mean 9.729	EDL 5.126	NIG_NLL 4.425	NIG_Reg 70.079
2023-05-20 18:24:34,201 | Best EDL Loss: 8.322
2023-05-20 18:24:34,204 | ===> Saving current best checkpoint...
2023-05-20 18:24:41,243 | Epoch #26: Train loss [4.2335]; Val loss: MSE [114.4336], L1 [8.3216], G-Mean [5.3235], EDL [4.2693], NIG_NLL [3.828], NIG_Reg [44.163]
2023-05-20 18:24:41,244 | this_lr: 
2023-05-20 18:24:41,245 | 0.001
2023-05-20 18:24:45,313 | Epoch: [27][  0/191]	Time   4.06 (  4.06)	Data 3.0712 (3.0712)	Loss (EDL) 3.915 (3.915)
2023-05-20 18:24:50,974 | Epoch: [27][ 10/191]	Time   0.55 (  0.88)	Data 0.0002 (0.2795)	Loss (EDL) 4.010 (4.153)
2023-05-20 18:24:56,544 | Epoch: [27][ 20/191]	Time   0.55 (  0.73)	Data 0.0001 (0.1465)	Loss (EDL) 3.811 (4.112)
2023-05-20 18:25:02,270 | Epoch: [27][ 30/191]	Time   0.56 (  0.68)	Data 0.0001 (0.0993)	Loss (EDL) 4.595 (4.168)
2023-05-20 18:25:07,888 | Epoch: [27][ 40/191]	Time   0.56 (  0.65)	Data 0.0002 (0.0752)	Loss (EDL) 4.253 (4.178)
2023-05-20 18:25:13,705 | Epoch: [27][ 50/191]	Time   0.53 (  0.64)	Data 0.0001 (0.0605)	Loss (EDL) 4.327 (4.180)
2023-05-20 18:25:19,345 | Epoch: [27][ 60/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0506)	Loss (EDL) 4.281 (4.179)
2023-05-20 18:25:24,915 | Epoch: [27][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0435)	Loss (EDL) 4.614 (4.191)
2023-05-20 18:25:30,518 | Epoch: [27][ 80/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0382)	Loss (EDL) 4.290 (4.199)
2023-05-20 18:25:36,127 | Epoch: [27][ 90/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0340)	Loss (EDL) 4.504 (4.197)
2023-05-20 18:25:41,645 | Epoch: [27][100/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0307)	Loss (EDL) 4.060 (4.191)
2023-05-20 18:25:47,284 | Epoch: [27][110/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0279)	Loss (EDL) 3.934 (4.188)
2023-05-20 18:25:52,972 | Epoch: [27][120/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0256)	Loss (EDL) 4.391 (4.185)
2023-05-20 18:25:58,815 | Epoch: [27][130/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0237)	Loss (EDL) 4.302 (4.179)
2023-05-20 18:26:04,293 | Epoch: [27][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0220)	Loss (EDL) 4.423 (4.184)
2023-05-20 18:26:09,784 | Epoch: [27][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0206)	Loss (EDL) 4.236 (4.188)
2023-05-20 18:26:15,219 | Epoch: [27][160/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0193)	Loss (EDL) 4.560 (4.192)
2023-05-20 18:26:20,672 | Epoch: [27][170/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0182)	Loss (EDL) 4.144 (4.194)
2023-05-20 18:26:26,148 | Epoch: [27][180/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0172)	Loss (EDL) 4.162 (4.198)
2023-05-20 18:26:31,583 | Epoch: [27][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0163)	Loss (EDL) 4.140 (4.196)
2023-05-20 18:26:31,919 | Create Epoch [27] features of all training data...
2023-05-20 18:27:01,565 | Updated smoothed statistics on Epoch [27]!
2023-05-20 18:27:01,672 | Updated running statistics with Epoch [27] features!
2023-05-20 18:27:05,604 | Val: [ 0/34]	Time  3.627 ( 3.627)	Loss (L1) 8.343 (8.343)	Loss (EDL) 4.323 (4.323)	Loss (NIG_NLL) 3.880 (3.880)	Loss (NIG_Reg) 44.350 (44.350)
2023-05-20 18:27:06,610 | Val: [10/34]	Time  0.100 ( 0.421)	Loss (L1) 7.976 (8.034)	Loss (EDL) 4.217 (4.218)	Loss (NIG_NLL) 3.793 (3.791)	Loss (NIG_Reg) 42.339 (42.651)
2023-05-20 18:27:07,616 | Val: [20/34]	Time  0.101 ( 0.269)	Loss (L1) 9.400 (8.210)	Loss (EDL) 4.441 (4.251)	Loss (NIG_NLL) 3.942 (3.816)	Loss (NIG_Reg) 49.866 (43.583)
2023-05-20 18:27:08,626 | Val: [30/34]	Time  0.102 ( 0.214)	Loss (L1) 9.618 (8.264)	Loss (EDL) 4.405 (4.260)	Loss (NIG_NLL) 3.895 (3.822)	Loss (NIG_Reg) 51.022 (43.870)
2023-05-20 18:27:09,282 |  * Overall: MSE 110.728	L1 8.206	G-Mean 5.357	EDL 4.250	NIG_NLL 3.815	NIG_Reg 43.559
2023-05-20 18:27:09,282 |  * Many: MSE 98.770	L1 7.706	G-Mean 4.943	EDL 4.133	NIG_NLL 3.724	NIG_Reg 40.910
2023-05-20 18:27:09,282 |  * Median: MSE 116.037	L1 8.589	G-Mean 5.910	EDL 4.397	NIG_NLL 3.941	NIG_Reg 45.579
2023-05-20 18:27:09,282 |  * Low: MSE 208.990	L1 11.858	G-Mean 8.741	EDL 4.950	NIG_NLL 4.320	NIG_Reg 62.981
2023-05-20 18:27:09,282 | Best EDL Loss: 8.206
2023-05-20 18:27:09,285 | ===> Saving current best checkpoint...
2023-05-20 18:27:16,273 | Epoch #27: Train loss [4.1958]; Val loss: MSE [110.7282], L1 [8.2056], G-Mean [5.3575], EDL [4.2503], NIG_NLL [3.815], NIG_Reg [43.559]
2023-05-20 18:27:16,274 | this_lr: 
2023-05-20 18:27:16,274 | 0.001
2023-05-20 18:27:20,564 | Epoch: [28][  0/191]	Time   4.29 (  4.29)	Data 3.3323 (3.3323)	Loss (EDL) 4.126 (4.126)
2023-05-20 18:27:26,509 | Epoch: [28][ 10/191]	Time   0.87 (  0.93)	Data 0.0002 (0.3031)	Loss (EDL) 4.019 (4.098)
2023-05-20 18:27:32,091 | Epoch: [28][ 20/191]	Time   0.56 (  0.75)	Data 0.0001 (0.1589)	Loss (EDL) 4.627 (4.157)
2023-05-20 18:27:37,732 | Epoch: [28][ 30/191]	Time   0.55 (  0.69)	Data 0.0003 (0.1077)	Loss (EDL) 4.351 (4.173)
2023-05-20 18:27:43,390 | Epoch: [28][ 40/191]	Time   0.54 (  0.66)	Data 0.0003 (0.0816)	Loss (EDL) 4.061 (4.172)
2023-05-20 18:27:49,060 | Epoch: [28][ 50/191]	Time   0.56 (  0.64)	Data 0.0003 (0.0657)	Loss (EDL) 3.853 (4.165)
2023-05-20 18:27:54,750 | Epoch: [28][ 60/191]	Time   0.60 (  0.63)	Data 0.0002 (0.0549)	Loss (EDL) 4.317 (4.168)
2023-05-20 18:28:00,404 | Epoch: [28][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0472)	Loss (EDL) 5.112 (4.181)
2023-05-20 18:28:06,440 | Epoch: [28][ 80/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0414)	Loss (EDL) 4.497 (4.184)
2023-05-20 18:28:12,122 | Epoch: [28][ 90/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0369)	Loss (EDL) 4.241 (4.195)
2023-05-20 18:28:17,795 | Epoch: [28][100/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0333)	Loss (EDL) 4.686 (4.195)
2023-05-20 18:28:23,545 | Epoch: [28][110/191]	Time   0.61 (  0.61)	Data 0.0002 (0.0303)	Loss (EDL) 4.217 (4.186)
2023-05-20 18:28:29,201 | Epoch: [28][120/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0279)	Loss (EDL) 4.064 (4.177)
2023-05-20 18:28:34,721 | Epoch: [28][130/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0257)	Loss (EDL) 4.127 (4.176)
2023-05-20 18:28:40,231 | Epoch: [28][140/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0239)	Loss (EDL) 4.386 (4.182)
2023-05-20 18:28:45,694 | Epoch: [28][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0224)	Loss (EDL) 4.139 (4.187)
2023-05-20 18:28:51,415 | Epoch: [28][160/191]	Time   0.53 (  0.59)	Data 0.0002 (0.0210)	Loss (EDL) 4.138 (4.187)
2023-05-20 18:28:56,866 | Epoch: [28][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0198)	Loss (EDL) 4.370 (4.188)
2023-05-20 18:29:02,386 | Epoch: [28][180/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0187)	Loss (EDL) 4.191 (4.191)
2023-05-20 18:29:07,794 | Epoch: [28][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0177)	Loss (EDL) 4.343 (4.193)
2023-05-20 18:29:08,151 | Create Epoch [28] features of all training data...
2023-05-20 18:29:37,952 | Updated smoothed statistics on Epoch [28]!
2023-05-20 18:29:38,018 | Updated running statistics with Epoch [28] features!
2023-05-20 18:29:41,883 | Val: [ 0/34]	Time  3.554 ( 3.554)	Loss (L1) 8.917 (8.917)	Loss (EDL) 4.415 (4.415)	Loss (NIG_NLL) 3.941 (3.941)	Loss (NIG_Reg) 47.319 (47.319)
2023-05-20 18:29:43,034 | Val: [10/34]	Time  0.100 ( 0.428)	Loss (L1) 8.986 (8.886)	Loss (EDL) 4.391 (4.374)	Loss (NIG_NLL) 3.915 (3.903)	Loss (NIG_Reg) 47.664 (47.133)
2023-05-20 18:29:44,040 | Val: [20/34]	Time  0.100 ( 0.272)	Loss (L1) 10.484 (9.124)	Loss (EDL) 4.649 (4.416)	Loss (NIG_NLL) 4.093 (3.932)	Loss (NIG_Reg) 55.590 (48.389)
2023-05-20 18:29:45,047 | Val: [30/34]	Time  0.100 ( 0.217)	Loss (L1) 10.644 (9.089)	Loss (EDL) 4.610 (4.407)	Loss (NIG_NLL) 4.045 (3.925)	Loss (NIG_Reg) 56.447 (48.204)
2023-05-20 18:29:45,679 |  * Overall: MSE 131.638	L1 9.003	G-Mean 5.824	EDL 4.391	NIG_NLL 3.914	NIG_Reg 47.747
2023-05-20 18:29:45,680 |  * Many: MSE 99.506	L1 7.792	G-Mean 4.985	EDL 4.170	NIG_NLL 3.757	NIG_Reg 41.327
2023-05-20 18:29:45,680 |  * Median: MSE 170.931	L1 10.929	G-Mean 7.931	EDL 4.759	NIG_NLL 4.180	NIG_Reg 57.957
2023-05-20 18:29:45,680 |  * Low: MSE 326.446	L1 15.109	G-Mean 10.783	EDL 5.465	NIG_NLL 4.664	NIG_Reg 80.147
2023-05-20 18:29:45,681 | Best EDL Loss: 8.206
2023-05-20 18:29:45,685 | Epoch #28: Train loss [4.1929]; Val loss: MSE [131.6382], L1 [9.0026], G-Mean [5.8240], EDL [4.3914], NIG_NLL [3.914], NIG_Reg [47.747]
2023-05-20 18:29:45,685 | this_lr: 
2023-05-20 18:29:45,685 | 0.001
2023-05-20 18:29:50,140 | Epoch: [29][  0/191]	Time   4.45 (  4.45)	Data 3.4638 (3.4638)	Loss (EDL) 4.517 (4.517)
2023-05-20 18:29:55,671 | Epoch: [29][ 10/191]	Time   0.56 (  0.91)	Data 0.0005 (0.3151)	Loss (EDL) 4.077 (4.183)
2023-05-20 18:30:01,250 | Epoch: [29][ 20/191]	Time   0.57 (  0.74)	Data 0.0001 (0.1652)	Loss (EDL) 4.258 (4.175)
2023-05-20 18:30:06,928 | Epoch: [29][ 30/191]	Time   0.56 (  0.69)	Data 0.0001 (0.1119)	Loss (EDL) 4.119 (4.166)
2023-05-20 18:30:12,546 | Epoch: [29][ 40/191]	Time   0.56 (  0.66)	Data 0.0002 (0.0847)	Loss (EDL) 4.220 (4.152)
2023-05-20 18:30:18,124 | Epoch: [29][ 50/191]	Time   0.56 (  0.64)	Data 0.0001 (0.0681)	Loss (EDL) 4.547 (4.157)
2023-05-20 18:30:23,953 | Epoch: [29][ 60/191]	Time   0.55 (  0.63)	Data 0.0002 (0.0570)	Loss (EDL) 4.145 (4.157)
2023-05-20 18:30:29,535 | Epoch: [29][ 70/191]	Time   0.54 (  0.62)	Data 0.0002 (0.0490)	Loss (EDL) 4.048 (4.154)
2023-05-20 18:30:35,139 | Epoch: [29][ 80/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0430)	Loss (EDL) 4.099 (4.148)
2023-05-20 18:30:40,710 | Epoch: [29][ 90/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0383)	Loss (EDL) 4.207 (4.136)
2023-05-20 18:30:46,282 | Epoch: [29][100/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0345)	Loss (EDL) 4.098 (4.132)
2023-05-20 18:30:51,881 | Epoch: [29][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0314)	Loss (EDL) 4.170 (4.146)
2023-05-20 18:30:57,502 | Epoch: [29][120/191]	Time   0.57 (  0.59)	Data 0.0002 (0.0289)	Loss (EDL) 4.138 (4.142)
2023-05-20 18:31:03,338 | Epoch: [29][130/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0267)	Loss (EDL) 4.164 (4.139)
2023-05-20 18:31:08,839 | Epoch: [29][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0248)	Loss (EDL) 4.160 (4.150)
2023-05-20 18:31:14,293 | Epoch: [29][150/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0232)	Loss (EDL) 3.883 (4.148)
2023-05-20 18:31:19,731 | Epoch: [29][160/191]	Time   0.53 (  0.58)	Data 0.0002 (0.0217)	Loss (EDL) 4.261 (4.145)
2023-05-20 18:31:25,190 | Epoch: [29][170/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0205)	Loss (EDL) 4.300 (4.146)
2023-05-20 18:31:30,629 | Epoch: [29][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0194)	Loss (EDL) 4.042 (4.138)
2023-05-20 18:31:35,968 | Epoch: [29][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0183)	Loss (EDL) 4.285 (4.140)
2023-05-20 18:31:36,322 | Create Epoch [29] features of all training data...
2023-05-20 18:32:06,007 | Updated smoothed statistics on Epoch [29]!
2023-05-20 18:32:06,074 | Updated running statistics with Epoch [29] features!
2023-05-20 18:32:09,898 | Val: [ 0/34]	Time  3.523 ( 3.523)	Loss (L1) 9.816 (9.816)	Loss (EDL) 4.525 (4.525)	Loss (NIG_NLL) 4.004 (4.004)	Loss (NIG_Reg) 52.116 (52.116)
2023-05-20 18:32:11,242 | Val: [10/34]	Time  0.101 ( 0.442)	Loss (L1) 8.160 (8.762)	Loss (EDL) 4.268 (4.341)	Loss (NIG_NLL) 3.835 (3.876)	Loss (NIG_Reg) 43.290 (46.494)
2023-05-20 18:32:12,246 | Val: [20/34]	Time  0.100 ( 0.280)	Loss (L1) 9.837 (8.889)	Loss (EDL) 4.529 (4.368)	Loss (NIG_NLL) 4.007 (3.896)	Loss (NIG_Reg) 52.166 (47.159)
2023-05-20 18:32:13,252 | Val: [30/34]	Time  0.100 ( 0.222)	Loss (L1) 10.392 (8.872)	Loss (EDL) 4.584 (4.364)	Loss (NIG_NLL) 4.033 (3.894)	Loss (NIG_Reg) 55.107 (47.070)
2023-05-20 18:32:13,919 |  * Overall: MSE 127.788	L1 8.844	G-Mean 5.743	EDL 4.359	NIG_NLL 3.890	NIG_Reg 46.923
2023-05-20 18:32:13,920 |  * Many: MSE 95.808	L1 7.616	G-Mean 4.883	EDL 4.134	NIG_NLL 3.730	NIG_Reg 40.417
2023-05-20 18:32:13,920 |  * Median: MSE 187.771	L1 11.360	G-Mean 8.216	EDL 4.832	NIG_NLL 4.230	NIG_Reg 60.238
2023-05-20 18:32:13,920 |  * Low: MSE 263.938	L1 13.487	G-Mean 9.869	EDL 5.169	NIG_NLL 4.454	NIG_Reg 71.549
2023-05-20 18:32:13,921 | Best EDL Loss: 8.206
2023-05-20 18:32:13,924 | Epoch #29: Train loss [4.1395]; Val loss: MSE [127.7881], L1 [8.8445], G-Mean [5.7429], EDL [4.3587], NIG_NLL [3.890], NIG_Reg [46.923]
2023-05-20 18:32:13,925 | this_lr: 
2023-05-20 18:32:13,925 | 0.001
2023-05-20 18:32:18,687 | Epoch: [30][  0/191]	Time   4.76 (  4.76)	Data 3.8665 (3.8665)	Loss (EDL) 4.107 (4.107)
2023-05-20 18:32:24,354 | Epoch: [30][ 10/191]	Time   0.54 (  0.95)	Data 0.0001 (0.3517)	Loss (EDL) 4.327 (4.091)
2023-05-20 18:32:30,077 | Epoch: [30][ 20/191]	Time   0.57 (  0.77)	Data 0.0001 (0.1843)	Loss (EDL) 4.304 (4.075)
2023-05-20 18:32:35,654 | Epoch: [30][ 30/191]	Time   0.61 (  0.70)	Data 0.0002 (0.1249)	Loss (EDL) 4.084 (4.081)
2023-05-20 18:32:41,274 | Epoch: [30][ 40/191]	Time   0.55 (  0.67)	Data 0.0002 (0.0945)	Loss (EDL) 4.227 (4.126)
2023-05-20 18:32:46,825 | Epoch: [30][ 50/191]	Time   0.56 (  0.65)	Data 0.0001 (0.0760)	Loss (EDL) 4.625 (4.132)
2023-05-20 18:32:52,405 | Epoch: [30][ 60/191]	Time   0.55 (  0.63)	Data 0.0002 (0.0636)	Loss (EDL) 3.971 (4.133)
2023-05-20 18:32:57,996 | Epoch: [30][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0547)	Loss (EDL) 4.266 (4.127)
2023-05-20 18:33:04,283 | Epoch: [30][ 80/191]	Time   1.19 (  0.62)	Data 0.0002 (0.0479)	Loss (EDL) 4.137 (4.130)
2023-05-20 18:33:09,944 | Epoch: [30][ 90/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0427)	Loss (EDL) 4.001 (4.133)
2023-05-20 18:33:15,682 | Epoch: [30][100/191]	Time   0.57 (  0.61)	Data 0.0008 (0.0385)	Loss (EDL) 3.976 (4.125)
2023-05-20 18:33:21,398 | Epoch: [30][110/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0351)	Loss (EDL) 4.150 (4.130)
2023-05-20 18:33:27,153 | Epoch: [30][120/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0322)	Loss (EDL) 4.042 (4.140)
2023-05-20 18:33:32,724 | Epoch: [30][130/191]	Time   0.53 (  0.60)	Data 0.0001 (0.0297)	Loss (EDL) 4.226 (4.144)
2023-05-20 18:33:38,240 | Epoch: [30][140/191]	Time   0.56 (  0.60)	Data 0.0001 (0.0276)	Loss (EDL) 4.197 (4.153)
2023-05-20 18:33:43,712 | Epoch: [30][150/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0258)	Loss (EDL) 4.089 (4.152)
2023-05-20 18:33:49,686 | Epoch: [30][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0242)	Loss (EDL) 4.290 (4.156)
2023-05-20 18:33:55,167 | Epoch: [30][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0228)	Loss (EDL) 4.380 (4.157)
2023-05-20 18:34:00,711 | Epoch: [30][180/191]	Time   0.61 (  0.59)	Data 0.0002 (0.0216)	Loss (EDL) 3.901 (4.153)
2023-05-20 18:34:06,169 | Epoch: [30][190/191]	Time   0.46 (  0.59)	Data 0.0001 (0.0205)	Loss (EDL) 3.852 (4.149)
2023-05-20 18:34:06,512 | Create Epoch [30] features of all training data...
2023-05-20 18:34:36,560 | Updated smoothed statistics on Epoch [30]!
2023-05-20 18:34:36,640 | Updated running statistics with Epoch [30] features!
2023-05-20 18:34:40,304 | Val: [ 0/34]	Time  3.317 ( 3.317)	Loss (L1) 8.608 (8.608)	Loss (EDL) 4.331 (4.331)	Loss (NIG_NLL) 3.874 (3.874)	Loss (NIG_Reg) 45.696 (45.696)
2023-05-20 18:34:41,640 | Val: [10/34]	Time  0.100 ( 0.423)	Loss (L1) 8.536 (8.363)	Loss (EDL) 4.332 (4.293)	Loss (NIG_NLL) 3.879 (3.849)	Loss (NIG_Reg) 45.300 (44.376)
2023-05-20 18:34:42,644 | Val: [20/34]	Time  0.100 ( 0.269)	Loss (L1) 9.502 (8.452)	Loss (EDL) 4.486 (4.319)	Loss (NIG_NLL) 3.982 (3.871)	Loss (NIG_Reg) 50.393 (44.845)
2023-05-20 18:34:43,654 | Val: [30/34]	Time  0.100 ( 0.215)	Loss (L1) 10.170 (8.561)	Loss (EDL) 4.554 (4.339)	Loss (NIG_NLL) 4.015 (3.884)	Loss (NIG_Reg) 53.935 (45.424)
2023-05-20 18:34:44,283 |  * Overall: MSE 116.338	L1 8.497	G-Mean 5.596	EDL 4.326	NIG_NLL 3.875	NIG_Reg 45.080
2023-05-20 18:34:44,283 |  * Many: MSE 90.899	L1 7.505	G-Mean 4.926	EDL 4.124	NIG_NLL 3.726	NIG_Reg 39.825
2023-05-20 18:34:44,283 |  * Median: MSE 159.117	L1 10.206	G-Mean 6.975	EDL 4.696	NIG_NLL 4.154	NIG_Reg 54.127
2023-05-20 18:34:44,283 |  * Low: MSE 238.294	L1 13.133	G-Mean 10.146	EDL 5.201	NIG_NLL 4.504	NIG_Reg 69.688
2023-05-20 18:34:44,284 | Best EDL Loss: 8.206
2023-05-20 18:34:44,288 | Epoch #30: Train loss [4.1493]; Val loss: MSE [116.3383], L1 [8.4965], G-Mean [5.5960], EDL [4.3256], NIG_NLL [3.875], NIG_Reg [45.080]
2023-05-20 18:34:44,289 | this_lr: 
2023-05-20 18:34:44,289 | 0.001
2023-05-20 18:34:49,039 | Epoch: [31][  0/191]	Time   4.75 (  4.75)	Data 3.8522 (3.8522)	Loss (EDL) 4.040 (4.040)
2023-05-20 18:34:54,649 | Epoch: [31][ 10/191]	Time   0.56 (  0.94)	Data 0.0001 (0.3504)	Loss (EDL) 3.862 (4.051)
2023-05-20 18:35:00,175 | Epoch: [31][ 20/191]	Time   0.54 (  0.76)	Data 0.0001 (0.1836)	Loss (EDL) 3.996 (4.051)
2023-05-20 18:35:05,818 | Epoch: [31][ 30/191]	Time   0.56 (  0.69)	Data 0.0001 (0.1245)	Loss (EDL) 3.928 (4.074)
2023-05-20 18:35:11,371 | Epoch: [31][ 40/191]	Time   0.55 (  0.66)	Data 0.0001 (0.0942)	Loss (EDL) 3.905 (4.073)
2023-05-20 18:35:16,957 | Epoch: [31][ 50/191]	Time   0.56 (  0.64)	Data 0.0003 (0.0757)	Loss (EDL) 3.896 (4.077)
2023-05-20 18:35:23,066 | Epoch: [31][ 60/191]	Time   0.58 (  0.64)	Data 0.0001 (0.0634)	Loss (EDL) 4.246 (4.108)
2023-05-20 18:35:28,620 | Epoch: [31][ 70/191]	Time   0.54 (  0.62)	Data 0.0002 (0.0545)	Loss (EDL) 4.130 (4.107)
2023-05-20 18:35:34,234 | Epoch: [31][ 80/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0478)	Loss (EDL) 4.387 (4.118)
2023-05-20 18:35:39,852 | Epoch: [31][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0425)	Loss (EDL) 3.911 (4.115)
2023-05-20 18:35:45,401 | Epoch: [31][100/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0384)	Loss (EDL) 4.611 (4.118)
2023-05-20 18:35:51,053 | Epoch: [31][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0349)	Loss (EDL) 4.087 (4.114)
2023-05-20 18:35:56,676 | Epoch: [31][120/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0321)	Loss (EDL) 3.952 (4.106)
2023-05-20 18:36:02,344 | Epoch: [31][130/191]	Time   0.56 (  0.60)	Data 0.0001 (0.0296)	Loss (EDL) 4.300 (4.114)
2023-05-20 18:36:08,222 | Epoch: [31][140/191]	Time   0.56 (  0.60)	Data 0.0001 (0.0276)	Loss (EDL) 4.217 (4.110)
2023-05-20 18:36:13,738 | Epoch: [31][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0257)	Loss (EDL) 4.105 (4.114)
2023-05-20 18:36:19,159 | Epoch: [31][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0242)	Loss (EDL) 4.267 (4.118)
2023-05-20 18:36:24,593 | Epoch: [31][170/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0228)	Loss (EDL) 4.061 (4.117)
2023-05-20 18:36:30,039 | Epoch: [31][180/191]	Time   0.52 (  0.58)	Data 0.0001 (0.0215)	Loss (EDL) 3.825 (4.116)
2023-05-20 18:36:35,391 | Epoch: [31][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0204)	Loss (EDL) 4.420 (4.121)
2023-05-20 18:36:35,726 | Create Epoch [31] features of all training data...
2023-05-20 18:37:05,363 | Updated smoothed statistics on Epoch [31]!
2023-05-20 18:37:05,438 | Updated running statistics with Epoch [31] features!
2023-05-20 18:37:09,245 | Val: [ 0/34]	Time  3.497 ( 3.497)	Loss (L1) 7.688 (7.688)	Loss (EDL) 4.212 (4.212)	Loss (NIG_NLL) 3.804 (3.804)	Loss (NIG_Reg) 40.804 (40.804)
2023-05-20 18:37:10,442 | Val: [10/34]	Time  0.101 ( 0.427)	Loss (L1) 8.842 (8.143)	Loss (EDL) 4.350 (4.249)	Loss (NIG_NLL) 3.881 (3.817)	Loss (NIG_Reg) 46.904 (43.198)
2023-05-20 18:37:11,448 | Val: [20/34]	Time  0.101 ( 0.271)	Loss (L1) 9.316 (8.259)	Loss (EDL) 4.464 (4.267)	Loss (NIG_NLL) 3.970 (3.829)	Loss (NIG_Reg) 49.401 (43.808)
2023-05-20 18:37:12,454 | Val: [30/34]	Time  0.100 ( 0.216)	Loss (L1) 9.573 (8.249)	Loss (EDL) 4.403 (4.260)	Loss (NIG_NLL) 3.895 (3.822)	Loss (NIG_Reg) 50.761 (43.757)
2023-05-20 18:37:13,098 |  * Overall: MSE 110.170	L1 8.169	G-Mean 5.358	EDL 4.244	NIG_NLL 3.811	NIG_Reg 43.332
2023-05-20 18:37:13,098 |  * Many: MSE 89.006	L1 7.310	G-Mean 4.758	EDL 4.067	NIG_NLL 3.679	NIG_Reg 38.776
2023-05-20 18:37:13,098 |  * Median: MSE 136.901	L1 9.492	G-Mean 6.628	EDL 4.558	NIG_NLL 4.054	NIG_Reg 50.337
2023-05-20 18:37:13,098 |  * Low: MSE 236.131	L1 12.628	G-Mean 9.140	EDL 5.052	NIG_NLL 4.382	NIG_Reg 66.993
2023-05-20 18:37:13,098 | Best EDL Loss: 8.169
2023-05-20 18:37:13,101 | ===> Saving current best checkpoint...
2023-05-20 18:37:20,277 | Epoch #31: Train loss [4.1206]; Val loss: MSE [110.1702], L1 [8.1692], G-Mean [5.3582], EDL [4.2440], NIG_NLL [3.811], NIG_Reg [43.332]
2023-05-20 18:37:20,278 | this_lr: 
2023-05-20 18:37:20,278 | 0.001
2023-05-20 18:37:24,545 | Epoch: [32][  0/191]	Time   4.26 (  4.26)	Data 3.3087 (3.3087)	Loss (EDL) 4.353 (4.353)
2023-05-20 18:37:30,255 | Epoch: [32][ 10/191]	Time   0.59 (  0.91)	Data 0.0001 (0.3010)	Loss (EDL) 3.994 (4.103)
2023-05-20 18:37:35,830 | Epoch: [32][ 20/191]	Time   0.54 (  0.74)	Data 0.0001 (0.1578)	Loss (EDL) 4.032 (4.077)
2023-05-20 18:37:41,691 | Epoch: [32][ 30/191]	Time   0.57 (  0.69)	Data 0.0002 (0.1070)	Loss (EDL) 4.170 (4.096)
2023-05-20 18:37:47,258 | Epoch: [32][ 40/191]	Time   0.57 (  0.66)	Data 0.0001 (0.0809)	Loss (EDL) 3.891 (4.103)
2023-05-20 18:37:52,944 | Epoch: [32][ 50/191]	Time   0.60 (  0.64)	Data 0.0003 (0.0651)	Loss (EDL) 4.132 (4.099)
2023-05-20 18:37:58,638 | Epoch: [32][ 60/191]	Time   0.58 (  0.63)	Data 0.0002 (0.0545)	Loss (EDL) 4.247 (4.118)
2023-05-20 18:38:04,295 | Epoch: [32][ 70/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0468)	Loss (EDL) 3.817 (4.105)
2023-05-20 18:38:09,988 | Epoch: [32][ 80/191]	Time   0.57 (  0.61)	Data 0.0005 (0.0411)	Loss (EDL) 4.156 (4.101)
2023-05-20 18:38:15,615 | Epoch: [32][ 90/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0366)	Loss (EDL) 4.037 (4.098)
2023-05-20 18:38:21,538 | Epoch: [32][100/191]	Time   0.60 (  0.61)	Data 0.0002 (0.0330)	Loss (EDL) 4.246 (4.100)
2023-05-20 18:38:27,126 | Epoch: [32][110/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0301)	Loss (EDL) 4.298 (4.108)
2023-05-20 18:38:32,729 | Epoch: [32][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0276)	Loss (EDL) 4.144 (4.110)
2023-05-20 18:38:38,331 | Epoch: [32][130/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0255)	Loss (EDL) 4.213 (4.103)
2023-05-20 18:38:43,792 | Epoch: [32][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0237)	Loss (EDL) 4.010 (4.109)
2023-05-20 18:38:49,273 | Epoch: [32][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0222)	Loss (EDL) 4.179 (4.111)
2023-05-20 18:38:54,714 | Epoch: [32][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0208)	Loss (EDL) 3.921 (4.115)
2023-05-20 18:39:00,184 | Epoch: [32][170/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0196)	Loss (EDL) 4.126 (4.117)
2023-05-20 18:39:05,931 | Epoch: [32][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0185)	Loss (EDL) 4.227 (4.120)
2023-05-20 18:39:11,302 | Epoch: [32][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0175)	Loss (EDL) 3.997 (4.122)
2023-05-20 18:39:11,616 | Create Epoch [32] features of all training data...
2023-05-20 18:39:41,448 | Updated smoothed statistics on Epoch [32]!
2023-05-20 18:39:41,521 | Updated running statistics with Epoch [32] features!
2023-05-20 18:39:45,603 | Val: [ 0/34]	Time  3.778 ( 3.778)	Loss (L1) 7.568 (7.568)	Loss (EDL) 4.167 (4.167)	Loss (NIG_NLL) 3.765 (3.765)	Loss (NIG_Reg) 40.218 (40.218)
2023-05-20 18:39:46,636 | Val: [10/34]	Time  0.100 ( 0.437)	Loss (L1) 8.073 (8.254)	Loss (EDL) 4.229 (4.259)	Loss (NIG_NLL) 3.800 (3.821)	Loss (NIG_Reg) 42.860 (43.814)
2023-05-20 18:39:47,641 | Val: [20/34]	Time  0.101 ( 0.277)	Loss (L1) 8.943 (8.322)	Loss (EDL) 4.382 (4.266)	Loss (NIG_NLL) 3.908 (3.825)	Loss (NIG_Reg) 47.426 (44.171)
2023-05-20 18:39:48,647 | Val: [30/34]	Time  0.100 ( 0.220)	Loss (L1) 9.134 (8.240)	Loss (EDL) 4.380 (4.255)	Loss (NIG_NLL) 3.896 (3.817)	Loss (NIG_Reg) 48.454 (43.733)
2023-05-20 18:39:49,317 |  * Overall: MSE 110.203	L1 8.175	G-Mean 5.324	EDL 4.242	NIG_NLL 3.808	NIG_Reg 43.391
2023-05-20 18:39:49,318 |  * Many: MSE 94.664	L1 7.599	G-Mean 4.934	EDL 4.118	NIG_NLL 3.715	NIG_Reg 40.340
2023-05-20 18:39:49,318 |  * Median: MSE 138.243	L1 9.216	G-Mean 6.108	EDL 4.481	NIG_NLL 3.992	NIG_Reg 48.885
2023-05-20 18:39:49,318 |  * Low: MSE 179.407	L1 10.741	G-Mean 7.471	EDL 4.748	NIG_NLL 4.178	NIG_Reg 57.016
2023-05-20 18:39:49,318 | Best EDL Loss: 8.169
2023-05-20 18:39:49,322 | Epoch #32: Train loss [4.1221]; Val loss: MSE [110.2025], L1 [8.1754], G-Mean [5.3238], EDL [4.2421], NIG_NLL [3.808], NIG_Reg [43.391]
2023-05-20 18:39:49,323 | this_lr: 
2023-05-20 18:39:49,323 | 0.001
2023-05-20 18:39:53,611 | Epoch: [33][  0/191]	Time   4.29 (  4.29)	Data 3.3192 (3.3192)	Loss (EDL) 4.040 (4.040)
2023-05-20 18:39:59,395 | Epoch: [33][ 10/191]	Time   0.55 (  0.92)	Data 0.0001 (0.3020)	Loss (EDL) 3.935 (4.060)
2023-05-20 18:40:05,053 | Epoch: [33][ 20/191]	Time   0.56 (  0.75)	Data 0.0001 (0.1583)	Loss (EDL) 3.949 (4.018)
2023-05-20 18:40:10,657 | Epoch: [33][ 30/191]	Time   0.57 (  0.69)	Data 0.0001 (0.1073)	Loss (EDL) 3.962 (4.033)
2023-05-20 18:40:16,274 | Epoch: [33][ 40/191]	Time   0.56 (  0.66)	Data 0.0001 (0.0812)	Loss (EDL) 4.027 (4.071)
2023-05-20 18:40:21,867 | Epoch: [33][ 50/191]	Time   0.58 (  0.64)	Data 0.0001 (0.0653)	Loss (EDL) 4.095 (4.086)
2023-05-20 18:40:27,498 | Epoch: [33][ 60/191]	Time   0.56 (  0.63)	Data 0.0001 (0.0547)	Loss (EDL) 4.035 (4.094)
2023-05-20 18:40:33,086 | Epoch: [33][ 70/191]	Time   0.56 (  0.62)	Data 0.0003 (0.0470)	Loss (EDL) 4.060 (4.107)
2023-05-20 18:40:38,956 | Epoch: [33][ 80/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0412)	Loss (EDL) 4.049 (4.101)
2023-05-20 18:40:44,598 | Epoch: [33][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0367)	Loss (EDL) 3.974 (4.103)
2023-05-20 18:40:50,195 | Epoch: [33][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0331)	Loss (EDL) 3.972 (4.103)
2023-05-20 18:40:55,752 | Epoch: [33][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0301)	Loss (EDL) 4.181 (4.102)
2023-05-20 18:41:01,506 | Epoch: [33][120/191]	Time   0.59 (  0.60)	Data 0.0003 (0.0277)	Loss (EDL) 4.151 (4.108)
2023-05-20 18:41:07,081 | Epoch: [33][130/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0256)	Loss (EDL) 4.237 (4.103)
2023-05-20 18:41:12,555 | Epoch: [33][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0238)	Loss (EDL) 4.124 (4.113)
2023-05-20 18:41:18,110 | Epoch: [33][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0222)	Loss (EDL) 4.312 (4.117)
2023-05-20 18:41:23,902 | Epoch: [33][160/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0208)	Loss (EDL) 4.360 (4.115)
2023-05-20 18:41:29,378 | Epoch: [33][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0196)	Loss (EDL) 3.790 (4.115)
2023-05-20 18:41:34,884 | Epoch: [33][180/191]	Time   0.57 (  0.58)	Data 0.0001 (0.0186)	Loss (EDL) 4.150 (4.115)
2023-05-20 18:41:40,277 | Epoch: [33][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0176)	Loss (EDL) 3.906 (4.113)
2023-05-20 18:41:40,604 | Create Epoch [33] features of all training data...
2023-05-20 18:42:10,353 | Updated smoothed statistics on Epoch [33]!
2023-05-20 18:42:10,426 | Updated running statistics with Epoch [33] features!
2023-05-20 18:42:14,015 | Val: [ 0/34]	Time  3.283 ( 3.283)	Loss (L1) 6.840 (6.840)	Loss (EDL) 3.999 (3.999)	Loss (NIG_NLL) 3.636 (3.636)	Loss (NIG_Reg) 36.315 (36.315)
2023-05-20 18:42:15,169 | Val: [10/34]	Time  0.100 ( 0.403)	Loss (L1) 8.315 (8.454)	Loss (EDL) 4.242 (4.279)	Loss (NIG_NLL) 3.801 (3.830)	Loss (NIG_Reg) 44.137 (44.865)
2023-05-20 18:42:16,176 | Val: [20/34]	Time  0.101 ( 0.259)	Loss (L1) 9.658 (8.783)	Loss (EDL) 4.507 (4.345)	Loss (NIG_NLL) 3.995 (3.879)	Loss (NIG_Reg) 51.216 (46.607)
2023-05-20 18:42:17,182 | Val: [30/34]	Time  0.100 ( 0.208)	Loss (L1) 9.685 (8.839)	Loss (EDL) 4.455 (4.358)	Loss (NIG_NLL) 3.941 (3.889)	Loss (NIG_Reg) 51.360 (46.904)
2023-05-20 18:42:17,838 |  * Overall: MSE 124.587	L1 8.776	G-Mean 5.844	EDL 4.344	NIG_NLL 3.878	NIG_Reg 46.567
2023-05-20 18:42:17,839 |  * Many: MSE 91.643	L1 7.581	G-Mean 5.127	EDL 4.127	NIG_NLL 3.725	NIG_Reg 40.242
2023-05-20 18:42:17,839 |  * Median: MSE 192.464	L1 11.393	G-Mean 8.035	EDL 4.827	NIG_NLL 4.223	NIG_Reg 60.409
2023-05-20 18:42:17,839 |  * Low: MSE 248.021	L1 12.821	G-Mean 8.341	EDL 5.058	NIG_NLL 4.378	NIG_Reg 68.022
2023-05-20 18:42:17,840 | Best EDL Loss: 8.169
2023-05-20 18:42:17,847 | Epoch #33: Train loss [4.1134]; Val loss: MSE [124.5875], L1 [8.7756], G-Mean [5.8442], EDL [4.3440], NIG_NLL [3.878], NIG_Reg [46.567]
2023-05-20 18:42:17,848 | this_lr: 
2023-05-20 18:42:17,848 | 0.001
2023-05-20 18:42:22,399 | Epoch: [34][  0/191]	Time   4.55 (  4.55)	Data 3.5983 (3.5983)	Loss (EDL) 3.889 (3.889)
2023-05-20 18:42:28,019 | Epoch: [34][ 10/191]	Time   0.58 (  0.92)	Data 0.0001 (0.3273)	Loss (EDL) 4.039 (4.060)
2023-05-20 18:42:33,808 | Epoch: [34][ 20/191]	Time   0.59 (  0.76)	Data 0.0002 (0.1715)	Loss (EDL) 4.090 (4.081)
2023-05-20 18:42:39,414 | Epoch: [34][ 30/191]	Time   0.56 (  0.70)	Data 0.0003 (0.1163)	Loss (EDL) 4.593 (4.079)
2023-05-20 18:42:45,033 | Epoch: [34][ 40/191]	Time   0.54 (  0.66)	Data 0.0001 (0.0880)	Loss (EDL) 3.843 (4.073)
2023-05-20 18:42:50,569 | Epoch: [34][ 50/191]	Time   0.54 (  0.64)	Data 0.0001 (0.0708)	Loss (EDL) 4.070 (4.070)
2023-05-20 18:42:56,432 | Epoch: [34][ 60/191]	Time   0.56 (  0.63)	Data 0.0002 (0.0592)	Loss (EDL) 3.855 (4.059)
2023-05-20 18:43:02,124 | Epoch: [34][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0509)	Loss (EDL) 4.056 (4.060)
2023-05-20 18:43:07,880 | Epoch: [34][ 80/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0447)	Loss (EDL) 3.874 (4.058)
2023-05-20 18:43:13,616 | Epoch: [34][ 90/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0398)	Loss (EDL) 4.054 (4.067)
2023-05-20 18:43:19,339 | Epoch: [34][100/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0359)	Loss (EDL) 4.253 (4.076)
2023-05-20 18:43:25,002 | Epoch: [34][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0327)	Loss (EDL) 3.663 (4.075)
2023-05-20 18:43:30,562 | Epoch: [34][120/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0300)	Loss (EDL) 4.334 (4.070)
2023-05-20 18:43:36,380 | Epoch: [34][130/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0277)	Loss (EDL) 4.252 (4.077)
2023-05-20 18:43:41,812 | Epoch: [34][140/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0258)	Loss (EDL) 4.224 (4.075)
2023-05-20 18:43:47,309 | Epoch: [34][150/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0241)	Loss (EDL) 3.945 (4.077)
2023-05-20 18:43:52,833 | Epoch: [34][160/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0226)	Loss (EDL) 3.954 (4.084)
2023-05-20 18:43:58,305 | Epoch: [34][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0213)	Loss (EDL) 3.875 (4.080)
2023-05-20 18:44:03,810 | Epoch: [34][180/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0201)	Loss (EDL) 4.213 (4.084)
2023-05-20 18:44:09,221 | Epoch: [34][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0191)	Loss (EDL) 4.051 (4.084)
2023-05-20 18:44:09,585 | Create Epoch [34] features of all training data...
2023-05-20 18:44:39,203 | Updated smoothed statistics on Epoch [34]!
2023-05-20 18:44:39,297 | Updated running statistics with Epoch [34] features!
2023-05-20 18:44:42,888 | Val: [ 0/34]	Time  3.286 ( 3.286)	Loss (L1) 8.095 (8.095)	Loss (EDL) 4.235 (4.235)	Loss (NIG_NLL) 3.805 (3.805)	Loss (NIG_Reg) 42.993 (42.993)
2023-05-20 18:44:44,279 | Val: [10/34]	Time  0.101 ( 0.425)	Loss (L1) 7.972 (8.172)	Loss (EDL) 4.230 (4.244)	Loss (NIG_NLL) 3.807 (3.810)	Loss (NIG_Reg) 42.314 (43.372)
2023-05-20 18:44:45,285 | Val: [20/34]	Time  0.100 ( 0.271)	Loss (L1) 9.289 (8.229)	Loss (EDL) 4.423 (4.258)	Loss (NIG_NLL) 3.931 (3.821)	Loss (NIG_Reg) 49.270 (43.671)
2023-05-20 18:44:46,292 | Val: [30/34]	Time  0.100 ( 0.216)	Loss (L1) 11.040 (8.241)	Loss (EDL) 4.708 (4.262)	Loss (NIG_NLL) 4.122 (3.824)	Loss (NIG_Reg) 58.563 (43.734)
2023-05-20 18:44:46,904 |  * Overall: MSE 111.304	L1 8.235	G-Mean 5.455	EDL 4.258	NIG_NLL 3.821	NIG_Reg 43.700
2023-05-20 18:44:46,904 |  * Many: MSE 89.173	L1 7.430	G-Mean 4.946	EDL 4.101	NIG_NLL 3.707	NIG_Reg 39.442
2023-05-20 18:44:46,904 |  * Median: MSE 141.382	L1 9.426	G-Mean 6.358	EDL 4.514	NIG_NLL 4.015	NIG_Reg 49.986
2023-05-20 18:44:46,904 |  * Low: MSE 237.134	L1 12.537	G-Mean 9.000	EDL 5.035	NIG_NLL 4.369	NIG_Reg 66.530
2023-05-20 18:44:46,904 | Best EDL Loss: 8.169
2023-05-20 18:44:46,908 | Epoch #34: Train loss [4.0837]; Val loss: MSE [111.3037], L1 [8.2345], G-Mean [5.4549], EDL [4.2583], NIG_NLL [3.821], NIG_Reg [43.700]
2023-05-20 18:44:46,908 | this_lr: 
2023-05-20 18:44:46,908 | 0.001
2023-05-20 18:44:51,230 | Epoch: [35][  0/191]	Time   4.32 (  4.32)	Data 3.4111 (3.4111)	Loss (EDL) 3.947 (3.947)
2023-05-20 18:44:56,868 | Epoch: [35][ 10/191]	Time   0.57 (  0.91)	Data 0.0001 (0.3103)	Loss (EDL) 3.846 (3.981)
2023-05-20 18:45:02,607 | Epoch: [35][ 20/191]	Time   0.75 (  0.75)	Data 0.0001 (0.1627)	Loss (EDL) 4.110 (4.006)
2023-05-20 18:45:08,211 | Epoch: [35][ 30/191]	Time   0.54 (  0.69)	Data 0.0002 (0.1102)	Loss (EDL) 4.073 (4.022)
2023-05-20 18:45:13,823 | Epoch: [35][ 40/191]	Time   0.56 (  0.66)	Data 0.0001 (0.0834)	Loss (EDL) 3.840 (4.019)
2023-05-20 18:45:19,421 | Epoch: [35][ 50/191]	Time   0.56 (  0.64)	Data 0.0001 (0.0671)	Loss (EDL) 3.845 (4.042)
2023-05-20 18:45:24,944 | Epoch: [35][ 60/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0561)	Loss (EDL) 3.974 (4.043)
2023-05-20 18:45:30,470 | Epoch: [35][ 70/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0482)	Loss (EDL) 4.178 (4.045)
2023-05-20 18:45:35,997 | Epoch: [35][ 80/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0423)	Loss (EDL) 3.933 (4.048)
2023-05-20 18:45:41,836 | Epoch: [35][ 90/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0377)	Loss (EDL) 4.102 (4.046)
2023-05-20 18:45:47,442 | Epoch: [35][100/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0340)	Loss (EDL) 3.937 (4.045)
2023-05-20 18:45:53,091 | Epoch: [35][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0309)	Loss (EDL) 3.891 (4.058)
2023-05-20 18:45:58,697 | Epoch: [35][120/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0284)	Loss (EDL) 4.301 (4.072)
2023-05-20 18:46:04,344 | Epoch: [35][130/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0263)	Loss (EDL) 4.361 (4.078)
2023-05-20 18:46:09,819 | Epoch: [35][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0244)	Loss (EDL) 4.516 (4.081)
2023-05-20 18:46:15,278 | Epoch: [35][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0228)	Loss (EDL) 4.390 (4.085)
2023-05-20 18:46:20,989 | Epoch: [35][160/191]	Time   0.79 (  0.58)	Data 0.0001 (0.0214)	Loss (EDL) 4.096 (4.085)
2023-05-20 18:46:26,479 | Epoch: [35][170/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0202)	Loss (EDL) 4.148 (4.088)
2023-05-20 18:46:31,990 | Epoch: [35][180/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0191)	Loss (EDL) 4.330 (4.090)
2023-05-20 18:46:37,357 | Epoch: [35][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0181)	Loss (EDL) 4.079 (4.087)
2023-05-20 18:46:37,687 | Create Epoch [35] features of all training data...
2023-05-20 18:47:07,236 | Updated smoothed statistics on Epoch [35]!
2023-05-20 18:47:07,302 | Updated running statistics with Epoch [35] features!
2023-05-20 18:47:10,813 | Val: [ 0/34]	Time  3.230 ( 3.230)	Loss (L1) 8.139 (8.139)	Loss (EDL) 4.243 (4.243)	Loss (NIG_NLL) 3.811 (3.811)	Loss (NIG_Reg) 43.215 (43.215)
2023-05-20 18:47:12,283 | Val: [10/34]	Time  0.100 ( 0.427)	Loss (L1) 8.054 (8.154)	Loss (EDL) 4.178 (4.227)	Loss (NIG_NLL) 3.750 (3.794)	Loss (NIG_Reg) 42.748 (43.269)
2023-05-20 18:47:13,291 | Val: [20/34]	Time  0.101 ( 0.272)	Loss (L1) 9.750 (8.182)	Loss (EDL) 4.531 (4.240)	Loss (NIG_NLL) 4.014 (3.806)	Loss (NIG_Reg) 51.706 (43.414)
2023-05-20 18:47:14,298 | Val: [30/34]	Time  0.101 ( 0.217)	Loss (L1) 8.946 (8.052)	Loss (EDL) 4.362 (4.221)	Loss (NIG_NLL) 3.887 (3.794)	Loss (NIG_Reg) 47.443 (42.725)
2023-05-20 18:47:14,922 |  * Overall: MSE 106.630	L1 7.971	G-Mean 5.124	EDL 4.204	NIG_NLL 3.781	NIG_Reg 42.294
2023-05-20 18:47:14,922 |  * Many: MSE 92.437	L1 7.403	G-Mean 4.686	EDL 4.069	NIG_NLL 3.677	NIG_Reg 39.280
2023-05-20 18:47:14,923 |  * Median: MSE 120.659	L1 8.536	G-Mean 5.677	EDL 4.397	NIG_NLL 3.944	NIG_Reg 45.284
2023-05-20 18:47:14,923 |  * Low: MSE 201.877	L1 11.768	G-Mean 8.981	EDL 4.944	NIG_NLL 4.320	NIG_Reg 62.485
2023-05-20 18:47:14,923 | Best EDL Loss: 7.971
2023-05-20 18:47:14,926 | ===> Saving current best checkpoint...
2023-05-20 18:47:22,248 | Epoch #35: Train loss [4.0870]; Val loss: MSE [106.6302], L1 [7.9707], G-Mean [5.1242], EDL [4.2043], NIG_NLL [3.781], NIG_Reg [42.294]
2023-05-20 18:47:22,249 | this_lr: 
2023-05-20 18:47:22,249 | 0.001
2023-05-20 18:47:25,911 | Epoch: [36][  0/191]	Time   3.66 (  3.66)	Data 2.5961 (2.5961)	Loss (EDL) 3.740 (3.740)
2023-05-20 18:47:31,573 | Epoch: [36][ 10/191]	Time   0.59 (  0.85)	Data 0.0002 (0.2363)	Loss (EDL) 4.259 (4.039)
2023-05-20 18:47:37,175 | Epoch: [36][ 20/191]	Time   0.57 (  0.71)	Data 0.0002 (0.1239)	Loss (EDL) 3.804 (4.028)
2023-05-20 18:47:42,813 | Epoch: [36][ 30/191]	Time   0.58 (  0.66)	Data 0.0001 (0.0840)	Loss (EDL) 4.227 (4.033)
2023-05-20 18:47:48,427 | Epoch: [36][ 40/191]	Time   0.56 (  0.64)	Data 0.0001 (0.0636)	Loss (EDL) 4.150 (4.054)
2023-05-20 18:47:54,099 | Epoch: [36][ 50/191]	Time   0.57 (  0.62)	Data 0.0001 (0.0512)	Loss (EDL) 4.149 (4.067)
2023-05-20 18:47:59,929 | Epoch: [36][ 60/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0428)	Loss (EDL) 3.928 (4.070)
2023-05-20 18:48:05,526 | Epoch: [36][ 70/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0368)	Loss (EDL) 3.996 (4.063)
2023-05-20 18:48:11,087 | Epoch: [36][ 80/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0323)	Loss (EDL) 3.903 (4.047)
2023-05-20 18:48:16,719 | Epoch: [36][ 90/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0288)	Loss (EDL) 4.049 (4.057)
2023-05-20 18:48:22,422 | Epoch: [36][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0259)	Loss (EDL) 4.078 (4.057)
2023-05-20 18:48:28,085 | Epoch: [36][110/191]	Time   0.58 (  0.59)	Data 0.0002 (0.0236)	Loss (EDL) 4.116 (4.059)
2023-05-20 18:48:33,789 | Epoch: [36][120/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0217)	Loss (EDL) 4.151 (4.076)
2023-05-20 18:48:39,537 | Epoch: [36][130/191]	Time   0.77 (  0.59)	Data 0.0001 (0.0201)	Loss (EDL) 4.527 (4.082)
2023-05-20 18:48:45,066 | Epoch: [36][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0187)	Loss (EDL) 4.210 (4.082)
2023-05-20 18:48:50,600 | Epoch: [36][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0174)	Loss (EDL) 4.098 (4.085)
2023-05-20 18:48:56,078 | Epoch: [36][160/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0164)	Loss (EDL) 3.826 (4.084)
2023-05-20 18:49:01,615 | Epoch: [36][170/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0154)	Loss (EDL) 4.181 (4.084)
2023-05-20 18:49:07,090 | Epoch: [36][180/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0146)	Loss (EDL) 3.935 (4.084)
2023-05-20 18:49:12,442 | Epoch: [36][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0138)	Loss (EDL) 3.965 (4.083)
2023-05-20 18:49:12,740 | Create Epoch [36] features of all training data...
2023-05-20 18:49:42,079 | Updated smoothed statistics on Epoch [36]!
2023-05-20 18:49:42,156 | Updated running statistics with Epoch [36] features!
2023-05-20 18:49:46,009 | Val: [ 0/34]	Time  3.564 ( 3.564)	Loss (L1) 7.620 (7.620)	Loss (EDL) 4.191 (4.191)	Loss (NIG_NLL) 3.787 (3.787)	Loss (NIG_Reg) 40.453 (40.453)
2023-05-20 18:49:47,307 | Val: [10/34]	Time  0.100 ( 0.442)	Loss (L1) 8.314 (8.064)	Loss (EDL) 4.269 (4.232)	Loss (NIG_NLL) 3.828 (3.804)	Loss (NIG_Reg) 44.116 (42.784)
2023-05-20 18:49:48,312 | Val: [20/34]	Time  0.102 ( 0.279)	Loss (L1) 9.612 (8.261)	Loss (EDL) 4.511 (4.273)	Loss (NIG_NLL) 4.002 (3.835)	Loss (NIG_Reg) 50.974 (43.830)
2023-05-20 18:49:49,322 | Val: [30/34]	Time  0.101 ( 0.222)	Loss (L1) 9.228 (8.212)	Loss (EDL) 4.405 (4.261)	Loss (NIG_NLL) 3.916 (3.826)	Loss (NIG_Reg) 48.949 (43.570)
2023-05-20 18:49:49,956 |  * Overall: MSE 109.583	L1 8.115	G-Mean 5.209	EDL 4.242	NIG_NLL 3.812	NIG_Reg 43.055
2023-05-20 18:49:49,956 |  * Many: MSE 96.237	L1 7.589	G-Mean 4.907	EDL 4.123	NIG_NLL 3.720	NIG_Reg 40.272
2023-05-20 18:49:49,956 |  * Median: MSE 123.506	L1 8.725	G-Mean 5.613	EDL 4.424	NIG_NLL 3.961	NIG_Reg 46.271
2023-05-20 18:49:49,956 |  * Low: MSE 197.122	L1 11.394	G-Mean 7.446	EDL 4.867	NIG_NLL 4.263	NIG_Reg 60.445
2023-05-20 18:49:49,957 | Best EDL Loss: 7.971
2023-05-20 18:49:49,961 | Epoch #36: Train loss [4.0830]; Val loss: MSE [109.5830], L1 [8.1151], G-Mean [5.2090], EDL [4.2424], NIG_NLL [3.812], NIG_Reg [43.055]
2023-05-20 18:49:49,961 | this_lr: 
2023-05-20 18:49:49,961 | 0.001
2023-05-20 18:49:54,674 | Epoch: [37][  0/191]	Time   4.71 (  4.71)	Data 3.7275 (3.7275)	Loss (EDL) 4.121 (4.121)
2023-05-20 18:50:00,224 | Epoch: [37][ 10/191]	Time   0.55 (  0.93)	Data 0.0001 (0.3390)	Loss (EDL) 3.791 (4.144)
2023-05-20 18:50:05,813 | Epoch: [37][ 20/191]	Time   0.58 (  0.75)	Data 0.0002 (0.1777)	Loss (EDL) 3.945 (4.079)
2023-05-20 18:50:11,673 | Epoch: [37][ 30/191]	Time   0.55 (  0.70)	Data 0.0003 (0.1205)	Loss (EDL) 4.065 (4.058)
2023-05-20 18:50:17,365 | Epoch: [37][ 40/191]	Time   0.57 (  0.67)	Data 0.0001 (0.0912)	Loss (EDL) 4.027 (4.042)
2023-05-20 18:50:23,039 | Epoch: [37][ 50/191]	Time   0.56 (  0.65)	Data 0.0002 (0.0733)	Loss (EDL) 4.051 (4.065)
2023-05-20 18:50:28,696 | Epoch: [37][ 60/191]	Time   0.58 (  0.63)	Data 0.0001 (0.0613)	Loss (EDL) 4.188 (4.099)
2023-05-20 18:50:34,334 | Epoch: [37][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0527)	Loss (EDL) 3.971 (4.089)
2023-05-20 18:50:39,926 | Epoch: [37][ 80/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0463)	Loss (EDL) 4.097 (4.089)
2023-05-20 18:50:45,555 | Epoch: [37][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0412)	Loss (EDL) 4.030 (4.096)
2023-05-20 18:50:51,470 | Epoch: [37][100/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0371)	Loss (EDL) 3.971 (4.093)
2023-05-20 18:50:57,166 | Epoch: [37][110/191]	Time   0.60 (  0.61)	Data 0.0002 (0.0338)	Loss (EDL) 4.095 (4.084)
2023-05-20 18:51:02,771 | Epoch: [37][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0311)	Loss (EDL) 3.881 (4.080)
2023-05-20 18:51:08,399 | Epoch: [37][130/191]	Time   0.57 (  0.60)	Data 0.0001 (0.0287)	Loss (EDL) 4.223 (4.083)
2023-05-20 18:51:13,846 | Epoch: [37][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0267)	Loss (EDL) 4.181 (4.088)
2023-05-20 18:51:19,325 | Epoch: [37][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0249)	Loss (EDL) 4.161 (4.082)
2023-05-20 18:51:24,786 | Epoch: [37][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0234)	Loss (EDL) 4.011 (4.077)
2023-05-20 18:51:30,270 | Epoch: [37][170/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0220)	Loss (EDL) 3.835 (4.071)
2023-05-20 18:51:36,013 | Epoch: [37][180/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0208)	Loss (EDL) 3.817 (4.064)
2023-05-20 18:51:41,450 | Epoch: [37][190/191]	Time   0.47 (  0.58)	Data 0.0002 (0.0198)	Loss (EDL) 4.220 (4.069)
2023-05-20 18:51:41,777 | Create Epoch [37] features of all training data...
2023-05-20 18:52:11,470 | Updated smoothed statistics on Epoch [37]!
2023-05-20 18:52:11,536 | Updated running statistics with Epoch [37] features!
2023-05-20 18:52:15,263 | Val: [ 0/34]	Time  3.437 ( 3.437)	Loss (L1) 8.367 (8.367)	Loss (EDL) 4.316 (4.316)	Loss (NIG_NLL) 3.872 (3.872)	Loss (NIG_Reg) 44.408 (44.408)
2023-05-20 18:52:16,462 | Val: [10/34]	Time  0.102 ( 0.422)	Loss (L1) 7.486 (8.013)	Loss (EDL) 4.148 (4.214)	Loss (NIG_NLL) 3.751 (3.789)	Loss (NIG_Reg) 39.712 (42.508)
2023-05-20 18:52:17,472 | Val: [20/34]	Time  0.101 ( 0.269)	Loss (L1) 8.947 (8.110)	Loss (EDL) 4.389 (4.241)	Loss (NIG_NLL) 3.914 (3.811)	Loss (NIG_Reg) 47.449 (43.024)
2023-05-20 18:52:18,477 | Val: [30/34]	Time  0.101 ( 0.215)	Loss (L1) 9.989 (8.018)	Loss (EDL) 4.504 (4.224)	Loss (NIG_NLL) 3.974 (3.798)	Loss (NIG_Reg) 52.964 (42.536)
2023-05-20 18:52:19,133 |  * Overall: MSE 103.914	L1 7.953	G-Mean 5.177	EDL 4.209	NIG_NLL 3.787	NIG_Reg 42.189
2023-05-20 18:52:19,134 |  * Many: MSE 84.738	L1 7.155	G-Mean 4.646	EDL 4.039	NIG_NLL 3.659	NIG_Reg 37.957
2023-05-20 18:52:19,134 |  * Median: MSE 129.615	L1 9.182	G-Mean 6.262	EDL 4.502	NIG_NLL 4.015	NIG_Reg 48.702
2023-05-20 18:52:19,134 |  * Low: MSE 213.949	L1 12.088	G-Mean 8.503	EDL 5.012	NIG_NLL 4.371	NIG_Reg 64.150
2023-05-20 18:52:19,135 | Best EDL Loss: 7.953
2023-05-20 18:52:19,138 | ===> Saving current best checkpoint...
2023-05-20 18:52:26,328 | Epoch #37: Train loss [4.0689]; Val loss: MSE [103.9144], L1 [7.9527], G-Mean [5.1771], EDL [4.2093], NIG_NLL [3.787], NIG_Reg [42.189]
2023-05-20 18:52:26,329 | this_lr: 
2023-05-20 18:52:26,329 | 0.001
2023-05-20 18:52:30,552 | Epoch: [38][  0/191]	Time   4.22 (  4.22)	Data 3.2156 (3.2156)	Loss (EDL) 3.970 (3.970)
2023-05-20 18:52:36,203 | Epoch: [38][ 10/191]	Time   0.57 (  0.90)	Data 0.0001 (0.2925)	Loss (EDL) 3.767 (4.022)
2023-05-20 18:52:41,774 | Epoch: [38][ 20/191]	Time   0.53 (  0.74)	Data 0.0001 (0.1533)	Loss (EDL) 4.074 (3.977)
2023-05-20 18:52:47,297 | Epoch: [38][ 30/191]	Time   0.56 (  0.68)	Data 0.0001 (0.1039)	Loss (EDL) 4.062 (3.962)
2023-05-20 18:52:52,865 | Epoch: [38][ 40/191]	Time   0.56 (  0.65)	Data 0.0001 (0.0787)	Loss (EDL) 3.905 (3.988)
2023-05-20 18:52:58,499 | Epoch: [38][ 50/191]	Time   0.58 (  0.63)	Data 0.0003 (0.0633)	Loss (EDL) 3.904 (3.977)
2023-05-20 18:53:04,126 | Epoch: [38][ 60/191]	Time   0.57 (  0.62)	Data 0.0001 (0.0530)	Loss (EDL) 4.201 (3.984)
2023-05-20 18:53:09,915 | Epoch: [38][ 70/191]	Time   0.60 (  0.61)	Data 0.0004 (0.0455)	Loss (EDL) 4.057 (3.983)
2023-05-20 18:53:16,206 | Epoch: [38][ 80/191]	Time   0.58 (  0.62)	Data 0.0002 (0.0400)	Loss (EDL) 4.070 (3.979)
2023-05-20 18:53:21,932 | Epoch: [38][ 90/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0356)	Loss (EDL) 3.885 (3.982)
2023-05-20 18:53:27,605 | Epoch: [38][100/191]	Time   0.57 (  0.61)	Data 0.0003 (0.0321)	Loss (EDL) 3.875 (3.985)
2023-05-20 18:53:33,340 | Epoch: [38][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0292)	Loss (EDL) 3.984 (3.987)
2023-05-20 18:53:38,946 | Epoch: [38][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0268)	Loss (EDL) 3.819 (3.994)
2023-05-20 18:53:44,657 | Epoch: [38][130/191]	Time   0.57 (  0.60)	Data 0.0003 (0.0248)	Loss (EDL) 3.930 (3.994)
2023-05-20 18:53:50,259 | Epoch: [38][140/191]	Time   0.61 (  0.60)	Data 0.0001 (0.0231)	Loss (EDL) 3.851 (3.999)
2023-05-20 18:53:56,235 | Epoch: [38][150/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0216)	Loss (EDL) 3.770 (4.001)
2023-05-20 18:54:01,777 | Epoch: [38][160/191]	Time   0.58 (  0.59)	Data 0.0002 (0.0202)	Loss (EDL) 4.106 (4.005)
2023-05-20 18:54:07,276 | Epoch: [38][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0191)	Loss (EDL) 4.264 (4.010)
2023-05-20 18:54:12,778 | Epoch: [38][180/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0180)	Loss (EDL) 4.037 (4.016)
2023-05-20 18:54:18,261 | Epoch: [38][190/191]	Time   0.46 (  0.59)	Data 0.0002 (0.0171)	Loss (EDL) 4.085 (4.017)
2023-05-20 18:54:18,601 | Create Epoch [38] features of all training data...
2023-05-20 18:54:48,519 | Updated smoothed statistics on Epoch [38]!
2023-05-20 18:54:48,585 | Updated running statistics with Epoch [38] features!
2023-05-20 18:54:52,626 | Val: [ 0/34]	Time  3.694 ( 3.694)	Loss (L1) 7.611 (7.611)	Loss (EDL) 4.133 (4.133)	Loss (NIG_NLL) 3.729 (3.729)	Loss (NIG_Reg) 40.407 (40.407)
2023-05-20 18:54:53,812 | Val: [10/34]	Time  0.100 ( 0.444)	Loss (L1) 7.888 (8.226)	Loss (EDL) 4.187 (4.249)	Loss (NIG_NLL) 3.768 (3.812)	Loss (NIG_Reg) 41.838 (43.639)
2023-05-20 18:54:54,816 | Val: [20/34]	Time  0.100 ( 0.280)	Loss (L1) 8.365 (8.281)	Loss (EDL) 4.303 (4.254)	Loss (NIG_NLL) 3.859 (3.815)	Loss (NIG_Reg) 44.358 (43.923)
2023-05-20 18:54:55,827 | Val: [30/34]	Time  0.100 ( 0.222)	Loss (L1) 9.287 (8.182)	Loss (EDL) 4.389 (4.236)	Loss (NIG_NLL) 3.896 (3.802)	Loss (NIG_Reg) 49.251 (43.398)
2023-05-20 18:54:56,466 |  * Overall: MSE 111.446	L1 8.215	G-Mean 5.405	EDL 4.240	NIG_NLL 3.804	NIG_Reg 43.575
2023-05-20 18:54:56,467 |  * Many: MSE 83.920	L1 7.080	G-Mean 4.627	EDL 4.021	NIG_NLL 3.646	NIG_Reg 37.561
2023-05-20 18:54:56,467 |  * Median: MSE 156.740	L1 10.282	G-Mean 7.376	EDL 4.661	NIG_NLL 4.116	NIG_Reg 54.519
2023-05-20 18:54:56,467 |  * Low: MSE 246.158	L1 13.214	G-Mean 9.925	EDL 5.143	NIG_NLL 4.442	NIG_Reg 70.101
2023-05-20 18:54:56,467 | Best EDL Loss: 7.953
2023-05-20 18:54:56,470 | Epoch #38: Train loss [4.0167]; Val loss: MSE [111.4459], L1 [8.2150], G-Mean [5.4046], EDL [4.2401], NIG_NLL [3.804], NIG_Reg [43.575]
2023-05-20 18:54:56,471 | this_lr: 
2023-05-20 18:54:56,471 | 0.001
2023-05-20 18:55:00,956 | Epoch: [39][  0/191]	Time   4.48 (  4.48)	Data 3.5800 (3.5800)	Loss (EDL) 4.081 (4.081)
2023-05-20 18:55:06,574 | Epoch: [39][ 10/191]	Time   0.58 (  0.92)	Data 0.0003 (0.3256)	Loss (EDL) 4.085 (4.047)
2023-05-20 18:55:12,147 | Epoch: [39][ 20/191]	Time   0.55 (  0.75)	Data 0.0001 (0.1707)	Loss (EDL) 4.055 (4.002)
2023-05-20 18:55:17,692 | Epoch: [39][ 30/191]	Time   0.54 (  0.68)	Data 0.0003 (0.1157)	Loss (EDL) 3.860 (3.972)
2023-05-20 18:55:23,207 | Epoch: [39][ 40/191]	Time   0.57 (  0.65)	Data 0.0001 (0.0875)	Loss (EDL) 4.020 (3.976)
2023-05-20 18:55:28,787 | Epoch: [39][ 50/191]	Time   0.57 (  0.63)	Data 0.0001 (0.0704)	Loss (EDL) 4.159 (3.984)
2023-05-20 18:55:34,717 | Epoch: [39][ 60/191]	Time   0.56 (  0.63)	Data 0.0001 (0.0589)	Loss (EDL) 4.029 (3.990)
2023-05-20 18:55:40,462 | Epoch: [39][ 70/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0506)	Loss (EDL) 4.519 (3.996)
2023-05-20 18:55:46,071 | Epoch: [39][ 80/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0444)	Loss (EDL) 3.793 (4.009)
2023-05-20 18:55:51,662 | Epoch: [39][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0396)	Loss (EDL) 4.079 (4.008)
2023-05-20 18:55:57,274 | Epoch: [39][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0357)	Loss (EDL) 4.004 (4.012)
2023-05-20 18:56:02,892 | Epoch: [39][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0325)	Loss (EDL) 3.960 (4.016)
2023-05-20 18:56:08,484 | Epoch: [39][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0298)	Loss (EDL) 3.993 (4.022)
2023-05-20 18:56:14,306 | Epoch: [39][130/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0275)	Loss (EDL) 3.769 (4.026)
2023-05-20 18:56:19,741 | Epoch: [39][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0256)	Loss (EDL) 4.093 (4.026)
2023-05-20 18:56:25,230 | Epoch: [39][150/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0239)	Loss (EDL) 3.968 (4.019)
2023-05-20 18:56:30,664 | Epoch: [39][160/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0224)	Loss (EDL) 4.103 (4.021)
2023-05-20 18:56:36,093 | Epoch: [39][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0211)	Loss (EDL) 4.014 (4.018)
2023-05-20 18:56:41,524 | Epoch: [39][180/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0200)	Loss (EDL) 4.266 (4.019)
2023-05-20 18:56:46,855 | Epoch: [39][190/191]	Time   0.48 (  0.58)	Data 0.0001 (0.0189)	Loss (EDL) 4.116 (4.023)
2023-05-20 18:56:47,169 | Create Epoch [39] features of all training data...
2023-05-20 18:57:16,404 | Updated smoothed statistics on Epoch [39]!
2023-05-20 18:57:16,476 | Updated running statistics with Epoch [39] features!
2023-05-20 18:57:20,116 | Val: [ 0/34]	Time  3.331 ( 3.331)	Loss (L1) 7.883 (7.883)	Loss (EDL) 4.174 (4.174)	Loss (NIG_NLL) 3.755 (3.755)	Loss (NIG_Reg) 41.853 (41.853)
2023-05-20 18:57:21,520 | Val: [10/34]	Time  0.100 ( 0.430)	Loss (L1) 8.062 (7.866)	Loss (EDL) 4.208 (4.175)	Loss (NIG_NLL) 3.781 (3.758)	Loss (NIG_Reg) 42.768 (41.727)
2023-05-20 18:57:22,522 | Val: [20/34]	Time  0.100 ( 0.273)	Loss (L1) 8.558 (7.806)	Loss (EDL) 4.321 (4.171)	Loss (NIG_NLL) 3.867 (3.757)	Loss (NIG_Reg) 45.382 (41.412)
2023-05-20 18:57:23,528 | Val: [30/34]	Time  0.100 ( 0.218)	Loss (L1) 9.538 (7.838)	Loss (EDL) 4.471 (4.179)	Loss (NIG_NLL) 3.965 (3.763)	Loss (NIG_Reg) 50.580 (41.579)
2023-05-20 18:57:24,149 |  * Overall: MSE 101.585	L1 7.792	G-Mean 4.958	EDL 4.169	NIG_NLL 3.755	NIG_Reg 41.337
2023-05-20 18:57:24,149 |  * Many: MSE 87.249	L1 7.203	G-Mean 4.582	EDL 4.039	NIG_NLL 3.657	NIG_Reg 38.214
2023-05-20 18:57:24,149 |  * Median: MSE 122.382	L1 8.677	G-Mean 5.485	EDL 4.392	NIG_NLL 3.932	NIG_Reg 46.010
2023-05-20 18:57:24,149 |  * Low: MSE 179.459	L1 10.916	G-Mean 7.893	EDL 4.777	NIG_NLL 4.198	NIG_Reg 57.909
2023-05-20 18:57:24,149 | Best EDL Loss: 7.792
2023-05-20 18:57:24,153 | ===> Saving current best checkpoint...
2023-05-20 18:57:31,206 | Epoch #39: Train loss [4.0231]; Val loss: MSE [101.5845], L1 [7.7924], G-Mean [4.9579], EDL [4.1687], NIG_NLL [3.755], NIG_Reg [41.337]
2023-05-20 18:57:31,208 | this_lr: 
2023-05-20 18:57:31,208 | 0.001
2023-05-20 18:57:35,353 | Epoch: [40][  0/191]	Time   4.14 (  4.14)	Data 3.1746 (3.1746)	Loss (EDL) 3.983 (3.983)
2023-05-20 18:57:40,858 | Epoch: [40][ 10/191]	Time   0.56 (  0.88)	Data 0.0001 (0.2888)	Loss (EDL) 3.885 (3.940)
2023-05-20 18:57:46,640 | Epoch: [40][ 20/191]	Time   0.57 (  0.73)	Data 0.0001 (0.1514)	Loss (EDL) 3.931 (3.981)
2023-05-20 18:57:52,210 | Epoch: [40][ 30/191]	Time   0.54 (  0.68)	Data 0.0001 (0.1026)	Loss (EDL) 3.735 (3.954)
2023-05-20 18:57:57,809 | Epoch: [40][ 40/191]	Time   0.57 (  0.65)	Data 0.0002 (0.0777)	Loss (EDL) 3.911 (3.966)
2023-05-20 18:58:03,338 | Epoch: [40][ 50/191]	Time   0.56 (  0.63)	Data 0.0001 (0.0625)	Loss (EDL) 3.907 (3.965)
2023-05-20 18:58:09,059 | Epoch: [40][ 60/191]	Time   0.58 (  0.62)	Data 0.0002 (0.0523)	Loss (EDL) 4.065 (3.975)
2023-05-20 18:58:14,725 | Epoch: [40][ 70/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0450)	Loss (EDL) 3.871 (3.970)
2023-05-20 18:58:20,732 | Epoch: [40][ 80/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0394)	Loss (EDL) 4.250 (3.979)
2023-05-20 18:58:26,457 | Epoch: [40][ 90/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0351)	Loss (EDL) 4.005 (3.992)
2023-05-20 18:58:32,092 | Epoch: [40][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0317)	Loss (EDL) 4.356 (3.997)
2023-05-20 18:58:37,788 | Epoch: [40][110/191]	Time   0.59 (  0.60)	Data 0.0002 (0.0288)	Loss (EDL) 4.199 (4.012)
2023-05-20 18:58:43,478 | Epoch: [40][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0265)	Loss (EDL) 3.654 (4.012)
2023-05-20 18:58:49,061 | Epoch: [40][130/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0245)	Loss (EDL) 3.935 (4.010)
2023-05-20 18:58:54,546 | Epoch: [40][140/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0228)	Loss (EDL) 3.808 (3.998)
2023-05-20 18:59:00,282 | Epoch: [40][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0213)	Loss (EDL) 4.246 (4.002)
2023-05-20 18:59:05,768 | Epoch: [40][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0200)	Loss (EDL) 3.908 (4.007)
2023-05-20 18:59:11,267 | Epoch: [40][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0188)	Loss (EDL) 3.904 (4.010)
2023-05-20 18:59:16,721 | Epoch: [40][180/191]	Time   0.56 (  0.58)	Data 0.0002 (0.0178)	Loss (EDL) 3.919 (4.007)
2023-05-20 18:59:22,057 | Epoch: [40][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0168)	Loss (EDL) 3.928 (4.003)
2023-05-20 18:59:22,402 | Create Epoch [40] features of all training data...
2023-05-20 18:59:52,073 | Updated smoothed statistics on Epoch [40]!
2023-05-20 18:59:52,139 | Updated running statistics with Epoch [40] features!
2023-05-20 18:59:55,683 | Val: [ 0/34]	Time  3.254 ( 3.254)	Loss (L1) 8.046 (8.046)	Loss (EDL) 4.246 (4.246)	Loss (NIG_NLL) 3.819 (3.819)	Loss (NIG_Reg) 42.692 (42.692)
2023-05-20 18:59:57,130 | Val: [10/34]	Time  0.101 ( 0.427)	Loss (L1) 9.172 (7.932)	Loss (EDL) 4.429 (4.209)	Loss (NIG_NLL) 3.942 (3.789)	Loss (NIG_Reg) 48.640 (42.070)
2023-05-20 18:59:58,134 | Val: [20/34]	Time  0.100 ( 0.272)	Loss (L1) 9.600 (8.119)	Loss (EDL) 4.531 (4.250)	Loss (NIG_NLL) 4.022 (3.819)	Loss (NIG_Reg) 50.893 (43.056)
2023-05-20 18:59:59,139 | Val: [30/34]	Time  0.100 ( 0.216)	Loss (L1) 8.975 (8.143)	Loss (EDL) 4.369 (4.252)	Loss (NIG_NLL) 3.893 (3.821)	Loss (NIG_Reg) 47.584 (43.185)
2023-05-20 18:59:59,801 |  * Overall: MSE 109.180	L1 8.116	G-Mean 5.258	EDL 4.245	NIG_NLL 3.815	NIG_Reg 43.039
2023-05-20 18:59:59,801 |  * Many: MSE 90.387	L1 7.372	G-Mean 4.754	EDL 4.076	NIG_NLL 3.685	NIG_Reg 39.099
2023-05-20 18:59:59,801 |  * Median: MSE 128.643	L1 9.146	G-Mean 6.201	EDL 4.524	NIG_NLL 4.039	NIG_Reg 48.494
2023-05-20 18:59:59,801 |  * Low: MSE 232.844	L1 12.288	G-Mean 8.618	EDL 5.070	NIG_NLL 4.419	NIG_Reg 65.165
2023-05-20 18:59:59,801 | Best EDL Loss: 7.792
2023-05-20 18:59:59,805 | Epoch #40: Train loss [4.0025]; Val loss: MSE [109.1798], L1 [8.1158], G-Mean [5.2576], EDL [4.2453], NIG_NLL [3.815], NIG_Reg [43.039]
2023-05-20 18:59:59,805 | this_lr: 
2023-05-20 18:59:59,805 | 0.001
2023-05-20 19:00:04,527 | Epoch: [41][  0/191]	Time   4.72 (  4.72)	Data 3.7469 (3.7469)	Loss (EDL) 3.817 (3.817)
2023-05-20 19:00:10,220 | Epoch: [41][ 10/191]	Time   0.56 (  0.95)	Data 0.0001 (0.3409)	Loss (EDL) 3.866 (3.904)
2023-05-20 19:00:15,867 | Epoch: [41][ 20/191]	Time   0.58 (  0.76)	Data 0.0001 (0.1786)	Loss (EDL) 4.106 (3.938)
2023-05-20 19:00:21,608 | Epoch: [41][ 30/191]	Time   0.56 (  0.70)	Data 0.0002 (0.1211)	Loss (EDL) 4.008 (3.959)
2023-05-20 19:00:27,222 | Epoch: [41][ 40/191]	Time   0.56 (  0.67)	Data 0.0002 (0.0916)	Loss (EDL) 4.152 (3.952)
2023-05-20 19:00:33,255 | Epoch: [41][ 50/191]	Time   0.55 (  0.66)	Data 0.0001 (0.0737)	Loss (EDL) 3.657 (3.962)
2023-05-20 19:00:38,887 | Epoch: [41][ 60/191]	Time   0.56 (  0.64)	Data 0.0001 (0.0616)	Loss (EDL) 3.771 (3.953)
2023-05-20 19:00:44,556 | Epoch: [41][ 70/191]	Time   0.57 (  0.63)	Data 0.0003 (0.0530)	Loss (EDL) 3.995 (3.945)
2023-05-20 19:00:50,203 | Epoch: [41][ 80/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0465)	Loss (EDL) 3.980 (3.939)
2023-05-20 19:00:55,805 | Epoch: [41][ 90/191]	Time   0.54 (  0.62)	Data 0.0003 (0.0414)	Loss (EDL) 3.979 (3.945)
2023-05-20 19:01:01,413 | Epoch: [41][100/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0373)	Loss (EDL) 3.774 (3.944)
2023-05-20 19:01:06,946 | Epoch: [41][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0340)	Loss (EDL) 4.059 (3.960)
2023-05-20 19:01:12,924 | Epoch: [41][120/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0312)	Loss (EDL) 3.996 (3.963)
2023-05-20 19:01:18,536 | Epoch: [41][130/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0289)	Loss (EDL) 3.891 (3.968)
2023-05-20 19:01:23,997 | Epoch: [41][140/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0268)	Loss (EDL) 3.881 (3.971)
2023-05-20 19:01:29,441 | Epoch: [41][150/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0251)	Loss (EDL) 3.948 (3.974)
2023-05-20 19:01:34,978 | Epoch: [41][160/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0235)	Loss (EDL) 3.786 (3.980)
2023-05-20 19:01:40,472 | Epoch: [41][170/191]	Time   0.55 (  0.59)	Data 0.0003 (0.0222)	Loss (EDL) 4.080 (3.978)
2023-05-20 19:01:45,964 | Epoch: [41][180/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0210)	Loss (EDL) 3.961 (3.980)
2023-05-20 19:01:51,392 | Epoch: [41][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0199)	Loss (EDL) 3.881 (3.982)
2023-05-20 19:01:51,779 | Create Epoch [41] features of all training data...
2023-05-20 19:02:21,198 | Updated smoothed statistics on Epoch [41]!
2023-05-20 19:02:21,265 | Updated running statistics with Epoch [41] features!
2023-05-20 19:02:25,083 | Val: [ 0/34]	Time  3.514 ( 3.514)	Loss (L1) 8.049 (8.049)	Loss (EDL) 4.256 (4.256)	Loss (NIG_NLL) 3.829 (3.829)	Loss (NIG_Reg) 42.720 (42.720)
2023-05-20 19:02:26,319 | Val: [10/34]	Time  0.100 ( 0.432)	Loss (L1) 9.107 (7.923)	Loss (EDL) 4.394 (4.202)	Loss (NIG_NLL) 3.911 (3.781)	Loss (NIG_Reg) 48.301 (42.025)
2023-05-20 19:02:27,323 | Val: [20/34]	Time  0.101 ( 0.274)	Loss (L1) 7.907 (7.912)	Loss (EDL) 4.211 (4.204)	Loss (NIG_NLL) 3.792 (3.785)	Loss (NIG_Reg) 41.925 (41.965)
2023-05-20 19:02:28,330 | Val: [30/34]	Time  0.100 ( 0.218)	Loss (L1) 9.365 (7.935)	Loss (EDL) 4.421 (4.212)	Loss (NIG_NLL) 3.924 (3.791)	Loss (NIG_Reg) 49.654 (42.089)
2023-05-20 19:02:28,996 |  * Overall: MSE 101.831	L1 7.893	G-Mean 5.251	EDL 4.201	NIG_NLL 3.782	NIG_Reg 41.862
2023-05-20 19:02:28,996 |  * Many: MSE 86.102	L1 7.246	G-Mean 4.785	EDL 4.057	NIG_NLL 3.673	NIG_Reg 38.434
2023-05-20 19:02:28,996 |  * Median: MSE 121.582	L1 8.844	G-Mean 6.181	EDL 4.444	NIG_NLL 3.975	NIG_Reg 46.897
2023-05-20 19:02:28,996 |  * Low: MSE 195.760	L1 11.370	G-Mean 8.036	EDL 4.889	NIG_NLL 4.286	NIG_Reg 60.319
2023-05-20 19:02:28,996 | Best EDL Loss: 7.792
2023-05-20 19:02:29,000 | Epoch #41: Train loss [3.9815]; Val loss: MSE [101.8308], L1 [7.8925], G-Mean [5.2505], EDL [4.2011], NIG_NLL [3.782], NIG_Reg [41.862]
2023-05-20 19:02:29,000 | this_lr: 
2023-05-20 19:02:29,000 | 0.001
2023-05-20 19:02:33,489 | Epoch: [42][  0/191]	Time   4.49 (  4.49)	Data 3.5959 (3.5959)	Loss (EDL) 4.170 (4.170)
2023-05-20 19:02:39,051 | Epoch: [42][ 10/191]	Time   0.56 (  0.91)	Data 0.0001 (0.3271)	Loss (EDL) 3.841 (3.990)
2023-05-20 19:02:44,913 | Epoch: [42][ 20/191]	Time   0.56 (  0.76)	Data 0.0001 (0.1714)	Loss (EDL) 4.107 (3.974)
2023-05-20 19:02:50,524 | Epoch: [42][ 30/191]	Time   0.58 (  0.69)	Data 0.0002 (0.1162)	Loss (EDL) 3.956 (3.974)
2023-05-20 19:02:56,170 | Epoch: [42][ 40/191]	Time   0.56 (  0.66)	Data 0.0003 (0.0879)	Loss (EDL) 3.942 (3.957)
2023-05-20 19:03:01,837 | Epoch: [42][ 50/191]	Time   0.55 (  0.64)	Data 0.0001 (0.0707)	Loss (EDL) 3.838 (3.952)
2023-05-20 19:03:07,484 | Epoch: [42][ 60/191]	Time   0.55 (  0.63)	Data 0.0002 (0.0592)	Loss (EDL) 3.721 (3.953)
2023-05-20 19:03:13,153 | Epoch: [42][ 70/191]	Time   0.58 (  0.62)	Data 0.0002 (0.0509)	Loss (EDL) 4.203 (3.950)
2023-05-20 19:03:19,111 | Epoch: [42][ 80/191]	Time   0.54 (  0.62)	Data 0.0002 (0.0446)	Loss (EDL) 3.778 (3.945)
2023-05-20 19:03:24,778 | Epoch: [42][ 90/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0397)	Loss (EDL) 3.920 (3.955)
2023-05-20 19:03:30,488 | Epoch: [42][100/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0358)	Loss (EDL) 4.054 (3.961)
2023-05-20 19:03:36,094 | Epoch: [42][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0326)	Loss (EDL) 4.259 (3.972)
2023-05-20 19:03:41,741 | Epoch: [42][120/191]	Time   0.57 (  0.60)	Data 0.0003 (0.0299)	Loss (EDL) 4.264 (3.975)
2023-05-20 19:03:47,330 | Epoch: [42][130/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0277)	Loss (EDL) 4.554 (3.983)
2023-05-20 19:03:52,807 | Epoch: [42][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0257)	Loss (EDL) 3.593 (3.988)
2023-05-20 19:03:58,309 | Epoch: [42][150/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0240)	Loss (EDL) 3.896 (3.989)
2023-05-20 19:04:04,097 | Epoch: [42][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0226)	Loss (EDL) 3.828 (3.985)
2023-05-20 19:04:09,595 | Epoch: [42][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0212)	Loss (EDL) 3.927 (3.982)
2023-05-20 19:04:15,173 | Epoch: [42][180/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0201)	Loss (EDL) 4.127 (3.982)
2023-05-20 19:04:20,554 | Epoch: [42][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0190)	Loss (EDL) 4.032 (3.980)
2023-05-20 19:04:20,879 | Create Epoch [42] features of all training data...
2023-05-20 19:04:50,317 | Updated smoothed statistics on Epoch [42]!
2023-05-20 19:04:50,382 | Updated running statistics with Epoch [42] features!
2023-05-20 19:04:54,254 | Val: [ 0/34]	Time  3.591 ( 3.591)	Loss (L1) 8.359 (8.359)	Loss (EDL) 4.253 (4.253)	Loss (NIG_NLL) 3.809 (3.809)	Loss (NIG_Reg) 44.360 (44.360)
2023-05-20 19:04:55,273 | Val: [10/34]	Time  0.100 ( 0.419)	Loss (L1) 8.733 (7.925)	Loss (EDL) 4.341 (4.193)	Loss (NIG_NLL) 3.878 (3.772)	Loss (NIG_Reg) 46.317 (42.036)
2023-05-20 19:04:56,281 | Val: [20/34]	Time  0.101 ( 0.267)	Loss (L1) 9.013 (7.968)	Loss (EDL) 4.414 (4.208)	Loss (NIG_NLL) 3.936 (3.786)	Loss (NIG_Reg) 47.788 (42.266)
2023-05-20 19:04:57,289 | Val: [30/34]	Time  0.101 ( 0.214)	Loss (L1) 8.771 (7.951)	Loss (EDL) 4.320 (4.204)	Loss (NIG_NLL) 3.855 (3.782)	Loss (NIG_Reg) 46.503 (42.172)
2023-05-20 19:04:57,929 |  * Overall: MSE 101.945	L1 7.886	G-Mean 5.176	EDL 4.191	NIG_NLL 3.773	NIG_Reg 41.829
2023-05-20 19:04:57,929 |  * Many: MSE 85.845	L1 7.174	G-Mean 4.632	EDL 4.045	NIG_NLL 3.664	NIG_Reg 38.055
2023-05-20 19:04:57,929 |  * Median: MSE 127.639	L1 9.007	G-Mean 6.244	EDL 4.436	NIG_NLL 3.958	NIG_Reg 47.757
2023-05-20 19:04:57,929 |  * Low: MSE 182.949	L1 11.513	G-Mean 8.796	EDL 4.892	NIG_NLL 4.282	NIG_Reg 61.071
2023-05-20 19:04:57,930 | Best EDL Loss: 7.792
2023-05-20 19:04:57,934 | Epoch #42: Train loss [3.9797]; Val loss: MSE [101.9454], L1 [7.8861], G-Mean [5.1760], EDL [4.1908], NIG_NLL [3.773], NIG_Reg [41.829]
2023-05-20 19:04:57,934 | this_lr: 
2023-05-20 19:04:57,935 | 0.001
2023-05-20 19:05:02,789 | Epoch: [43][  0/191]	Time   4.85 (  4.85)	Data 3.9829 (3.9829)	Loss (EDL) 3.969 (3.969)
2023-05-20 19:05:08,483 | Epoch: [43][ 10/191]	Time   0.56 (  0.96)	Data 0.0001 (0.3623)	Loss (EDL) 3.924 (3.898)
2023-05-20 19:05:14,029 | Epoch: [43][ 20/191]	Time   0.55 (  0.77)	Data 0.0001 (0.1899)	Loss (EDL) 3.814 (3.908)
2023-05-20 19:05:19,616 | Epoch: [43][ 30/191]	Time   0.55 (  0.70)	Data 0.0001 (0.1287)	Loss (EDL) 4.012 (3.926)
2023-05-20 19:05:25,381 | Epoch: [43][ 40/191]	Time   0.59 (  0.67)	Data 0.0001 (0.0974)	Loss (EDL) 4.328 (3.920)
2023-05-20 19:05:30,971 | Epoch: [43][ 50/191]	Time   0.56 (  0.65)	Data 0.0003 (0.0783)	Loss (EDL) 3.880 (3.932)
2023-05-20 19:05:36,825 | Epoch: [43][ 60/191]	Time   0.54 (  0.64)	Data 0.0001 (0.0655)	Loss (EDL) 3.733 (3.914)
2023-05-20 19:05:42,408 | Epoch: [43][ 70/191]	Time   0.57 (  0.63)	Data 0.0002 (0.0563)	Loss (EDL) 3.849 (3.916)
2023-05-20 19:05:47,945 | Epoch: [43][ 80/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0494)	Loss (EDL) 3.900 (3.926)
2023-05-20 19:05:53,554 | Epoch: [43][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0440)	Loss (EDL) 4.096 (3.925)
2023-05-20 19:05:59,154 | Epoch: [43][100/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0397)	Loss (EDL) 3.846 (3.922)
2023-05-20 19:06:04,863 | Epoch: [43][110/191]	Time   0.55 (  0.60)	Data 0.0003 (0.0361)	Loss (EDL) 3.905 (3.923)
2023-05-20 19:06:10,482 | Epoch: [43][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0332)	Loss (EDL) 3.841 (3.924)
2023-05-20 19:06:16,300 | Epoch: [43][130/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0306)	Loss (EDL) 4.186 (3.931)
2023-05-20 19:06:21,845 | Epoch: [43][140/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0285)	Loss (EDL) 3.981 (3.938)
2023-05-20 19:06:27,329 | Epoch: [43][150/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0266)	Loss (EDL) 4.542 (3.941)
2023-05-20 19:06:32,819 | Epoch: [43][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0250)	Loss (EDL) 4.340 (3.947)
2023-05-20 19:06:38,287 | Epoch: [43][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0235)	Loss (EDL) 3.752 (3.943)
2023-05-20 19:06:43,762 | Epoch: [43][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0222)	Loss (EDL) 4.086 (3.947)
2023-05-20 19:06:49,119 | Epoch: [43][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0211)	Loss (EDL) 3.950 (3.945)
2023-05-20 19:06:49,455 | Create Epoch [43] features of all training data...
2023-05-20 19:07:18,951 | Updated smoothed statistics on Epoch [43]!
2023-05-20 19:07:19,029 | Updated running statistics with Epoch [43] features!
2023-05-20 19:07:22,663 | Val: [ 0/34]	Time  3.317 ( 3.317)	Loss (L1) 8.065 (8.065)	Loss (EDL) 4.234 (4.234)	Loss (NIG_NLL) 3.806 (3.806)	Loss (NIG_Reg) 42.800 (42.800)
2023-05-20 19:07:23,897 | Val: [10/34]	Time  0.101 ( 0.414)	Loss (L1) 8.610 (8.185)	Loss (EDL) 4.314 (4.257)	Loss (NIG_NLL) 3.857 (3.823)	Loss (NIG_Reg) 45.659 (43.413)
2023-05-20 19:07:24,909 | Val: [20/34]	Time  0.101 ( 0.265)	Loss (L1) 9.010 (8.218)	Loss (EDL) 4.442 (4.264)	Loss (NIG_NLL) 3.964 (3.828)	Loss (NIG_Reg) 47.770 (43.584)
2023-05-20 19:07:25,920 | Val: [30/34]	Time  0.101 ( 0.212)	Loss (L1) 9.678 (8.220)	Loss (EDL) 4.465 (4.264)	Loss (NIG_NLL) 3.952 (3.828)	Loss (NIG_Reg) 51.311 (43.598)
2023-05-20 19:07:26,574 |  * Overall: MSE 108.704	L1 8.155	G-Mean 5.380	EDL 4.250	NIG_NLL 3.817	NIG_Reg 43.249
2023-05-20 19:07:26,575 |  * Many: MSE 87.052	L1 7.235	G-Mean 4.792	EDL 4.053	NIG_NLL 3.670	NIG_Reg 38.374
2023-05-20 19:07:26,575 |  * Median: MSE 147.216	L1 9.986	G-Mean 6.861	EDL 4.659	NIG_NLL 4.129	NIG_Reg 52.944
2023-05-20 19:07:26,575 |  * Low: MSE 206.692	L1 11.780	G-Mean 8.189	EDL 4.971	NIG_NLL 4.347	NIG_Reg 62.474
2023-05-20 19:07:26,575 | Best EDL Loss: 7.792
2023-05-20 19:07:26,578 | Epoch #43: Train loss [3.9449]; Val loss: MSE [108.7040], L1 [8.1546], G-Mean [5.3798], EDL [4.2496], NIG_NLL [3.817], NIG_Reg [43.249]
2023-05-20 19:07:26,579 | this_lr: 
2023-05-20 19:07:26,579 | 0.001
2023-05-20 19:07:31,409 | Epoch: [44][  0/191]	Time   4.83 (  4.83)	Data 3.9793 (3.9793)	Loss (EDL) 3.771 (3.771)
2023-05-20 19:07:37,064 | Epoch: [44][ 10/191]	Time   0.57 (  0.95)	Data 0.0001 (0.3619)	Loss (EDL) 3.940 (3.856)
2023-05-20 19:07:42,669 | Epoch: [44][ 20/191]	Time   0.55 (  0.77)	Data 0.0002 (0.1897)	Loss (EDL) 4.007 (3.849)
2023-05-20 19:07:48,454 | Epoch: [44][ 30/191]	Time   0.58 (  0.71)	Data 0.0003 (0.1286)	Loss (EDL) 3.866 (3.878)
2023-05-20 19:07:54,168 | Epoch: [44][ 40/191]	Time   0.56 (  0.67)	Data 0.0001 (0.0972)	Loss (EDL) 3.755 (3.904)
2023-05-20 19:07:59,800 | Epoch: [44][ 50/191]	Time   0.57 (  0.65)	Data 0.0002 (0.0782)	Loss (EDL) 4.121 (3.922)
2023-05-20 19:08:05,398 | Epoch: [44][ 60/191]	Time   0.54 (  0.64)	Data 0.0001 (0.0654)	Loss (EDL) 3.989 (3.924)
2023-05-20 19:08:11,084 | Epoch: [44][ 70/191]	Time   0.54 (  0.63)	Data 0.0002 (0.0562)	Loss (EDL) 3.951 (3.934)
2023-05-20 19:08:16,690 | Epoch: [44][ 80/191]	Time   0.58 (  0.62)	Data 0.0002 (0.0493)	Loss (EDL) 4.419 (3.943)
2023-05-20 19:08:22,727 | Epoch: [44][ 90/191]	Time   0.58 (  0.62)	Data 0.0002 (0.0439)	Loss (EDL) 3.985 (3.946)
2023-05-20 19:08:28,365 | Epoch: [44][100/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0396)	Loss (EDL) 4.123 (3.950)
2023-05-20 19:08:34,047 | Epoch: [44][110/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0361)	Loss (EDL) 3.947 (3.951)
2023-05-20 19:08:39,674 | Epoch: [44][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0331)	Loss (EDL) 3.946 (3.954)
2023-05-20 19:08:45,143 | Epoch: [44][130/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0306)	Loss (EDL) 3.788 (3.950)
2023-05-20 19:08:50,618 | Epoch: [44][140/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0284)	Loss (EDL) 4.027 (3.945)
2023-05-20 19:08:56,126 | Epoch: [44][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0266)	Loss (EDL) 3.732 (3.943)
2023-05-20 19:09:01,614 | Epoch: [44][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0249)	Loss (EDL) 3.891 (3.945)
2023-05-20 19:09:07,374 | Epoch: [44][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0235)	Loss (EDL) 3.706 (3.943)
2023-05-20 19:09:12,862 | Epoch: [44][180/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0222)	Loss (EDL) 3.924 (3.941)
2023-05-20 19:09:18,256 | Epoch: [44][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0210)	Loss (EDL) 4.106 (3.945)
2023-05-20 19:09:18,599 | Create Epoch [44] features of all training data...
2023-05-20 19:09:47,842 | Updated smoothed statistics on Epoch [44]!
2023-05-20 19:09:47,908 | Updated running statistics with Epoch [44] features!
2023-05-20 19:09:51,705 | Val: [ 0/34]	Time  3.482 ( 3.482)	Loss (L1) 7.948 (7.948)	Loss (EDL) 4.241 (4.241)	Loss (NIG_NLL) 3.819 (3.819)	Loss (NIG_Reg) 42.172 (42.172)
2023-05-20 19:09:52,991 | Val: [10/34]	Time  0.100 ( 0.434)	Loss (L1) 8.105 (7.833)	Loss (EDL) 4.244 (4.197)	Loss (NIG_NLL) 3.814 (3.782)	Loss (NIG_Reg) 42.981 (41.541)
2023-05-20 19:09:54,008 | Val: [20/34]	Time  0.106 ( 0.275)	Loss (L1) 8.927 (8.059)	Loss (EDL) 4.417 (4.244)	Loss (NIG_NLL) 3.943 (3.817)	Loss (NIG_Reg) 47.334 (42.740)
2023-05-20 19:09:55,014 | Val: [30/34]	Time  0.100 ( 0.219)	Loss (L1) 8.218 (8.010)	Loss (EDL) 4.180 (4.236)	Loss (NIG_NLL) 3.745 (3.811)	Loss (NIG_Reg) 43.571 (42.481)
2023-05-20 19:09:55,675 |  * Overall: MSE 102.954	L1 7.914	G-Mean 5.166	EDL 4.214	NIG_NLL 3.795	NIG_Reg 41.971
2023-05-20 19:09:55,675 |  * Many: MSE 82.355	L1 7.033	G-Mean 4.513	EDL 4.031	NIG_NLL 3.658	NIG_Reg 37.300
2023-05-20 19:09:55,675 |  * Median: MSE 138.946	L1 9.432	G-Mean 6.614	EDL 4.542	NIG_NLL 4.041	NIG_Reg 50.010
2023-05-20 19:09:55,675 |  * Low: MSE 197.968	L1 12.035	G-Mean 9.346	EDL 5.035	NIG_NLL 4.397	NIG_Reg 63.853
2023-05-20 19:09:55,676 | Best EDL Loss: 7.792
2023-05-20 19:09:55,679 | Epoch #44: Train loss [3.9449]; Val loss: MSE [102.9541], L1 [7.9139], G-Mean [5.1658], EDL [4.2142], NIG_NLL [3.795], NIG_Reg [41.971]
2023-05-20 19:09:55,679 | this_lr: 
2023-05-20 19:09:55,679 | 0.001
2023-05-20 19:09:59,989 | Epoch: [45][  0/191]	Time   4.31 (  4.31)	Data 3.4670 (3.4670)	Loss (EDL) 4.123 (4.123)
2023-05-20 19:10:05,850 | Epoch: [45][ 10/191]	Time   0.56 (  0.92)	Data 0.0001 (0.3154)	Loss (EDL) 3.936 (3.956)
2023-05-20 19:10:11,492 | Epoch: [45][ 20/191]	Time   0.57 (  0.75)	Data 0.0001 (0.1653)	Loss (EDL) 3.875 (3.919)
2023-05-20 19:10:17,040 | Epoch: [45][ 30/191]	Time   0.55 (  0.69)	Data 0.0001 (0.1121)	Loss (EDL) 3.559 (3.890)
2023-05-20 19:10:22,564 | Epoch: [45][ 40/191]	Time   0.54 (  0.66)	Data 0.0001 (0.0848)	Loss (EDL) 4.133 (3.885)
2023-05-20 19:10:28,162 | Epoch: [45][ 50/191]	Time   0.56 (  0.64)	Data 0.0001 (0.0682)	Loss (EDL) 3.931 (3.882)
2023-05-20 19:10:33,666 | Epoch: [45][ 60/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0570)	Loss (EDL) 4.184 (3.882)
2023-05-20 19:10:39,621 | Epoch: [45][ 70/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0490)	Loss (EDL) 3.822 (3.875)
2023-05-20 19:10:45,225 | Epoch: [45][ 80/191]	Time   0.54 (  0.61)	Data 0.0005 (0.0430)	Loss (EDL) 3.602 (3.869)
2023-05-20 19:10:50,912 | Epoch: [45][ 90/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0383)	Loss (EDL) 4.232 (3.876)
2023-05-20 19:10:56,555 | Epoch: [45][100/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0345)	Loss (EDL) 4.021 (3.881)
2023-05-20 19:11:02,219 | Epoch: [45][110/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0314)	Loss (EDL) 4.062 (3.892)
2023-05-20 19:11:07,740 | Epoch: [45][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0289)	Loss (EDL) 3.760 (3.892)
2023-05-20 19:11:13,282 | Epoch: [45][130/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0267)	Loss (EDL) 3.871 (3.892)
2023-05-20 19:11:18,798 | Epoch: [45][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0248)	Loss (EDL) 3.788 (3.890)
2023-05-20 19:11:24,552 | Epoch: [45][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0232)	Loss (EDL) 4.319 (3.897)
2023-05-20 19:11:29,989 | Epoch: [45][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0217)	Loss (EDL) 3.749 (3.906)
2023-05-20 19:11:35,450 | Epoch: [45][170/191]	Time   0.55 (  0.58)	Data 0.0002 (0.0205)	Loss (EDL) 4.006 (3.909)
2023-05-20 19:11:40,949 | Epoch: [45][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0194)	Loss (EDL) 3.938 (3.922)
2023-05-20 19:11:46,313 | Epoch: [45][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0184)	Loss (EDL) 4.077 (3.930)
2023-05-20 19:11:46,635 | Create Epoch [45] features of all training data...
2023-05-20 19:12:16,410 | Updated smoothed statistics on Epoch [45]!
2023-05-20 19:12:16,476 | Updated running statistics with Epoch [45] features!
2023-05-20 19:12:20,114 | Val: [ 0/34]	Time  3.333 ( 3.333)	Loss (L1) 8.527 (8.527)	Loss (EDL) 4.264 (4.264)	Loss (NIG_NLL) 3.812 (3.812)	Loss (NIG_Reg) 45.219 (45.219)
2023-05-20 19:12:21,397 | Val: [10/34]	Time  0.103 ( 0.420)	Loss (L1) 7.707 (8.174)	Loss (EDL) 4.152 (4.223)	Loss (NIG_NLL) 3.743 (3.790)	Loss (NIG_Reg) 40.872 (43.345)
2023-05-20 19:12:22,404 | Val: [20/34]	Time  0.101 ( 0.268)	Loss (L1) 8.807 (8.215)	Loss (EDL) 4.368 (4.234)	Loss (NIG_NLL) 3.901 (3.798)	Loss (NIG_Reg) 46.691 (43.562)
2023-05-20 19:12:23,413 | Val: [30/34]	Time  0.100 ( 0.214)	Loss (L1) 8.510 (8.206)	Loss (EDL) 4.231 (4.238)	Loss (NIG_NLL) 3.780 (3.802)	Loss (NIG_Reg) 45.112 (43.510)
2023-05-20 19:12:24,090 |  * Overall: MSE 108.713	L1 8.136	G-Mean 5.356	EDL 4.223	NIG_NLL 3.791	NIG_Reg 43.138
2023-05-20 19:12:24,090 |  * Many: MSE 76.930	L1 6.832	G-Mean 4.542	EDL 3.973	NIG_NLL 3.611	NIG_Reg 36.228
2023-05-20 19:12:24,090 |  * Median: MSE 163.692	L1 10.673	G-Mean 7.637	EDL 4.729	NIG_NLL 4.163	NIG_Reg 56.582
2023-05-20 19:12:24,090 |  * Low: MSE 256.842	L1 13.432	G-Mean 9.535	EDL 5.178	NIG_NLL 4.466	NIG_Reg 71.229
2023-05-20 19:12:24,091 | Best EDL Loss: 7.792
2023-05-20 19:12:24,095 | Epoch #45: Train loss [3.9301]; Val loss: MSE [108.7130], L1 [8.1356], G-Mean [5.3564], EDL [4.2226], NIG_NLL [3.791], NIG_Reg [43.138]
2023-05-20 19:12:24,095 | this_lr: 
2023-05-20 19:12:24,095 | 0.001
2023-05-20 19:12:28,423 | Epoch: [46][  0/191]	Time   4.33 (  4.33)	Data 3.3941 (3.3941)	Loss (EDL) 3.966 (3.966)
2023-05-20 19:12:34,218 | Epoch: [46][ 10/191]	Time   0.56 (  0.92)	Data 0.0002 (0.3092)	Loss (EDL) 3.597 (3.899)
2023-05-20 19:12:39,778 | Epoch: [46][ 20/191]	Time   0.56 (  0.75)	Data 0.0001 (0.1620)	Loss (EDL) 3.759 (3.900)
2023-05-20 19:12:45,284 | Epoch: [46][ 30/191]	Time   0.54 (  0.68)	Data 0.0001 (0.1098)	Loss (EDL) 3.662 (3.877)
2023-05-20 19:12:51,159 | Epoch: [46][ 40/191]	Time   0.75 (  0.66)	Data 0.0002 (0.0831)	Loss (EDL) 3.801 (3.875)
2023-05-20 19:12:56,784 | Epoch: [46][ 50/191]	Time   0.56 (  0.64)	Data 0.0001 (0.0668)	Loss (EDL) 3.779 (3.875)
2023-05-20 19:13:02,437 | Epoch: [46][ 60/191]	Time   0.54 (  0.63)	Data 0.0001 (0.0559)	Loss (EDL) 3.785 (3.883)
2023-05-20 19:13:07,982 | Epoch: [46][ 70/191]	Time   0.54 (  0.62)	Data 0.0004 (0.0481)	Loss (EDL) 3.810 (3.887)
2023-05-20 19:13:13,676 | Epoch: [46][ 80/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0422)	Loss (EDL) 3.755 (3.871)
2023-05-20 19:13:19,384 | Epoch: [46][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0376)	Loss (EDL) 3.654 (3.864)
2023-05-20 19:13:25,043 | Epoch: [46][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0339)	Loss (EDL) 3.822 (3.871)
2023-05-20 19:13:30,962 | Epoch: [46][110/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0308)	Loss (EDL) 3.830 (3.869)
2023-05-20 19:13:36,556 | Epoch: [46][120/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0283)	Loss (EDL) 3.842 (3.878)
2023-05-20 19:13:42,137 | Epoch: [46][130/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0262)	Loss (EDL) 3.990 (3.872)
2023-05-20 19:13:47,646 | Epoch: [46][140/191]	Time   0.58 (  0.59)	Data 0.0001 (0.0243)	Loss (EDL) 3.926 (3.869)
2023-05-20 19:13:53,149 | Epoch: [46][150/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0227)	Loss (EDL) 3.746 (3.869)
2023-05-20 19:13:58,623 | Epoch: [46][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0213)	Loss (EDL) 3.959 (3.867)
2023-05-20 19:14:04,155 | Epoch: [46][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0201)	Loss (EDL) 3.937 (3.866)
2023-05-20 19:14:09,692 | Epoch: [46][180/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0190)	Loss (EDL) 3.599 (3.863)
2023-05-20 19:14:15,060 | Epoch: [46][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0180)	Loss (EDL) 4.184 (3.868)
2023-05-20 19:14:15,389 | Create Epoch [46] features of all training data...
2023-05-20 19:14:45,017 | Updated smoothed statistics on Epoch [46]!
2023-05-20 19:14:45,093 | Updated running statistics with Epoch [46] features!
2023-05-20 19:14:48,894 | Val: [ 0/34]	Time  3.499 ( 3.499)	Loss (L1) 7.520 (7.520)	Loss (EDL) 4.140 (4.140)	Loss (NIG_NLL) 3.741 (3.741)	Loss (NIG_Reg) 39.895 (39.895)
2023-05-20 19:14:50,193 | Val: [10/34]	Time  0.100 ( 0.436)	Loss (L1) 8.402 (7.895)	Loss (EDL) 4.285 (4.200)	Loss (NIG_NLL) 3.839 (3.781)	Loss (NIG_Reg) 44.551 (41.864)
2023-05-20 19:14:51,196 | Val: [20/34]	Time  0.100 ( 0.276)	Loss (L1) 8.746 (7.866)	Loss (EDL) 4.397 (4.203)	Loss (NIG_NLL) 3.933 (3.786)	Loss (NIG_Reg) 46.366 (41.710)
2023-05-20 19:14:52,199 | Val: [30/34]	Time  0.100 ( 0.219)	Loss (L1) 10.607 (7.981)	Loss (EDL) 4.663 (4.218)	Loss (NIG_NLL) 4.101 (3.795)	Loss (NIG_Reg) 56.234 (42.320)
2023-05-20 19:14:52,875 |  * Overall: MSE 106.409	L1 7.924	G-Mean 5.053	EDL 4.203	NIG_NLL 3.783	NIG_Reg 42.018
2023-05-20 19:14:52,875 |  * Many: MSE 88.725	L1 7.203	G-Mean 4.533	EDL 4.055	NIG_NLL 3.673	NIG_Reg 38.194
2023-05-20 19:14:52,875 |  * Median: MSE 126.440	L1 8.990	G-Mean 6.173	EDL 4.440	NIG_NLL 3.963	NIG_Reg 47.662
2023-05-20 19:14:52,875 |  * Low: MSE 218.029	L1 11.788	G-Mean 8.098	EDL 4.953	NIG_NLL 4.328	NIG_Reg 62.515
2023-05-20 19:14:52,876 | Best EDL Loss: 7.792
2023-05-20 19:14:52,880 | Epoch #46: Train loss [3.8681]; Val loss: MSE [106.4091], L1 [7.9239], G-Mean [5.0528], EDL [4.2033], NIG_NLL [3.783], NIG_Reg [42.018]
2023-05-20 19:14:52,880 | this_lr: 
2023-05-20 19:14:52,880 | 0.001
2023-05-20 19:14:57,260 | Epoch: [47][  0/191]	Time   4.38 (  4.38)	Data 3.3573 (3.3573)	Loss (EDL) 3.919 (3.919)
2023-05-20 19:15:03,184 | Epoch: [47][ 10/191]	Time   0.56 (  0.94)	Data 0.0001 (0.3054)	Loss (EDL) 4.088 (3.924)
2023-05-20 19:15:08,726 | Epoch: [47][ 20/191]	Time   0.57 (  0.75)	Data 0.0002 (0.1601)	Loss (EDL) 3.821 (3.857)
2023-05-20 19:15:14,331 | Epoch: [47][ 30/191]	Time   0.56 (  0.69)	Data 0.0002 (0.1085)	Loss (EDL) 3.952 (3.880)
2023-05-20 19:15:19,945 | Epoch: [47][ 40/191]	Time   0.55 (  0.66)	Data 0.0005 (0.0821)	Loss (EDL) 4.016 (3.876)
2023-05-20 19:15:25,705 | Epoch: [47][ 50/191]	Time   0.60 (  0.64)	Data 0.0001 (0.0661)	Loss (EDL) 4.290 (3.887)
2023-05-20 19:15:31,470 | Epoch: [47][ 60/191]	Time   0.54 (  0.63)	Data 0.0001 (0.0553)	Loss (EDL) 3.907 (3.894)
2023-05-20 19:15:37,059 | Epoch: [47][ 70/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0475)	Loss (EDL) 3.839 (3.902)
2023-05-20 19:15:42,603 | Epoch: [47][ 80/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0417)	Loss (EDL) 4.407 (3.899)
2023-05-20 19:15:48,167 | Epoch: [47][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0371)	Loss (EDL) 3.715 (3.902)
2023-05-20 19:15:53,739 | Epoch: [47][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0335)	Loss (EDL) 3.720 (3.902)
2023-05-20 19:15:59,308 | Epoch: [47][110/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0305)	Loss (EDL) 4.009 (3.904)
2023-05-20 19:16:04,917 | Epoch: [47][120/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0280)	Loss (EDL) 4.147 (3.913)
2023-05-20 19:16:10,471 | Epoch: [47][130/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0259)	Loss (EDL) 3.918 (3.916)
2023-05-20 19:16:16,165 | Epoch: [47][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0241)	Loss (EDL) 3.872 (3.920)
2023-05-20 19:16:21,635 | Epoch: [47][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0225)	Loss (EDL) 3.789 (3.923)
2023-05-20 19:16:27,075 | Epoch: [47][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0211)	Loss (EDL) 4.035 (3.923)
2023-05-20 19:16:32,584 | Epoch: [47][170/191]	Time   0.57 (  0.58)	Data 0.0001 (0.0199)	Loss (EDL) 3.837 (3.926)
2023-05-20 19:16:38,052 | Epoch: [47][180/191]	Time   0.58 (  0.58)	Data 0.0001 (0.0188)	Loss (EDL) 3.828 (3.924)
2023-05-20 19:16:43,443 | Epoch: [47][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0178)	Loss (EDL) 3.715 (3.923)
2023-05-20 19:16:43,795 | Create Epoch [47] features of all training data...
2023-05-20 19:17:13,221 | Updated smoothed statistics on Epoch [47]!
2023-05-20 19:17:13,286 | Updated running statistics with Epoch [47] features!
2023-05-20 19:17:16,868 | Val: [ 0/34]	Time  3.302 ( 3.302)	Loss (L1) 6.814 (6.814)	Loss (EDL) 4.014 (4.014)	Loss (NIG_NLL) 3.653 (3.653)	Loss (NIG_Reg) 36.156 (36.156)
2023-05-20 19:17:18,322 | Val: [10/34]	Time  0.101 ( 0.432)	Loss (L1) 8.349 (8.130)	Loss (EDL) 4.223 (4.229)	Loss (NIG_NLL) 3.780 (3.797)	Loss (NIG_Reg) 44.273 (43.122)
2023-05-20 19:17:19,323 | Val: [20/34]	Time  0.100 ( 0.274)	Loss (L1) 8.733 (7.990)	Loss (EDL) 4.348 (4.214)	Loss (NIG_NLL) 3.885 (3.790)	Loss (NIG_Reg) 46.301 (42.376)
2023-05-20 19:17:20,326 | Val: [30/34]	Time  0.100 ( 0.218)	Loss (L1) 7.995 (7.899)	Loss (EDL) 4.243 (4.195)	Loss (NIG_NLL) 3.819 (3.776)	Loss (NIG_Reg) 42.402 (41.894)
2023-05-20 19:17:20,978 |  * Overall: MSE 104.689	L1 7.877	G-Mean 5.018	EDL 4.186	NIG_NLL 3.768	NIG_Reg 41.777
2023-05-20 19:17:20,978 |  * Many: MSE 93.862	L1 7.407	G-Mean 4.669	EDL 4.080	NIG_NLL 3.687	NIG_Reg 39.288
2023-05-20 19:17:20,978 |  * Median: MSE 122.695	L1 8.746	G-Mean 5.789	EDL 4.392	NIG_NLL 3.929	NIG_Reg 46.366
2023-05-20 19:17:20,978 |  * Low: MSE 157.151	L1 9.915	G-Mean 6.674	EDL 4.617	NIG_NLL 4.091	NIG_Reg 52.590
2023-05-20 19:17:20,979 | Best EDL Loss: 7.792
2023-05-20 19:17:20,982 | Epoch #47: Train loss [3.9231]; Val loss: MSE [104.6891], L1 [7.8770], G-Mean [5.0183], EDL [4.1861], NIG_NLL [3.768], NIG_Reg [41.777]
2023-05-20 19:17:20,983 | this_lr: 
2023-05-20 19:17:20,983 | 0.001
2023-05-20 19:17:25,280 | Epoch: [48][  0/191]	Time   4.30 (  4.30)	Data 3.3222 (3.3222)	Loss (EDL) 3.848 (3.848)
2023-05-20 19:17:30,915 | Epoch: [48][ 10/191]	Time   0.57 (  0.90)	Data 0.0001 (0.3022)	Loss (EDL) 3.727 (3.828)
2023-05-20 19:17:36,514 | Epoch: [48][ 20/191]	Time   0.55 (  0.74)	Data 0.0002 (0.1584)	Loss (EDL) 4.057 (3.873)
2023-05-20 19:17:42,140 | Epoch: [48][ 30/191]	Time   0.58 (  0.68)	Data 0.0002 (0.1074)	Loss (EDL) 4.015 (3.871)
2023-05-20 19:17:47,943 | Epoch: [48][ 40/191]	Time   0.59 (  0.66)	Data 0.0001 (0.0813)	Loss (EDL) 3.925 (3.870)
2023-05-20 19:17:53,515 | Epoch: [48][ 50/191]	Time   0.56 (  0.64)	Data 0.0001 (0.0654)	Loss (EDL) 3.787 (3.883)
2023-05-20 19:17:59,179 | Epoch: [48][ 60/191]	Time   0.56 (  0.63)	Data 0.0002 (0.0547)	Loss (EDL) 3.796 (3.882)
2023-05-20 19:18:04,901 | Epoch: [48][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0470)	Loss (EDL) 3.719 (3.878)
2023-05-20 19:18:10,614 | Epoch: [48][ 80/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0412)	Loss (EDL) 3.956 (3.871)
2023-05-20 19:18:16,311 | Epoch: [48][ 90/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0367)	Loss (EDL) 3.783 (3.858)
2023-05-20 19:18:21,955 | Epoch: [48][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0331)	Loss (EDL) 3.609 (3.846)
2023-05-20 19:18:27,987 | Epoch: [48][110/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0302)	Loss (EDL) 3.962 (3.856)
2023-05-20 19:18:33,634 | Epoch: [48][120/191]	Time   0.56 (  0.60)	Data 0.0003 (0.0277)	Loss (EDL) 3.926 (3.865)
2023-05-20 19:18:39,167 | Epoch: [48][130/191]	Time   0.53 (  0.60)	Data 0.0001 (0.0256)	Loss (EDL) 3.778 (3.866)
2023-05-20 19:18:44,625 | Epoch: [48][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0238)	Loss (EDL) 4.269 (3.870)
2023-05-20 19:18:50,079 | Epoch: [48][150/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0222)	Loss (EDL) 3.818 (3.874)
2023-05-20 19:18:55,579 | Epoch: [48][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0209)	Loss (EDL) 4.028 (3.879)
2023-05-20 19:19:01,030 | Epoch: [48][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0197)	Loss (EDL) 3.740 (3.878)
2023-05-20 19:19:06,613 | Epoch: [48][180/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0186)	Loss (EDL) 3.972 (3.880)
2023-05-20 19:19:12,219 | Epoch: [48][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0176)	Loss (EDL) 3.980 (3.884)
2023-05-20 19:19:12,534 | Create Epoch [48] features of all training data...
2023-05-20 19:19:41,890 | Updated smoothed statistics on Epoch [48]!
2023-05-20 19:19:41,960 | Updated running statistics with Epoch [48] features!
2023-05-20 19:19:45,507 | Val: [ 0/34]	Time  3.282 ( 3.282)	Loss (L1) 7.582 (7.582)	Loss (EDL) 4.158 (4.158)	Loss (NIG_NLL) 3.756 (3.756)	Loss (NIG_Reg) 40.223 (40.223)
2023-05-20 19:19:46,719 | Val: [10/34]	Time  0.101 ( 0.408)	Loss (L1) 8.470 (7.945)	Loss (EDL) 4.318 (4.205)	Loss (NIG_NLL) 3.869 (3.783)	Loss (NIG_Reg) 44.915 (42.131)
2023-05-20 19:19:47,733 | Val: [20/34]	Time  0.101 ( 0.262)	Loss (L1) 8.002 (7.870)	Loss (EDL) 4.245 (4.196)	Loss (NIG_NLL) 3.821 (3.779)	Loss (NIG_Reg) 42.421 (41.731)
2023-05-20 19:19:48,747 | Val: [30/34]	Time  0.101 ( 0.210)	Loss (L1) 8.915 (7.921)	Loss (EDL) 4.326 (4.201)	Loss (NIG_NLL) 3.854 (3.781)	Loss (NIG_Reg) 47.266 (42.000)
2023-05-20 19:19:49,419 |  * Overall: MSE 104.782	L1 7.883	G-Mean 5.051	EDL 4.193	NIG_NLL 3.775	NIG_Reg 41.801
2023-05-20 19:19:49,419 |  * Many: MSE 95.692	L1 7.531	G-Mean 4.770	EDL 4.103	NIG_NLL 3.704	NIG_Reg 39.933
2023-05-20 19:19:49,419 |  * Median: MSE 110.574	L1 8.195	G-Mean 5.445	EDL 4.312	NIG_NLL 3.878	NIG_Reg 43.449
2023-05-20 19:19:49,419 |  * Low: MSE 174.611	L1 10.349	G-Mean 7.041	EDL 4.717	NIG_NLL 4.168	NIG_Reg 54.890
2023-05-20 19:19:49,419 | Best EDL Loss: 7.792
2023-05-20 19:19:49,423 | Epoch #48: Train loss [3.8839]; Val loss: MSE [104.7816], L1 [7.8831], G-Mean [5.0507], EDL [4.1934], NIG_NLL [3.775], NIG_Reg [41.801]
2023-05-20 19:19:49,423 | this_lr: 
2023-05-20 19:19:49,423 | 0.001
2023-05-20 19:19:54,031 | Epoch: [49][  0/191]	Time   4.61 (  4.61)	Data 3.6707 (3.6707)	Loss (EDL) 3.617 (3.617)
2023-05-20 19:19:59,548 | Epoch: [49][ 10/191]	Time   0.60 (  0.92)	Data 0.0001 (0.3339)	Loss (EDL) 3.893 (3.771)
2023-05-20 19:20:05,308 | Epoch: [49][ 20/191]	Time   0.57 (  0.76)	Data 0.0001 (0.1750)	Loss (EDL) 3.727 (3.829)
2023-05-20 19:20:10,900 | Epoch: [49][ 30/191]	Time   0.54 (  0.69)	Data 0.0001 (0.1186)	Loss (EDL) 3.752 (3.869)
2023-05-20 19:20:16,472 | Epoch: [49][ 40/191]	Time   0.57 (  0.66)	Data 0.0001 (0.0897)	Loss (EDL) 3.667 (3.859)
2023-05-20 19:20:22,079 | Epoch: [49][ 50/191]	Time   0.56 (  0.64)	Data 0.0002 (0.0722)	Loss (EDL) 3.742 (3.858)
2023-05-20 19:20:27,583 | Epoch: [49][ 60/191]	Time   0.55 (  0.63)	Data 0.0001 (0.0604)	Loss (EDL) 3.920 (3.858)
2023-05-20 19:20:33,142 | Epoch: [49][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0519)	Loss (EDL) 3.860 (3.867)
2023-05-20 19:20:38,759 | Epoch: [49][ 80/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0455)	Loss (EDL) 3.718 (3.876)
2023-05-20 19:20:44,722 | Epoch: [49][ 90/191]	Time   0.89 (  0.61)	Data 0.0004 (0.0406)	Loss (EDL) 3.702 (3.869)
2023-05-20 19:20:50,330 | Epoch: [49][100/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0366)	Loss (EDL) 3.834 (3.864)
2023-05-20 19:20:55,905 | Epoch: [49][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0333)	Loss (EDL) 3.862 (3.860)
2023-05-20 19:21:01,469 | Epoch: [49][120/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0306)	Loss (EDL) 4.021 (3.869)
2023-05-20 19:21:07,029 | Epoch: [49][130/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0283)	Loss (EDL) 3.673 (3.870)
2023-05-20 19:21:12,523 | Epoch: [49][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0263)	Loss (EDL) 3.902 (3.866)
2023-05-20 19:21:17,984 | Epoch: [49][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0245)	Loss (EDL) 4.138 (3.869)
2023-05-20 19:21:23,466 | Epoch: [49][160/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0230)	Loss (EDL) 3.576 (3.874)
2023-05-20 19:21:29,183 | Epoch: [49][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0217)	Loss (EDL) 3.775 (3.876)
2023-05-20 19:21:34,678 | Epoch: [49][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0205)	Loss (EDL) 4.100 (3.879)
2023-05-20 19:21:40,064 | Epoch: [49][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0194)	Loss (EDL) 3.654 (3.878)
2023-05-20 19:21:40,408 | Create Epoch [49] features of all training data...
2023-05-20 19:22:09,751 | Updated smoothed statistics on Epoch [49]!
2023-05-20 19:22:09,828 | Updated running statistics with Epoch [49] features!
2023-05-20 19:22:13,359 | Val: [ 0/34]	Time  3.237 ( 3.237)	Loss (L1) 8.591 (8.591)	Loss (EDL) 4.378 (4.378)	Loss (NIG_NLL) 3.922 (3.922)	Loss (NIG_Reg) 45.587 (45.587)
2023-05-20 19:22:14,648 | Val: [10/34]	Time  0.100 ( 0.411)	Loss (L1) 7.661 (8.201)	Loss (EDL) 4.151 (4.266)	Loss (NIG_NLL) 3.745 (3.831)	Loss (NIG_Reg) 40.632 (43.501)
2023-05-20 19:22:15,652 | Val: [20/34]	Time  0.102 ( 0.263)	Loss (L1) 8.475 (8.161)	Loss (EDL) 4.359 (4.280)	Loss (NIG_NLL) 3.910 (3.847)	Loss (NIG_Reg) 44.937 (43.287)
2023-05-20 19:22:16,658 | Val: [30/34]	Time  0.101 ( 0.211)	Loss (L1) 9.334 (8.164)	Loss (EDL) 4.421 (4.281)	Loss (NIG_NLL) 3.926 (3.848)	Loss (NIG_Reg) 49.494 (43.300)
2023-05-20 19:22:17,280 |  * Overall: MSE 108.394	L1 8.116	G-Mean 5.330	EDL 4.271	NIG_NLL 3.840	NIG_Reg 43.047
2023-05-20 19:22:17,280 |  * Many: MSE 92.781	L1 7.523	G-Mean 4.919	EDL 4.152	NIG_NLL 3.753	NIG_Reg 39.907
2023-05-20 19:22:17,280 |  * Median: MSE 134.769	L1 9.128	G-Mean 6.228	EDL 4.481	NIG_NLL 3.997	NIG_Reg 48.398
2023-05-20 19:22:17,280 |  * Low: MSE 182.915	L1 10.918	G-Mean 7.387	EDL 4.808	NIG_NLL 4.229	NIG_Reg 57.908
2023-05-20 19:22:17,281 | Best EDL Loss: 7.792
2023-05-20 19:22:17,284 | Epoch #49: Train loss [3.8780]; Val loss: MSE [108.3945], L1 [8.1163], G-Mean [5.3298], EDL [4.2709], NIG_NLL [3.840], NIG_Reg [43.047]
2023-05-20 19:22:17,284 | this_lr: 
2023-05-20 19:22:17,284 | 0.001
2023-05-20 19:22:21,696 | Epoch: [50][  0/191]	Time   4.41 (  4.41)	Data 3.4110 (3.4110)	Loss (EDL) 3.713 (3.713)
2023-05-20 19:22:27,346 | Epoch: [50][ 10/191]	Time   0.59 (  0.91)	Data 0.0001 (0.3103)	Loss (EDL) 3.951 (3.821)
2023-05-20 19:22:32,919 | Epoch: [50][ 20/191]	Time   0.55 (  0.74)	Data 0.0003 (0.1627)	Loss (EDL) 3.783 (3.833)
2023-05-20 19:22:38,562 | Epoch: [50][ 30/191]	Time   0.58 (  0.69)	Data 0.0002 (0.1103)	Loss (EDL) 3.638 (3.820)
2023-05-20 19:22:44,207 | Epoch: [50][ 40/191]	Time   0.56 (  0.66)	Data 0.0002 (0.0834)	Loss (EDL) 3.834 (3.830)
2023-05-20 19:22:49,787 | Epoch: [50][ 50/191]	Time   0.55 (  0.64)	Data 0.0003 (0.0671)	Loss (EDL) 3.628 (3.828)
2023-05-20 19:22:55,433 | Epoch: [50][ 60/191]	Time   0.57 (  0.63)	Data 0.0001 (0.0562)	Loss (EDL) 4.254 (3.843)
2023-05-20 19:23:01,083 | Epoch: [50][ 70/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0483)	Loss (EDL) 3.922 (3.842)
2023-05-20 19:23:07,026 | Epoch: [50][ 80/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0424)	Loss (EDL) 4.099 (3.844)
2023-05-20 19:23:12,822 | Epoch: [50][ 90/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0377)	Loss (EDL) 3.788 (3.847)
2023-05-20 19:23:18,540 | Epoch: [50][100/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0340)	Loss (EDL) 4.024 (3.856)
2023-05-20 19:23:24,270 | Epoch: [50][110/191]	Time   0.59 (  0.60)	Data 0.0002 (0.0310)	Loss (EDL) 4.068 (3.860)
2023-05-20 19:23:29,883 | Epoch: [50][120/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0284)	Loss (EDL) 3.956 (3.863)
2023-05-20 19:23:35,520 | Epoch: [50][130/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0263)	Loss (EDL) 3.993 (3.861)
2023-05-20 19:23:41,050 | Epoch: [50][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0244)	Loss (EDL) 3.961 (3.865)
2023-05-20 19:23:46,817 | Epoch: [50][150/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0228)	Loss (EDL) 3.902 (3.871)
2023-05-20 19:23:52,269 | Epoch: [50][160/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0214)	Loss (EDL) 3.914 (3.872)
2023-05-20 19:23:57,800 | Epoch: [50][170/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0202)	Loss (EDL) 4.019 (3.873)
2023-05-20 19:24:03,309 | Epoch: [50][180/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0191)	Loss (EDL) 4.127 (3.876)
2023-05-20 19:24:08,671 | Epoch: [50][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0181)	Loss (EDL) 4.271 (3.875)
2023-05-20 19:24:08,992 | Create Epoch [50] features of all training data...
2023-05-20 19:24:38,579 | Updated smoothed statistics on Epoch [50]!
2023-05-20 19:24:38,650 | Updated running statistics with Epoch [50] features!
2023-05-20 19:24:42,358 | Val: [ 0/34]	Time  3.396 ( 3.396)	Loss (L1) 7.542 (7.542)	Loss (EDL) 4.149 (4.149)	Loss (NIG_NLL) 3.749 (3.749)	Loss (NIG_Reg) 40.002 (40.002)
2023-05-20 19:24:43,377 | Val: [10/34]	Time  0.100 ( 0.401)	Loss (L1) 8.193 (7.666)	Loss (EDL) 4.275 (4.165)	Loss (NIG_NLL) 3.841 (3.759)	Loss (NIG_Reg) 43.436 (40.650)
2023-05-20 19:24:44,380 | Val: [20/34]	Time  0.100 ( 0.258)	Loss (L1) 8.513 (7.702)	Loss (EDL) 4.344 (4.185)	Loss (NIG_NLL) 3.893 (3.777)	Loss (NIG_Reg) 45.127 (40.839)
2023-05-20 19:24:45,386 | Val: [30/34]	Time  0.100 ( 0.207)	Loss (L1) 8.716 (7.759)	Loss (EDL) 4.311 (4.194)	Loss (NIG_NLL) 3.849 (3.782)	Loss (NIG_Reg) 46.208 (41.141)
2023-05-20 19:24:46,034 |  * Overall: MSE 98.627	L1 7.706	G-Mean 4.957	EDL 4.181	NIG_NLL 3.772	NIG_Reg 40.859
2023-05-20 19:24:46,034 |  * Many: MSE 87.209	L1 7.247	G-Mean 4.664	EDL 4.068	NIG_NLL 3.684	NIG_Reg 38.426
2023-05-20 19:24:46,034 |  * Median: MSE 108.549	L1 8.097	G-Mean 5.110	EDL 4.310	NIG_NLL 3.881	NIG_Reg 42.929
2023-05-20 19:24:46,034 |  * Low: MSE 179.027	L1 10.954	G-Mean 8.099	EDL 4.891	NIG_NLL 4.310	NIG_Reg 58.111
2023-05-20 19:24:46,035 | Best EDL Loss: 7.706
2023-05-20 19:24:46,039 | ===> Saving current best checkpoint...
2023-05-20 19:24:53,280 | Epoch #50: Train loss [3.8750]; Val loss: MSE [98.6270], L1 [7.7058], G-Mean [4.9568], EDL [4.1811], NIG_NLL [3.772], NIG_Reg [40.859]
2023-05-20 19:24:53,281 | this_lr: 
2023-05-20 19:24:53,281 | 0.001
2023-05-20 19:24:57,523 | Epoch: [51][  0/191]	Time   4.24 (  4.24)	Data 3.3875 (3.3875)	Loss (EDL) 3.673 (3.673)
2023-05-20 19:25:03,204 | Epoch: [51][ 10/191]	Time   0.55 (  0.90)	Data 0.0001 (0.3081)	Loss (EDL) 3.701 (3.853)
2023-05-20 19:25:08,783 | Epoch: [51][ 20/191]	Time   0.54 (  0.74)	Data 0.0002 (0.1615)	Loss (EDL) 3.814 (3.824)
2023-05-20 19:25:14,321 | Epoch: [51][ 30/191]	Time   0.54 (  0.68)	Data 0.0002 (0.1095)	Loss (EDL) 3.927 (3.819)
2023-05-20 19:25:19,872 | Epoch: [51][ 40/191]	Time   0.53 (  0.65)	Data 0.0003 (0.0828)	Loss (EDL) 3.576 (3.822)
2023-05-20 19:25:25,653 | Epoch: [51][ 50/191]	Time   0.56 (  0.63)	Data 0.0001 (0.0666)	Loss (EDL) 3.610 (3.800)
2023-05-20 19:25:31,206 | Epoch: [51][ 60/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0557)	Loss (EDL) 3.906 (3.786)
2023-05-20 19:25:36,814 | Epoch: [51][ 70/191]	Time   0.56 (  0.61)	Data 0.0001 (0.0479)	Loss (EDL) 4.086 (3.813)
2023-05-20 19:25:42,385 | Epoch: [51][ 80/191]	Time   0.54 (  0.61)	Data 0.0003 (0.0420)	Loss (EDL) 4.162 (3.835)
2023-05-20 19:25:47,926 | Epoch: [51][ 90/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0374)	Loss (EDL) 3.693 (3.846)
2023-05-20 19:25:53,555 | Epoch: [51][100/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0338)	Loss (EDL) 3.694 (3.848)
2023-05-20 19:25:59,197 | Epoch: [51][110/191]	Time   0.56 (  0.59)	Data 0.0003 (0.0308)	Loss (EDL) 3.895 (3.858)
2023-05-20 19:26:05,172 | Epoch: [51][120/191]	Time   0.58 (  0.59)	Data 0.0002 (0.0282)	Loss (EDL) 3.711 (3.857)
2023-05-20 19:26:10,714 | Epoch: [51][130/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0261)	Loss (EDL) 3.770 (3.857)
2023-05-20 19:26:16,195 | Epoch: [51][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0243)	Loss (EDL) 3.692 (3.857)
2023-05-20 19:26:21,683 | Epoch: [51][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0227)	Loss (EDL) 3.840 (3.854)
2023-05-20 19:26:27,126 | Epoch: [51][160/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0213)	Loss (EDL) 3.967 (3.857)
2023-05-20 19:26:32,602 | Epoch: [51][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0200)	Loss (EDL) 3.770 (3.853)
2023-05-20 19:26:38,091 | Epoch: [51][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0189)	Loss (EDL) 3.816 (3.857)
2023-05-20 19:26:43,522 | Epoch: [51][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0180)	Loss (EDL) 3.628 (3.853)
2023-05-20 19:26:43,843 | Create Epoch [51] features of all training data...
2023-05-20 19:27:13,352 | Updated smoothed statistics on Epoch [51]!
2023-05-20 19:27:13,419 | Updated running statistics with Epoch [51] features!
2023-05-20 19:27:17,457 | Val: [ 0/34]	Time  3.744 ( 3.744)	Loss (L1) 7.363 (7.363)	Loss (EDL) 4.167 (4.167)	Loss (NIG_NLL) 3.777 (3.777)	Loss (NIG_Reg) 39.048 (39.048)
2023-05-20 19:27:18,458 | Val: [10/34]	Time  0.100 ( 0.431)	Loss (L1) 8.313 (7.879)	Loss (EDL) 4.251 (4.227)	Loss (NIG_NLL) 3.810 (3.809)	Loss (NIG_Reg) 44.071 (41.774)
2023-05-20 19:27:19,462 | Val: [20/34]	Time  0.100 ( 0.274)	Loss (L1) 7.997 (7.809)	Loss (EDL) 4.252 (4.210)	Loss (NIG_NLL) 3.828 (3.796)	Loss (NIG_Reg) 42.392 (41.399)
2023-05-20 19:27:20,465 | Val: [30/34]	Time  0.101 ( 0.218)	Loss (L1) 9.451 (7.842)	Loss (EDL) 4.431 (4.210)	Loss (NIG_NLL) 3.930 (3.794)	Loss (NIG_Reg) 50.099 (41.575)
2023-05-20 19:27:21,125 |  * Overall: MSE 99.429	L1 7.776	G-Mean 5.144	EDL 4.195	NIG_NLL 3.783	NIG_Reg 41.227
2023-05-20 19:27:21,125 |  * Many: MSE 83.840	L1 7.155	G-Mean 4.744	EDL 4.051	NIG_NLL 3.672	NIG_Reg 37.935
2023-05-20 19:27:21,125 |  * Median: MSE 115.661	L1 8.550	G-Mean 5.879	EDL 4.405	NIG_NLL 3.952	NIG_Reg 45.324
2023-05-20 19:27:21,125 |  * Low: MSE 201.764	L1 11.502	G-Mean 7.630	EDL 4.973	NIG_NLL 4.363	NIG_Reg 60.983
2023-05-20 19:27:21,126 | Best EDL Loss: 7.706
2023-05-20 19:27:21,130 | Epoch #51: Train loss [3.8526]; Val loss: MSE [99.4288], L1 [7.7763], G-Mean [5.1440], EDL [4.1952], NIG_NLL [3.783], NIG_Reg [41.227]
2023-05-20 19:27:21,130 | this_lr: 
2023-05-20 19:27:21,130 | 0.001
2023-05-20 19:27:25,631 | Epoch: [52][  0/191]	Time   4.49 (  4.49)	Data 3.4414 (3.4414)	Loss (EDL) 3.821 (3.821)
2023-05-20 19:27:31,332 | Epoch: [52][ 10/191]	Time   0.56 (  0.93)	Data 0.0002 (0.3130)	Loss (EDL) 3.852 (3.782)
2023-05-20 19:27:37,178 | Epoch: [52][ 20/191]	Time   0.58 (  0.76)	Data 0.0001 (0.1641)	Loss (EDL) 3.665 (3.787)
2023-05-20 19:27:42,734 | Epoch: [52][ 30/191]	Time   0.56 (  0.70)	Data 0.0002 (0.1113)	Loss (EDL) 3.638 (3.788)
2023-05-20 19:27:48,271 | Epoch: [52][ 40/191]	Time   0.56 (  0.66)	Data 0.0002 (0.0842)	Loss (EDL) 3.806 (3.805)
2023-05-20 19:27:53,978 | Epoch: [52][ 50/191]	Time   0.60 (  0.64)	Data 0.0002 (0.0677)	Loss (EDL) 3.644 (3.800)
2023-05-20 19:27:59,565 | Epoch: [52][ 60/191]	Time   0.55 (  0.63)	Data 0.0001 (0.0566)	Loss (EDL) 3.618 (3.805)
2023-05-20 19:28:05,215 | Epoch: [52][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0487)	Loss (EDL) 3.789 (3.799)
2023-05-20 19:28:10,984 | Epoch: [52][ 80/191]	Time   0.57 (  0.62)	Data 0.0001 (0.0427)	Loss (EDL) 3.918 (3.806)
2023-05-20 19:28:16,690 | Epoch: [52][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0380)	Loss (EDL) 4.195 (3.817)
2023-05-20 19:28:22,364 | Epoch: [52][100/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0343)	Loss (EDL) 4.079 (3.814)
2023-05-20 19:28:27,965 | Epoch: [52][110/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0312)	Loss (EDL) 3.765 (3.816)
2023-05-20 19:28:33,674 | Epoch: [52][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0287)	Loss (EDL) 3.535 (3.807)
2023-05-20 19:28:39,246 | Epoch: [52][130/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0265)	Loss (EDL) 3.764 (3.811)
2023-05-20 19:28:44,730 | Epoch: [52][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0246)	Loss (EDL) 3.803 (3.815)
2023-05-20 19:28:50,146 | Epoch: [52][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0230)	Loss (EDL) 3.896 (3.825)
2023-05-20 19:28:55,811 | Epoch: [52][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0216)	Loss (EDL) 3.892 (3.827)
2023-05-20 19:29:01,257 | Epoch: [52][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0203)	Loss (EDL) 3.812 (3.822)
2023-05-20 19:29:06,718 | Epoch: [52][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0192)	Loss (EDL) 3.754 (3.816)
2023-05-20 19:29:12,110 | Epoch: [52][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0182)	Loss (EDL) 3.798 (3.817)
2023-05-20 19:29:12,419 | Create Epoch [52] features of all training data...
2023-05-20 19:29:41,859 | Updated smoothed statistics on Epoch [52]!
2023-05-20 19:29:41,925 | Updated running statistics with Epoch [52] features!
2023-05-20 19:29:45,871 | Val: [ 0/34]	Time  3.645 ( 3.645)	Loss (L1) 6.810 (6.810)	Loss (EDL) 3.990 (3.990)	Loss (NIG_NLL) 3.629 (3.629)	Loss (NIG_Reg) 36.114 (36.114)
2023-05-20 19:29:47,065 | Val: [10/34]	Time  0.100 ( 0.440)	Loss (L1) 7.846 (7.696)	Loss (EDL) 4.180 (4.169)	Loss (NIG_NLL) 3.764 (3.761)	Loss (NIG_Reg) 41.600 (40.809)
2023-05-20 19:29:48,071 | Val: [20/34]	Time  0.101 ( 0.278)	Loss (L1) 7.942 (7.643)	Loss (EDL) 4.271 (4.165)	Loss (NIG_NLL) 3.850 (3.760)	Loss (NIG_Reg) 42.103 (40.525)
2023-05-20 19:29:49,084 | Val: [30/34]	Time  0.100 ( 0.221)	Loss (L1) 9.027 (7.687)	Loss (EDL) 4.412 (4.181)	Loss (NIG_NLL) 3.934 (3.774)	Loss (NIG_Reg) 47.863 (40.760)
2023-05-20 19:29:49,739 |  * Overall: MSE 98.692	L1 7.648	G-Mean 4.973	EDL 4.171	NIG_NLL 3.765	NIG_Reg 40.553
2023-05-20 19:29:49,739 |  * Many: MSE 88.571	L1 7.233	G-Mean 4.664	EDL 4.074	NIG_NLL 3.691	NIG_Reg 38.355
2023-05-20 19:29:49,739 |  * Median: MSE 109.674	L1 8.166	G-Mean 5.491	EDL 4.308	NIG_NLL 3.876	NIG_Reg 43.291
2023-05-20 19:29:49,739 |  * Low: MSE 163.904	L1 10.133	G-Mean 6.938	EDL 4.703	NIG_NLL 4.166	NIG_Reg 53.742
2023-05-20 19:29:49,739 | Best EDL Loss: 7.648
2023-05-20 19:29:49,743 | ===> Saving current best checkpoint...
2023-05-20 19:29:56,870 | Epoch #52: Train loss [3.8169]; Val loss: MSE [98.6915], L1 [7.6478], G-Mean [4.9730], EDL [4.1710], NIG_NLL [3.765], NIG_Reg [40.553]
2023-05-20 19:29:56,872 | this_lr: 
2023-05-20 19:29:56,872 | 0.001
2023-05-20 19:30:01,208 | Epoch: [53][  0/191]	Time   4.33 (  4.33)	Data 3.4312 (3.4312)	Loss (EDL) 3.706 (3.706)
2023-05-20 19:30:06,951 | Epoch: [53][ 10/191]	Time   0.56 (  0.92)	Data 0.0001 (0.3121)	Loss (EDL) 3.972 (3.782)
2023-05-20 19:30:12,541 | Epoch: [53][ 20/191]	Time   0.56 (  0.75)	Data 0.0003 (0.1636)	Loss (EDL) 3.887 (3.807)
2023-05-20 19:30:18,059 | Epoch: [53][ 30/191]	Time   0.57 (  0.68)	Data 0.0001 (0.1109)	Loss (EDL) 3.781 (3.809)
2023-05-20 19:30:23,606 | Epoch: [53][ 40/191]	Time   0.55 (  0.65)	Data 0.0001 (0.0839)	Loss (EDL) 3.520 (3.803)
2023-05-20 19:30:29,370 | Epoch: [53][ 50/191]	Time   0.77 (  0.64)	Data 0.0001 (0.0675)	Loss (EDL) 4.026 (3.800)
2023-05-20 19:30:34,938 | Epoch: [53][ 60/191]	Time   0.56 (  0.62)	Data 0.0003 (0.0564)	Loss (EDL) 3.739 (3.786)
2023-05-20 19:30:40,559 | Epoch: [53][ 70/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0485)	Loss (EDL) 3.838 (3.798)
2023-05-20 19:30:46,141 | Epoch: [53][ 80/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0426)	Loss (EDL) 3.961 (3.802)
2023-05-20 19:30:51,842 | Epoch: [53][ 90/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0379)	Loss (EDL) 3.943 (3.803)
2023-05-20 19:30:57,491 | Epoch: [53][100/191]	Time   0.57 (  0.60)	Data 0.0003 (0.0342)	Loss (EDL) 3.620 (3.799)
2023-05-20 19:31:03,122 | Epoch: [53][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0311)	Loss (EDL) 3.787 (3.793)
2023-05-20 19:31:08,775 | Epoch: [53][120/191]	Time   0.56 (  0.59)	Data 0.0003 (0.0286)	Loss (EDL) 3.579 (3.798)
2023-05-20 19:31:14,583 | Epoch: [53][130/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0264)	Loss (EDL) 3.861 (3.808)
2023-05-20 19:31:20,063 | Epoch: [53][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0246)	Loss (EDL) 3.659 (3.807)
2023-05-20 19:31:25,528 | Epoch: [53][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0229)	Loss (EDL) 3.857 (3.806)
2023-05-20 19:31:30,995 | Epoch: [53][160/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0215)	Loss (EDL) 3.799 (3.807)
2023-05-20 19:31:36,475 | Epoch: [53][170/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0203)	Loss (EDL) 3.786 (3.812)
2023-05-20 19:31:41,951 | Epoch: [53][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0192)	Loss (EDL) 3.724 (3.817)
2023-05-20 19:31:47,362 | Epoch: [53][190/191]	Time   0.48 (  0.58)	Data 0.0001 (0.0182)	Loss (EDL) 3.902 (3.821)
2023-05-20 19:31:47,666 | Create Epoch [53] features of all training data...
2023-05-20 19:32:17,671 | Updated smoothed statistics on Epoch [53]!
2023-05-20 19:32:17,748 | Updated running statistics with Epoch [53] features!
2023-05-20 19:32:21,448 | Val: [ 0/34]	Time  3.390 ( 3.390)	Loss (L1) 7.344 (7.344)	Loss (EDL) 4.123 (4.123)	Loss (NIG_NLL) 3.733 (3.733)	Loss (NIG_Reg) 38.951 (38.951)
2023-05-20 19:32:22,616 | Val: [10/34]	Time  0.100 ( 0.414)	Loss (L1) 7.007 (7.743)	Loss (EDL) 4.023 (4.159)	Loss (NIG_NLL) 3.651 (3.748)	Loss (NIG_Reg) 37.155 (41.056)
2023-05-20 19:32:23,620 | Val: [20/34]	Time  0.101 ( 0.265)	Loss (L1) 9.045 (7.841)	Loss (EDL) 4.411 (4.187)	Loss (NIG_NLL) 3.932 (3.772)	Loss (NIG_Reg) 47.952 (41.576)
2023-05-20 19:32:24,624 | Val: [30/34]	Time  0.101 ( 0.212)	Loss (L1) 8.485 (7.840)	Loss (EDL) 4.263 (4.184)	Loss (NIG_NLL) 3.813 (3.769)	Loss (NIG_Reg) 44.982 (41.569)
2023-05-20 19:32:25,260 |  * Overall: MSE 101.758	L1 7.787	G-Mean 4.977	EDL 4.173	NIG_NLL 3.760	NIG_Reg 41.289
2023-05-20 19:32:25,261 |  * Many: MSE 86.940	L1 7.195	G-Mean 4.598	EDL 4.042	NIG_NLL 3.660	NIG_Reg 38.152
2023-05-20 19:32:25,261 |  * Median: MSE 132.603	L1 9.001	G-Mean 5.956	EDL 4.447	NIG_NLL 3.970	NIG_Reg 47.716
2023-05-20 19:32:25,261 |  * Low: MSE 156.410	L1 10.020	G-Mean 6.391	EDL 4.648	NIG_NLL 4.117	NIG_Reg 53.141
2023-05-20 19:32:25,261 | Best EDL Loss: 7.648
2023-05-20 19:32:25,265 | Epoch #53: Train loss [3.8210]; Val loss: MSE [101.7580], L1 [7.7868], G-Mean [4.9766], EDL [4.1726], NIG_NLL [3.760], NIG_Reg [41.289]
2023-05-20 19:32:25,266 | this_lr: 
2023-05-20 19:32:25,266 | 0.001
2023-05-20 19:32:29,736 | Epoch: [54][  0/191]	Time   4.47 (  4.47)	Data 3.3875 (3.3875)	Loss (EDL) 3.899 (3.899)
2023-05-20 19:32:35,405 | Epoch: [54][ 10/191]	Time   0.56 (  0.92)	Data 0.0002 (0.3082)	Loss (EDL) 3.605 (3.797)
2023-05-20 19:32:41,238 | Epoch: [54][ 20/191]	Time   0.56 (  0.76)	Data 0.0001 (0.1615)	Loss (EDL) 3.595 (3.779)
2023-05-20 19:32:46,800 | Epoch: [54][ 30/191]	Time   0.55 (  0.69)	Data 0.0002 (0.1095)	Loss (EDL) 4.010 (3.782)
2023-05-20 19:32:52,463 | Epoch: [54][ 40/191]	Time   0.57 (  0.66)	Data 0.0001 (0.0828)	Loss (EDL) 4.036 (3.788)
2023-05-20 19:32:58,158 | Epoch: [54][ 50/191]	Time   0.56 (  0.64)	Data 0.0001 (0.0666)	Loss (EDL) 3.803 (3.785)
2023-05-20 19:33:03,743 | Epoch: [54][ 60/191]	Time   0.55 (  0.63)	Data 0.0004 (0.0557)	Loss (EDL) 3.666 (3.781)
2023-05-20 19:33:09,369 | Epoch: [54][ 70/191]	Time   0.58 (  0.62)	Data 0.0002 (0.0479)	Loss (EDL) 3.920 (3.776)
2023-05-20 19:33:15,134 | Epoch: [54][ 80/191]	Time   0.59 (  0.62)	Data 0.0002 (0.0420)	Loss (EDL) 3.664 (3.782)
2023-05-20 19:33:21,025 | Epoch: [54][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0375)	Loss (EDL) 3.976 (3.783)
2023-05-20 19:33:26,678 | Epoch: [54][100/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0338)	Loss (EDL) 3.719 (3.782)
2023-05-20 19:33:32,327 | Epoch: [54][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0307)	Loss (EDL) 3.777 (3.780)
2023-05-20 19:33:37,949 | Epoch: [54][120/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0282)	Loss (EDL) 3.820 (3.778)
2023-05-20 19:33:43,500 | Epoch: [54][130/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0261)	Loss (EDL) 3.785 (3.778)
2023-05-20 19:33:48,999 | Epoch: [54][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0243)	Loss (EDL) 3.812 (3.782)
2023-05-20 19:33:54,525 | Epoch: [54][150/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0227)	Loss (EDL) 3.917 (3.785)
2023-05-20 19:34:00,251 | Epoch: [54][160/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0213)	Loss (EDL) 4.176 (3.795)
2023-05-20 19:34:05,782 | Epoch: [54][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0200)	Loss (EDL) 3.978 (3.799)
2023-05-20 19:34:11,296 | Epoch: [54][180/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0189)	Loss (EDL) 4.048 (3.801)
2023-05-20 19:34:16,590 | Epoch: [54][190/191]	Time   0.46 (  0.58)	Data 0.0002 (0.0180)	Loss (EDL) 3.912 (3.799)
2023-05-20 19:34:16,911 | Create Epoch [54] features of all training data...
2023-05-20 19:34:46,045 | Updated smoothed statistics on Epoch [54]!
2023-05-20 19:34:46,111 | Updated running statistics with Epoch [54] features!
2023-05-20 19:34:49,832 | Val: [ 0/34]	Time  3.431 ( 3.431)	Loss (L1) 7.435 (7.435)	Loss (EDL) 4.162 (4.162)	Loss (NIG_NLL) 3.768 (3.768)	Loss (NIG_Reg) 39.428 (39.428)
2023-05-20 19:34:51,071 | Val: [10/34]	Time  0.100 ( 0.425)	Loss (L1) 7.080 (7.667)	Loss (EDL) 4.055 (4.163)	Loss (NIG_NLL) 3.679 (3.756)	Loss (NIG_Reg) 37.537 (40.652)
2023-05-20 19:34:52,075 | Val: [20/34]	Time  0.102 ( 0.270)	Loss (L1) 7.886 (7.591)	Loss (EDL) 4.260 (4.161)	Loss (NIG_NLL) 3.842 (3.758)	Loss (NIG_Reg) 41.805 (40.248)
2023-05-20 19:34:53,077 | Val: [30/34]	Time  0.100 ( 0.215)	Loss (L1) 8.103 (7.593)	Loss (EDL) 4.245 (4.162)	Loss (NIG_NLL) 3.815 (3.760)	Loss (NIG_Reg) 42.955 (40.256)
2023-05-20 19:34:53,724 |  * Overall: MSE 93.661	L1 7.582	G-Mean 5.018	EDL 4.158	NIG_NLL 3.756	NIG_Reg 40.199
2023-05-20 19:34:53,724 |  * Many: MSE 83.126	L1 7.121	G-Mean 4.714	EDL 4.043	NIG_NLL 3.665	NIG_Reg 37.754
2023-05-20 19:34:53,724 |  * Median: MSE 103.462	L1 8.094	G-Mean 5.445	EDL 4.323	NIG_NLL 3.894	NIG_Reg 42.903
2023-05-20 19:34:53,724 |  * Low: MSE 166.050	L1 10.525	G-Mean 7.236	EDL 4.794	NIG_NLL 4.236	NIG_Reg 55.804
2023-05-20 19:34:53,725 | Best EDL Loss: 7.582
2023-05-20 19:34:53,729 | ===> Saving current best checkpoint...
2023-05-20 19:35:00,751 | Epoch #54: Train loss [3.7995]; Val loss: MSE [93.6609], L1 [7.5820], G-Mean [5.0183], EDL [4.1581], NIG_NLL [3.756], NIG_Reg [40.199]
2023-05-20 19:35:00,752 | this_lr: 
2023-05-20 19:35:00,752 | 0.001
2023-05-20 19:35:04,935 | Epoch: [55][  0/191]	Time   4.18 (  4.18)	Data 3.2139 (3.2139)	Loss (EDL) 3.460 (3.460)
2023-05-20 19:35:10,429 | Epoch: [55][ 10/191]	Time   0.54 (  0.88)	Data 0.0001 (0.2924)	Loss (EDL) 3.660 (3.737)
2023-05-20 19:35:15,976 | Epoch: [55][ 20/191]	Time   0.57 (  0.72)	Data 0.0001 (0.1533)	Loss (EDL) 3.882 (3.759)
2023-05-20 19:35:21,658 | Epoch: [55][ 30/191]	Time   0.57 (  0.67)	Data 0.0003 (0.1039)	Loss (EDL) 3.576 (3.753)
2023-05-20 19:35:27,223 | Epoch: [55][ 40/191]	Time   0.55 (  0.65)	Data 0.0001 (0.0786)	Loss (EDL) 3.639 (3.744)
2023-05-20 19:35:32,788 | Epoch: [55][ 50/191]	Time   0.54 (  0.63)	Data 0.0002 (0.0633)	Loss (EDL) 4.218 (3.769)
2023-05-20 19:35:38,666 | Epoch: [55][ 60/191]	Time   0.82 (  0.62)	Data 0.0001 (0.0529)	Loss (EDL) 3.709 (3.778)
2023-05-20 19:35:44,135 | Epoch: [55][ 70/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0455)	Loss (EDL) 3.537 (3.762)
2023-05-20 19:35:49,669 | Epoch: [55][ 80/191]	Time   0.55 (  0.60)	Data 0.0003 (0.0399)	Loss (EDL) 3.548 (3.760)
2023-05-20 19:35:55,273 | Epoch: [55][ 90/191]	Time   0.56 (  0.60)	Data 0.0003 (0.0356)	Loss (EDL) 3.615 (3.753)
2023-05-20 19:36:00,793 | Epoch: [55][100/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0321)	Loss (EDL) 3.749 (3.759)
2023-05-20 19:36:06,338 | Epoch: [55][110/191]	Time   0.57 (  0.59)	Data 0.0002 (0.0292)	Loss (EDL) 3.622 (3.760)
2023-05-20 19:36:11,900 | Epoch: [55][120/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0268)	Loss (EDL) 4.062 (3.760)
2023-05-20 19:36:17,422 | Epoch: [55][130/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0248)	Loss (EDL) 4.065 (3.763)
2023-05-20 19:36:23,119 | Epoch: [55][140/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0230)	Loss (EDL) 3.930 (3.775)
2023-05-20 19:36:28,578 | Epoch: [55][150/191]	Time   0.56 (  0.58)	Data 0.0002 (0.0215)	Loss (EDL) 3.898 (3.778)
2023-05-20 19:36:34,067 | Epoch: [55][160/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0202)	Loss (EDL) 4.097 (3.780)
2023-05-20 19:36:39,548 | Epoch: [55][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0190)	Loss (EDL) 3.951 (3.785)
2023-05-20 19:36:45,033 | Epoch: [55][180/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0180)	Loss (EDL) 3.660 (3.786)
2023-05-20 19:36:50,448 | Epoch: [55][190/191]	Time   0.47 (  0.57)	Data 0.0001 (0.0170)	Loss (EDL) 3.890 (3.784)
2023-05-20 19:36:50,759 | Create Epoch [55] features of all training data...
2023-05-20 19:37:20,343 | Updated smoothed statistics on Epoch [55]!
2023-05-20 19:37:20,409 | Updated running statistics with Epoch [55] features!
2023-05-20 19:37:24,241 | Val: [ 0/34]	Time  3.535 ( 3.535)	Loss (L1) 7.706 (7.706)	Loss (EDL) 4.194 (4.194)	Loss (NIG_NLL) 3.786 (3.786)	Loss (NIG_Reg) 40.863 (40.863)
2023-05-20 19:37:25,574 | Val: [10/34]	Time  0.105 ( 0.443)	Loss (L1) 7.701 (7.563)	Loss (EDL) 4.146 (4.141)	Loss (NIG_NLL) 3.738 (3.740)	Loss (NIG_Reg) 40.829 (40.098)
2023-05-20 19:37:26,578 | Val: [20/34]	Time  0.100 ( 0.280)	Loss (L1) 8.106 (7.527)	Loss (EDL) 4.254 (4.139)	Loss (NIG_NLL) 3.825 (3.740)	Loss (NIG_Reg) 42.973 (39.906)
2023-05-20 19:37:27,578 | Val: [30/34]	Time  0.100 ( 0.222)	Loss (L1) 9.266 (7.499)	Loss (EDL) 4.426 (4.137)	Loss (NIG_NLL) 3.935 (3.740)	Loss (NIG_Reg) 49.117 (39.758)
2023-05-20 19:37:28,204 |  * Overall: MSE 95.849	L1 7.468	G-Mean 4.675	EDL 4.129	NIG_NLL 3.734	NIG_Reg 39.592
2023-05-20 19:37:28,204 |  * Many: MSE 77.386	L1 6.772	G-Mean 4.223	EDL 3.976	NIG_NLL 3.617	NIG_Reg 35.905
2023-05-20 19:37:28,204 |  * Median: MSE 119.539	L1 8.423	G-Mean 5.490	EDL 4.365	NIG_NLL 3.919	NIG_Reg 44.650
2023-05-20 19:37:28,204 |  * Low: MSE 204.701	L1 11.397	G-Mean 7.827	EDL 4.931	NIG_NLL 4.326	NIG_Reg 60.430
2023-05-20 19:37:28,205 | Best EDL Loss: 7.468
2023-05-20 19:37:28,209 | ===> Saving current best checkpoint...
2023-05-20 19:37:35,338 | Epoch #55: Train loss [3.7843]; Val loss: MSE [95.8487], L1 [7.4678], G-Mean [4.6752], EDL [4.1295], NIG_NLL [3.734], NIG_Reg [39.592]
2023-05-20 19:37:35,340 | this_lr: 
2023-05-20 19:37:35,340 | 0.001
2023-05-20 19:37:39,428 | Epoch: [56][  0/191]	Time   4.08 (  4.08)	Data 3.0727 (3.0727)	Loss (EDL) 3.516 (3.516)
2023-05-20 19:37:45,112 | Epoch: [56][ 10/191]	Time   0.57 (  0.89)	Data 0.0002 (0.2796)	Loss (EDL) 3.770 (3.744)
2023-05-20 19:37:50,763 | Epoch: [56][ 20/191]	Time   0.58 (  0.73)	Data 0.0001 (0.1466)	Loss (EDL) 3.675 (3.733)
2023-05-20 19:37:56,618 | Epoch: [56][ 30/191]	Time   0.59 (  0.69)	Data 0.0001 (0.0994)	Loss (EDL) 3.757 (3.743)
2023-05-20 19:38:02,316 | Epoch: [56][ 40/191]	Time   0.56 (  0.66)	Data 0.0002 (0.0752)	Loss (EDL) 3.799 (3.737)
2023-05-20 19:38:08,058 | Epoch: [56][ 50/191]	Time   0.58 (  0.64)	Data 0.0001 (0.0605)	Loss (EDL) 3.595 (3.738)
2023-05-20 19:38:13,662 | Epoch: [56][ 60/191]	Time   0.57 (  0.63)	Data 0.0004 (0.0506)	Loss (EDL) 4.295 (3.754)
2023-05-20 19:38:19,342 | Epoch: [56][ 70/191]	Time   0.58 (  0.62)	Data 0.0003 (0.0435)	Loss (EDL) 3.964 (3.773)
2023-05-20 19:38:25,058 | Epoch: [56][ 80/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0382)	Loss (EDL) 4.225 (3.789)
2023-05-20 19:38:30,781 | Epoch: [56][ 90/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0340)	Loss (EDL) 4.161 (3.813)
2023-05-20 19:38:36,820 | Epoch: [56][100/191]	Time   0.56 (  0.61)	Data 0.0003 (0.0307)	Loss (EDL) 3.894 (3.810)
2023-05-20 19:38:42,438 | Epoch: [56][110/191]	Time   0.56 (  0.60)	Data 0.0003 (0.0279)	Loss (EDL) 3.521 (3.798)
2023-05-20 19:38:48,130 | Epoch: [56][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0256)	Loss (EDL) 3.585 (3.792)
2023-05-20 19:38:53,744 | Epoch: [56][130/191]	Time   0.56 (  0.60)	Data 0.0001 (0.0237)	Loss (EDL) 3.618 (3.789)
2023-05-20 19:38:59,253 | Epoch: [56][140/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0220)	Loss (EDL) 3.819 (3.791)
2023-05-20 19:39:04,769 | Epoch: [56][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0206)	Loss (EDL) 3.691 (3.788)
2023-05-20 19:39:10,221 | Epoch: [56][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0193)	Loss (EDL) 3.759 (3.786)
2023-05-20 19:39:15,782 | Epoch: [56][170/191]	Time   0.58 (  0.59)	Data 0.0001 (0.0182)	Loss (EDL) 4.037 (3.783)
2023-05-20 19:39:21,551 | Epoch: [56][180/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0172)	Loss (EDL) 3.682 (3.782)
2023-05-20 19:39:26,973 | Epoch: [56][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0163)	Loss (EDL) 3.611 (3.784)
2023-05-20 19:39:27,317 | Create Epoch [56] features of all training data...
2023-05-20 19:39:56,767 | Updated smoothed statistics on Epoch [56]!
2023-05-20 19:39:56,833 | Updated running statistics with Epoch [56] features!
2023-05-20 19:40:00,635 | Val: [ 0/34]	Time  3.506 ( 3.506)	Loss (L1) 6.747 (6.747)	Loss (EDL) 4.012 (4.012)	Loss (NIG_NLL) 3.655 (3.655)	Loss (NIG_Reg) 35.780 (35.780)
2023-05-20 19:40:01,707 | Val: [10/34]	Time  0.100 ( 0.416)	Loss (L1) 8.461 (8.249)	Loss (EDL) 4.293 (4.283)	Loss (NIG_NLL) 3.844 (3.846)	Loss (NIG_Reg) 44.856 (43.734)
2023-05-20 19:40:02,714 | Val: [20/34]	Time  0.100 ( 0.266)	Loss (L1) 8.874 (8.183)	Loss (EDL) 4.432 (4.274)	Loss (NIG_NLL) 3.961 (3.840)	Loss (NIG_Reg) 47.042 (43.383)
2023-05-20 19:40:03,715 | Val: [30/34]	Time  0.100 ( 0.212)	Loss (L1) 8.583 (8.204)	Loss (EDL) 4.319 (4.277)	Loss (NIG_NLL) 3.864 (3.842)	Loss (NIG_Reg) 45.502 (43.496)
2023-05-20 19:40:04,387 |  * Overall: MSE 110.761	L1 8.171	G-Mean 5.305	EDL 4.266	NIG_NLL 3.833	NIG_Reg 43.319
2023-05-20 19:40:04,388 |  * Many: MSE 101.019	L1 7.800	G-Mean 5.128	EDL 4.177	NIG_NLL 3.763	NIG_Reg 41.352
2023-05-20 19:40:04,388 |  * Median: MSE 115.699	L1 8.518	G-Mean 5.405	EDL 4.378	NIG_NLL 3.926	NIG_Reg 45.154
2023-05-20 19:40:04,388 |  * Low: MSE 189.104	L1 10.715	G-Mean 6.937	EDL 4.801	NIG_NLL 4.233	NIG_Reg 56.819
2023-05-20 19:40:04,389 | Best EDL Loss: 7.468
2023-05-20 19:40:04,392 | Epoch #56: Train loss [3.7835]; Val loss: MSE [110.7605], L1 [8.1710], G-Mean [5.3047], EDL [4.2661], NIG_NLL [3.833], NIG_Reg [43.319]
2023-05-20 19:40:04,393 | this_lr: 
2023-05-20 19:40:04,393 | 0.001
2023-05-20 19:40:09,012 | Epoch: [57][  0/191]	Time   4.62 (  4.62)	Data 3.6707 (3.6707)	Loss (EDL) 3.713 (3.713)
2023-05-20 19:40:14,771 | Epoch: [57][ 10/191]	Time   0.58 (  0.94)	Data 0.0003 (0.3339)	Loss (EDL) 4.005 (3.750)
2023-05-20 19:40:20,332 | Epoch: [57][ 20/191]	Time   0.56 (  0.76)	Data 0.0001 (0.1750)	Loss (EDL) 3.825 (3.760)
2023-05-20 19:40:26,045 | Epoch: [57][ 30/191]	Time   0.57 (  0.70)	Data 0.0001 (0.1186)	Loss (EDL) 3.938 (3.755)
2023-05-20 19:40:31,671 | Epoch: [57][ 40/191]	Time   0.56 (  0.67)	Data 0.0001 (0.0898)	Loss (EDL) 3.793 (3.749)
2023-05-20 19:40:37,261 | Epoch: [57][ 50/191]	Time   0.55 (  0.64)	Data 0.0002 (0.0722)	Loss (EDL) 3.646 (3.755)
2023-05-20 19:40:42,959 | Epoch: [57][ 60/191]	Time   0.56 (  0.63)	Data 0.0002 (0.0604)	Loss (EDL) 3.509 (3.746)
2023-05-20 19:40:48,614 | Epoch: [57][ 70/191]	Time   0.59 (  0.62)	Data 0.0004 (0.0520)	Loss (EDL) 4.177 (3.749)
2023-05-20 19:40:54,260 | Epoch: [57][ 80/191]	Time   0.58 (  0.62)	Data 0.0002 (0.0456)	Loss (EDL) 3.683 (3.754)
2023-05-20 19:41:00,182 | Epoch: [57][ 90/191]	Time   0.55 (  0.61)	Data 0.0001 (0.0406)	Loss (EDL) 3.626 (3.761)
2023-05-20 19:41:05,785 | Epoch: [57][100/191]	Time   0.54 (  0.61)	Data 0.0003 (0.0366)	Loss (EDL) 3.839 (3.767)
2023-05-20 19:41:11,425 | Epoch: [57][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0333)	Loss (EDL) 3.790 (3.762)
2023-05-20 19:41:17,064 | Epoch: [57][120/191]	Time   0.56 (  0.60)	Data 0.0003 (0.0306)	Loss (EDL) 3.867 (3.763)
2023-05-20 19:41:22,714 | Epoch: [57][130/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0283)	Loss (EDL) 3.979 (3.761)
2023-05-20 19:41:28,167 | Epoch: [57][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0263)	Loss (EDL) 3.599 (3.763)
2023-05-20 19:41:33,711 | Epoch: [57][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0246)	Loss (EDL) 3.917 (3.764)
2023-05-20 19:41:39,166 | Epoch: [57][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0231)	Loss (EDL) 3.882 (3.764)
2023-05-20 19:41:44,988 | Epoch: [57][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0217)	Loss (EDL) 3.625 (3.762)
2023-05-20 19:41:50,443 | Epoch: [57][180/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0205)	Loss (EDL) 3.949 (3.764)
2023-05-20 19:41:55,944 | Epoch: [57][190/191]	Time   0.50 (  0.58)	Data 0.0001 (0.0195)	Loss (EDL) 3.975 (3.766)
2023-05-20 19:41:56,303 | Create Epoch [57] features of all training data...
2023-05-20 19:42:25,879 | Updated smoothed statistics on Epoch [57]!
2023-05-20 19:42:25,975 | Updated running statistics with Epoch [57] features!
2023-05-20 19:42:29,718 | Val: [ 0/34]	Time  3.448 ( 3.448)	Loss (L1) 7.703 (7.703)	Loss (EDL) 4.201 (4.201)	Loss (NIG_NLL) 3.793 (3.793)	Loss (NIG_Reg) 40.848 (40.848)
2023-05-20 19:42:30,757 | Val: [10/34]	Time  0.101 ( 0.408)	Loss (L1) 8.608 (8.100)	Loss (EDL) 4.286 (4.246)	Loss (NIG_NLL) 3.830 (3.817)	Loss (NIG_Reg) 45.633 (42.945)
2023-05-20 19:42:31,771 | Val: [20/34]	Time  0.100 ( 0.262)	Loss (L1) 8.498 (7.903)	Loss (EDL) 4.326 (4.219)	Loss (NIG_NLL) 3.875 (3.800)	Loss (NIG_Reg) 45.049 (41.899)
2023-05-20 19:42:32,772 | Val: [30/34]	Time  0.100 ( 0.210)	Loss (L1) 8.806 (7.811)	Loss (EDL) 4.367 (4.200)	Loss (NIG_NLL) 3.900 (3.786)	Loss (NIG_Reg) 46.682 (41.413)
2023-05-20 19:42:33,423 |  * Overall: MSE 102.157	L1 7.763	G-Mean 4.908	EDL 4.188	NIG_NLL 3.776	NIG_Reg 41.158
2023-05-20 19:42:33,424 |  * Many: MSE 96.777	L1 7.544	G-Mean 4.805	EDL 4.135	NIG_NLL 3.735	NIG_Reg 40.001
2023-05-20 19:42:33,424 |  * Median: MSE 107.106	L1 7.993	G-Mean 4.946	EDL 4.248	NIG_NLL 3.825	NIG_Reg 42.369
2023-05-20 19:42:33,424 |  * Low: MSE 139.278	L1 9.190	G-Mean 5.868	EDL 4.520	NIG_NLL 4.033	NIG_Reg 48.732
2023-05-20 19:42:33,425 | Best EDL Loss: 7.468
2023-05-20 19:42:33,429 | Epoch #57: Train loss [3.7662]; Val loss: MSE [102.1568], L1 [7.7628], G-Mean [4.9079], EDL [4.1877], NIG_NLL [3.776], NIG_Reg [41.158]
2023-05-20 19:42:33,429 | this_lr: 
2023-05-20 19:42:33,429 | 0.001
2023-05-20 19:42:38,148 | Epoch: [58][  0/191]	Time   4.72 (  4.72)	Data 3.6808 (3.6808)	Loss (EDL) 3.787 (3.787)
2023-05-20 19:42:43,841 | Epoch: [58][ 10/191]	Time   0.58 (  0.95)	Data 0.0002 (0.3348)	Loss (EDL) 3.957 (3.745)
2023-05-20 19:42:49,454 | Epoch: [58][ 20/191]	Time   0.55 (  0.76)	Data 0.0001 (0.1755)	Loss (EDL) 3.757 (3.749)
2023-05-20 19:42:55,047 | Epoch: [58][ 30/191]	Time   0.55 (  0.70)	Data 0.0003 (0.1189)	Loss (EDL) 3.490 (3.740)
2023-05-20 19:43:00,658 | Epoch: [58][ 40/191]	Time   0.58 (  0.66)	Data 0.0003 (0.0900)	Loss (EDL) 3.833 (3.727)
2023-05-20 19:43:06,370 | Epoch: [58][ 50/191]	Time   0.56 (  0.65)	Data 0.0002 (0.0724)	Loss (EDL) 3.773 (3.729)
2023-05-20 19:43:12,074 | Epoch: [58][ 60/191]	Time   0.56 (  0.63)	Data 0.0001 (0.0606)	Loss (EDL) 3.819 (3.729)
2023-05-20 19:43:17,708 | Epoch: [58][ 70/191]	Time   0.54 (  0.62)	Data 0.0002 (0.0521)	Loss (EDL) 3.665 (3.731)
2023-05-20 19:43:23,646 | Epoch: [58][ 80/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0457)	Loss (EDL) 3.860 (3.733)
2023-05-20 19:43:29,319 | Epoch: [58][ 90/191]	Time   0.56 (  0.61)	Data 0.0003 (0.0407)	Loss (EDL) 3.759 (3.732)
2023-05-20 19:43:35,003 | Epoch: [58][100/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0367)	Loss (EDL) 3.492 (3.740)
2023-05-20 19:43:40,593 | Epoch: [58][110/191]	Time   0.55 (  0.61)	Data 0.0003 (0.0334)	Loss (EDL) 3.743 (3.737)
2023-05-20 19:43:46,233 | Epoch: [58][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0307)	Loss (EDL) 4.029 (3.744)
2023-05-20 19:43:51,810 | Epoch: [58][130/191]	Time   0.53 (  0.60)	Data 0.0001 (0.0283)	Loss (EDL) 3.915 (3.748)
2023-05-20 19:43:57,322 | Epoch: [58][140/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0263)	Loss (EDL) 3.585 (3.744)
2023-05-20 19:44:03,179 | Epoch: [58][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0246)	Loss (EDL) 3.648 (3.741)
2023-05-20 19:44:08,667 | Epoch: [58][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0231)	Loss (EDL) 3.701 (3.747)
2023-05-20 19:44:14,147 | Epoch: [58][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0218)	Loss (EDL) 3.780 (3.746)
2023-05-20 19:44:19,683 | Epoch: [58][180/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0206)	Loss (EDL) 3.731 (3.749)
2023-05-20 19:44:25,135 | Epoch: [58][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0195)	Loss (EDL) 3.587 (3.748)
2023-05-20 19:44:25,489 | Create Epoch [58] features of all training data...
2023-05-20 19:44:54,760 | Updated smoothed statistics on Epoch [58]!
2023-05-20 19:44:54,825 | Updated running statistics with Epoch [58] features!
2023-05-20 19:44:58,687 | Val: [ 0/34]	Time  3.579 ( 3.579)	Loss (L1) 7.052 (7.052)	Loss (EDL) 4.115 (4.115)	Loss (NIG_NLL) 3.741 (3.741)	Loss (NIG_Reg) 37.395 (37.395)
2023-05-20 19:44:59,800 | Val: [10/34]	Time  0.100 ( 0.427)	Loss (L1) 9.003 (7.906)	Loss (EDL) 4.489 (4.253)	Loss (NIG_NLL) 4.012 (3.834)	Loss (NIG_Reg) 47.733 (41.915)
2023-05-20 19:45:00,807 | Val: [20/34]	Time  0.100 ( 0.271)	Loss (L1) 7.678 (7.825)	Loss (EDL) 4.211 (4.239)	Loss (NIG_NLL) 3.804 (3.824)	Loss (NIG_Reg) 40.702 (41.480)
2023-05-20 19:45:01,809 | Val: [30/34]	Time  0.100 ( 0.216)	Loss (L1) 8.266 (7.767)	Loss (EDL) 4.269 (4.221)	Loss (NIG_NLL) 3.831 (3.810)	Loss (NIG_Reg) 43.818 (41.176)
2023-05-20 19:45:02,451 |  * Overall: MSE 97.285	L1 7.703	G-Mean 4.986	EDL 4.206	NIG_NLL 3.797	NIG_Reg 40.834
2023-05-20 19:45:02,451 |  * Many: MSE 81.308	L1 6.980	G-Mean 4.479	EDL 4.035	NIG_NLL 3.665	NIG_Reg 37.005
2023-05-20 19:45:02,451 |  * Median: MSE 109.344	L1 8.595	G-Mean 5.971	EDL 4.430	NIG_NLL 3.974	NIG_Reg 45.564
2023-05-20 19:45:02,451 |  * Low: MSE 214.834	L1 12.054	G-Mean 8.355	EDL 5.193	NIG_NLL 4.554	NIG_Reg 63.918
2023-05-20 19:45:02,452 | Best EDL Loss: 7.468
2023-05-20 19:45:02,455 | Epoch #58: Train loss [3.7480]; Val loss: MSE [97.2850], L1 [7.7026], G-Mean [4.9865], EDL [4.2057], NIG_NLL [3.797], NIG_Reg [40.834]
2023-05-20 19:45:02,455 | this_lr: 
2023-05-20 19:45:02,456 | 0.001
2023-05-20 19:45:06,744 | Epoch: [59][  0/191]	Time   4.29 (  4.29)	Data 3.3317 (3.3317)	Loss (EDL) 3.565 (3.565)
2023-05-20 19:45:12,462 | Epoch: [59][ 10/191]	Time   0.56 (  0.91)	Data 0.0001 (0.3031)	Loss (EDL) 3.591 (3.650)
2023-05-20 19:45:18,054 | Epoch: [59][ 20/191]	Time   0.55 (  0.74)	Data 0.0001 (0.1589)	Loss (EDL) 3.708 (3.680)
2023-05-20 19:45:23,610 | Epoch: [59][ 30/191]	Time   0.55 (  0.68)	Data 0.0002 (0.1077)	Loss (EDL) 3.900 (3.702)
2023-05-20 19:45:29,173 | Epoch: [59][ 40/191]	Time   0.55 (  0.65)	Data 0.0001 (0.0815)	Loss (EDL) 3.707 (3.704)
2023-05-20 19:45:35,028 | Epoch: [59][ 50/191]	Time   0.56 (  0.64)	Data 0.0002 (0.0655)	Loss (EDL) 3.717 (3.714)
2023-05-20 19:45:40,589 | Epoch: [59][ 60/191]	Time   0.57 (  0.63)	Data 0.0002 (0.0548)	Loss (EDL) 4.017 (3.729)
2023-05-20 19:45:46,195 | Epoch: [59][ 70/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0471)	Loss (EDL) 3.685 (3.725)
2023-05-20 19:45:51,848 | Epoch: [59][ 80/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0413)	Loss (EDL) 3.819 (3.734)
2023-05-20 19:45:57,439 | Epoch: [59][ 90/191]	Time   0.58 (  0.60)	Data 0.0001 (0.0368)	Loss (EDL) 3.714 (3.741)
2023-05-20 19:46:03,027 | Epoch: [59][100/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0332)	Loss (EDL) 3.680 (3.735)
2023-05-20 19:46:08,598 | Epoch: [59][110/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0302)	Loss (EDL) 3.766 (3.731)
2023-05-20 19:46:14,459 | Epoch: [59][120/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0278)	Loss (EDL) 3.634 (3.729)
2023-05-20 19:46:20,010 | Epoch: [59][130/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0257)	Loss (EDL) 3.496 (3.730)
2023-05-20 19:46:25,399 | Epoch: [59][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0238)	Loss (EDL) 3.701 (3.729)
2023-05-20 19:46:30,920 | Epoch: [59][150/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0223)	Loss (EDL) 4.109 (3.730)
2023-05-20 19:46:36,474 | Epoch: [59][160/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0209)	Loss (EDL) 3.729 (3.733)
2023-05-20 19:46:41,908 | Epoch: [59][170/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0197)	Loss (EDL) 3.507 (3.729)
2023-05-20 19:46:47,346 | Epoch: [59][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0186)	Loss (EDL) 3.795 (3.733)
2023-05-20 19:46:52,755 | Epoch: [59][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0176)	Loss (EDL) 3.776 (3.728)
2023-05-20 19:46:53,075 | Create Epoch [59] features of all training data...
2023-05-20 19:47:22,262 | Updated smoothed statistics on Epoch [59]!
2023-05-20 19:47:22,328 | Updated running statistics with Epoch [59] features!
2023-05-20 19:47:25,945 | Val: [ 0/34]	Time  3.323 ( 3.323)	Loss (L1) 7.515 (7.515)	Loss (EDL) 4.203 (4.203)	Loss (NIG_NLL) 3.804 (3.804)	Loss (NIG_Reg) 39.845 (39.845)
2023-05-20 19:47:27,020 | Val: [10/34]	Time  0.101 ( 0.400)	Loss (L1) 7.739 (7.632)	Loss (EDL) 4.216 (4.196)	Loss (NIG_NLL) 3.805 (3.791)	Loss (NIG_Reg) 41.025 (40.457)
2023-05-20 19:47:28,023 | Val: [20/34]	Time  0.100 ( 0.257)	Loss (L1) 7.824 (7.510)	Loss (EDL) 4.241 (4.179)	Loss (NIG_NLL) 3.827 (3.781)	Loss (NIG_Reg) 41.473 (39.812)
2023-05-20 19:47:29,026 | Val: [30/34]	Time  0.100 ( 0.207)	Loss (L1) 8.021 (7.494)	Loss (EDL) 4.195 (4.167)	Loss (NIG_NLL) 3.770 (3.770)	Loss (NIG_Reg) 42.519 (39.728)
2023-05-20 19:47:29,649 |  * Overall: MSE 93.419	L1 7.455	G-Mean 4.785	EDL 4.156	NIG_NLL 3.760	NIG_Reg 39.523
2023-05-20 19:47:29,649 |  * Many: MSE 83.308	L1 7.017	G-Mean 4.462	EDL 4.048	NIG_NLL 3.676	NIG_Reg 37.199
2023-05-20 19:47:29,649 |  * Median: MSE 98.141	L1 7.854	G-Mean 5.307	EDL 4.267	NIG_NLL 3.851	NIG_Reg 41.635
2023-05-20 19:47:29,649 |  * Low: MSE 175.846	L1 10.492	G-Mean 6.948	EDL 4.858	NIG_NLL 4.302	NIG_Reg 55.628
2023-05-20 19:47:29,650 | Best EDL Loss: 7.455
2023-05-20 19:47:29,653 | ===> Saving current best checkpoint...
2023-05-20 19:47:37,034 | Epoch #59: Train loss [3.7279]; Val loss: MSE [93.4185], L1 [7.4554], G-Mean [4.7849], EDL [4.1556], NIG_NLL [3.760], NIG_Reg [39.523]
2023-05-20 19:47:37,035 | this_lr: 
2023-05-20 19:47:37,035 | 0.0001
2023-05-20 19:47:41,170 | Epoch: [60][  0/191]	Time   4.13 (  4.13)	Data 3.1695 (3.1695)	Loss (EDL) 3.512 (3.512)
2023-05-20 19:47:46,740 | Epoch: [60][ 10/191]	Time   0.55 (  0.88)	Data 0.0002 (0.2883)	Loss (EDL) 3.613 (3.591)
2023-05-20 19:47:52,314 | Epoch: [60][ 20/191]	Time   0.58 (  0.73)	Data 0.0001 (0.1512)	Loss (EDL) 3.428 (3.594)
2023-05-20 19:47:57,854 | Epoch: [60][ 30/191]	Time   0.55 (  0.67)	Data 0.0001 (0.1025)	Loss (EDL) 3.426 (3.587)
2023-05-20 19:48:03,487 | Epoch: [60][ 40/191]	Time   0.56 (  0.65)	Data 0.0002 (0.0776)	Loss (EDL) 3.659 (3.593)
2023-05-20 19:48:09,075 | Epoch: [60][ 50/191]	Time   0.58 (  0.63)	Data 0.0002 (0.0624)	Loss (EDL) 3.277 (3.577)
2023-05-20 19:48:15,029 | Epoch: [60][ 60/191]	Time   0.55 (  0.62)	Data 0.0001 (0.0522)	Loss (EDL) 3.539 (3.556)
2023-05-20 19:48:20,665 | Epoch: [60][ 70/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0449)	Loss (EDL) 3.497 (3.548)
2023-05-20 19:48:26,271 | Epoch: [60][ 80/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0394)	Loss (EDL) 3.360 (3.540)
2023-05-20 19:48:32,010 | Epoch: [60][ 90/191]	Time   0.59 (  0.60)	Data 0.0002 (0.0351)	Loss (EDL) 3.412 (3.533)
2023-05-20 19:48:37,664 | Epoch: [60][100/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0316)	Loss (EDL) 3.451 (3.527)
2023-05-20 19:48:43,272 | Epoch: [60][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0288)	Loss (EDL) 3.360 (3.522)
2023-05-20 19:48:48,803 | Epoch: [60][120/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0265)	Loss (EDL) 3.456 (3.515)
2023-05-20 19:48:54,346 | Epoch: [60][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0245)	Loss (EDL) 3.427 (3.508)
2023-05-20 19:49:00,007 | Epoch: [60][140/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0227)	Loss (EDL) 3.652 (3.509)
2023-05-20 19:49:05,429 | Epoch: [60][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0212)	Loss (EDL) 3.282 (3.506)
2023-05-20 19:49:10,916 | Epoch: [60][160/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0199)	Loss (EDL) 3.310 (3.503)
2023-05-20 19:49:16,430 | Epoch: [60][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0188)	Loss (EDL) 3.332 (3.503)
2023-05-20 19:49:21,887 | Epoch: [60][180/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0177)	Loss (EDL) 3.167 (3.498)
2023-05-20 19:49:27,276 | Epoch: [60][190/191]	Time   0.47 (  0.58)	Data 0.0002 (0.0168)	Loss (EDL) 3.578 (3.495)
2023-05-20 19:49:27,592 | Create Epoch [60] features of all training data...
2023-05-20 19:49:57,098 | Updated smoothed statistics on Epoch [60]!
2023-05-20 19:49:57,165 | Updated running statistics with Epoch [60] features!
2023-05-20 19:50:00,719 | Val: [ 0/34]	Time  3.248 ( 3.248)	Loss (L1) 6.773 (6.773)	Loss (EDL) 4.095 (4.095)	Loss (NIG_NLL) 3.736 (3.736)	Loss (NIG_Reg) 35.917 (35.917)
2023-05-20 19:50:01,922 | Val: [10/34]	Time  0.100 ( 0.405)	Loss (L1) 7.353 (7.202)	Loss (EDL) 4.171 (4.157)	Loss (NIG_NLL) 3.782 (3.775)	Loss (NIG_Reg) 38.981 (38.181)
2023-05-20 19:50:02,926 | Val: [20/34]	Time  0.100 ( 0.260)	Loss (L1) 7.661 (7.149)	Loss (EDL) 4.279 (4.154)	Loss (NIG_NLL) 3.873 (3.775)	Loss (NIG_Reg) 40.611 (37.902)
2023-05-20 19:50:03,932 | Val: [30/34]	Time  0.102 ( 0.208)	Loss (L1) 7.892 (7.121)	Loss (EDL) 4.262 (4.143)	Loss (NIG_NLL) 3.844 (3.766)	Loss (NIG_Reg) 41.835 (37.751)
2023-05-20 19:50:04,627 |  * Overall: MSE 83.479	L1 7.057	G-Mean 4.546	EDL 4.125	NIG_NLL 3.750	NIG_Reg 37.412
2023-05-20 19:50:04,627 |  * Many: MSE 72.066	L1 6.510	G-Mean 4.159	EDL 3.988	NIG_NLL 3.643	NIG_Reg 34.514
2023-05-20 19:50:04,627 |  * Median: MSE 96.634	L1 7.804	G-Mean 5.162	EDL 4.329	NIG_NLL 3.915	NIG_Reg 41.369
2023-05-20 19:50:04,627 |  * Low: MSE 154.893	L1 10.153	G-Mean 7.411	EDL 4.848	NIG_NLL 4.310	NIG_Reg 53.835
2023-05-20 19:50:04,628 | Best EDL Loss: 7.057
2023-05-20 19:50:04,631 | ===> Saving current best checkpoint...
2023-05-20 19:50:11,682 | Epoch #60: Train loss [3.4951]; Val loss: MSE [83.4792], L1 [7.0567], G-Mean [4.5458], EDL [4.1246], NIG_NLL [3.750], NIG_Reg [37.412]
2023-05-20 19:50:11,684 | this_lr: 
2023-05-20 19:50:11,684 | 0.0001
2023-05-20 19:50:15,712 | Epoch: [61][  0/191]	Time   4.02 (  4.02)	Data 3.0661 (3.0661)	Loss (EDL) 3.517 (3.517)
2023-05-20 19:50:21,278 | Epoch: [61][ 10/191]	Time   0.57 (  0.87)	Data 0.0001 (0.2790)	Loss (EDL) 3.592 (3.508)
2023-05-20 19:50:26,854 | Epoch: [61][ 20/191]	Time   0.55 (  0.72)	Data 0.0001 (0.1462)	Loss (EDL) 3.268 (3.481)
2023-05-20 19:50:32,702 | Epoch: [61][ 30/191]	Time   0.57 (  0.68)	Data 0.0001 (0.0991)	Loss (EDL) 3.308 (3.446)
2023-05-20 19:50:38,203 | Epoch: [61][ 40/191]	Time   0.55 (  0.65)	Data 0.0001 (0.0750)	Loss (EDL) 3.549 (3.449)
2023-05-20 19:50:43,768 | Epoch: [61][ 50/191]	Time   0.55 (  0.63)	Data 0.0002 (0.0603)	Loss (EDL) 3.421 (3.439)
2023-05-20 19:50:49,396 | Epoch: [61][ 60/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0505)	Loss (EDL) 3.308 (3.429)
2023-05-20 19:50:55,053 | Epoch: [61][ 70/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0434)	Loss (EDL) 3.286 (3.434)
2023-05-20 19:51:00,757 | Epoch: [61][ 80/191]	Time   0.60 (  0.61)	Data 0.0002 (0.0381)	Loss (EDL) 3.239 (3.440)
2023-05-20 19:51:06,586 | Epoch: [61][ 90/191]	Time   0.57 (  0.60)	Data 0.0003 (0.0339)	Loss (EDL) 3.381 (3.440)
2023-05-20 19:51:12,239 | Epoch: [61][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0306)	Loss (EDL) 3.374 (3.433)
2023-05-20 19:51:17,892 | Epoch: [61][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0279)	Loss (EDL) 3.526 (3.434)
2023-05-20 19:51:23,594 | Epoch: [61][120/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0256)	Loss (EDL) 3.437 (3.433)
2023-05-20 19:51:29,155 | Epoch: [61][130/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0237)	Loss (EDL) 3.688 (3.429)
2023-05-20 19:51:34,520 | Epoch: [61][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0220)	Loss (EDL) 3.207 (3.430)
2023-05-20 19:51:40,025 | Epoch: [61][150/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0205)	Loss (EDL) 3.257 (3.429)
2023-05-20 19:51:45,467 | Epoch: [61][160/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0193)	Loss (EDL) 3.335 (3.424)
2023-05-20 19:51:50,919 | Epoch: [61][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0182)	Loss (EDL) 3.430 (3.424)
2023-05-20 19:51:56,634 | Epoch: [61][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0172)	Loss (EDL) 3.429 (3.423)
2023-05-20 19:52:02,060 | Epoch: [61][190/191]	Time   0.46 (  0.58)	Data 0.0002 (0.0163)	Loss (EDL) 3.434 (3.423)
2023-05-20 19:52:02,371 | Create Epoch [61] features of all training data...
2023-05-20 19:52:32,103 | Updated smoothed statistics on Epoch [61]!
2023-05-20 19:52:32,183 | Updated running statistics with Epoch [61] features!
2023-05-20 19:52:35,958 | Val: [ 0/34]	Time  3.449 ( 3.449)	Loss (L1) 6.544 (6.544)	Loss (EDL) 4.096 (4.096)	Loss (NIG_NLL) 3.749 (3.749)	Loss (NIG_Reg) 34.704 (34.704)
2023-05-20 19:52:37,285 | Val: [10/34]	Time  0.101 ( 0.434)	Loss (L1) 7.472 (7.186)	Loss (EDL) 4.227 (4.185)	Loss (NIG_NLL) 3.831 (3.804)	Loss (NIG_Reg) 39.616 (38.101)
2023-05-20 19:52:38,287 | Val: [20/34]	Time  0.100 ( 0.275)	Loss (L1) 7.603 (7.080)	Loss (EDL) 4.312 (4.170)	Loss (NIG_NLL) 3.909 (3.795)	Loss (NIG_Reg) 40.306 (37.537)
2023-05-20 19:52:39,291 | Val: [30/34]	Time  0.100 ( 0.219)	Loss (L1) 7.716 (7.009)	Loss (EDL) 4.291 (4.149)	Loss (NIG_NLL) 3.882 (3.777)	Loss (NIG_Reg) 40.900 (37.159)
2023-05-20 19:52:39,942 |  * Overall: MSE 82.026	L1 6.963	G-Mean 4.424	EDL 4.133	NIG_NLL 3.764	NIG_Reg 36.918
2023-05-20 19:52:39,942 |  * Many: MSE 72.336	L1 6.468	G-Mean 4.037	EDL 4.007	NIG_NLL 3.665	NIG_Reg 34.290
2023-05-20 19:52:39,942 |  * Median: MSE 91.020	L1 7.597	G-Mean 5.098	EDL 4.313	NIG_NLL 3.910	NIG_Reg 40.272
2023-05-20 19:52:39,942 |  * Low: MSE 148.671	L1 9.894	G-Mean 7.091	EDL 4.826	NIG_NLL 4.302	NIG_Reg 52.467
2023-05-20 19:52:39,943 | Best EDL Loss: 6.963
2023-05-20 19:52:39,947 | ===> Saving current best checkpoint...
2023-05-20 19:52:46,834 | Epoch #61: Train loss [3.4228]; Val loss: MSE [82.0260], L1 [6.9634], G-Mean [4.4236], EDL [4.1333], NIG_NLL [3.764], NIG_Reg [36.918]
2023-05-20 19:52:46,836 | this_lr: 
2023-05-20 19:52:46,836 | 0.0001
2023-05-20 19:52:51,152 | Epoch: [62][  0/191]	Time   4.31 (  4.31)	Data 3.4359 (3.4359)	Loss (EDL) 3.342 (3.342)
2023-05-20 19:52:56,790 | Epoch: [62][ 10/191]	Time   0.57 (  0.90)	Data 0.0002 (0.3126)	Loss (EDL) 3.787 (3.345)
2023-05-20 19:53:02,306 | Epoch: [62][ 20/191]	Time   0.56 (  0.74)	Data 0.0001 (0.1638)	Loss (EDL) 3.390 (3.349)
2023-05-20 19:53:07,924 | Epoch: [62][ 30/191]	Time   0.55 (  0.68)	Data 0.0001 (0.1110)	Loss (EDL) 3.340 (3.383)
2023-05-20 19:53:13,573 | Epoch: [62][ 40/191]	Time   0.55 (  0.65)	Data 0.0002 (0.0840)	Loss (EDL) 3.311 (3.384)
2023-05-20 19:53:19,291 | Epoch: [62][ 50/191]	Time   0.57 (  0.64)	Data 0.0001 (0.0676)	Loss (EDL) 3.280 (3.375)
2023-05-20 19:53:24,871 | Epoch: [62][ 60/191]	Time   0.54 (  0.62)	Data 0.0001 (0.0565)	Loss (EDL) 4.025 (3.378)
2023-05-20 19:53:30,612 | Epoch: [62][ 70/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0486)	Loss (EDL) 3.342 (3.383)
2023-05-20 19:53:36,491 | Epoch: [62][ 80/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0426)	Loss (EDL) 3.199 (3.382)
2023-05-20 19:53:42,110 | Epoch: [62][ 90/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0380)	Loss (EDL) 3.275 (3.380)
2023-05-20 19:53:47,695 | Epoch: [62][100/191]	Time   0.52 (  0.60)	Data 0.0002 (0.0342)	Loss (EDL) 3.471 (3.379)
2023-05-20 19:53:53,221 | Epoch: [62][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0312)	Loss (EDL) 3.236 (3.373)
2023-05-20 19:53:58,852 | Epoch: [62][120/191]	Time   0.55 (  0.60)	Data 0.0003 (0.0286)	Loss (EDL) 3.261 (3.364)
2023-05-20 19:54:04,373 | Epoch: [62][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0265)	Loss (EDL) 3.572 (3.369)
2023-05-20 19:54:09,766 | Epoch: [62][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0246)	Loss (EDL) 3.493 (3.378)
2023-05-20 19:54:15,194 | Epoch: [62][150/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0230)	Loss (EDL) 3.708 (3.387)
2023-05-20 19:54:20,864 | Epoch: [62][160/191]	Time   0.54 (  0.58)	Data 0.0002 (0.0216)	Loss (EDL) 3.495 (3.381)
2023-05-20 19:54:26,367 | Epoch: [62][170/191]	Time   0.57 (  0.58)	Data 0.0001 (0.0203)	Loss (EDL) 3.378 (3.383)
2023-05-20 19:54:31,804 | Epoch: [62][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0192)	Loss (EDL) 3.221 (3.387)
2023-05-20 19:54:37,111 | Epoch: [62][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0182)	Loss (EDL) 3.295 (3.388)
2023-05-20 19:54:37,433 | Create Epoch [62] features of all training data...
2023-05-20 19:55:07,129 | Updated smoothed statistics on Epoch [62]!
2023-05-20 19:55:07,199 | Updated running statistics with Epoch [62] features!
2023-05-20 19:55:10,932 | Val: [ 0/34]	Time  3.449 ( 3.449)	Loss (L1) 6.349 (6.349)	Loss (EDL) 3.990 (3.990)	Loss (NIG_NLL) 3.653 (3.653)	Loss (NIG_Reg) 33.671 (33.671)
2023-05-20 19:55:12,164 | Val: [10/34]	Time  0.100 ( 0.425)	Loss (L1) 7.123 (7.081)	Loss (EDL) 4.136 (4.157)	Loss (NIG_NLL) 3.758 (3.781)	Loss (NIG_Reg) 37.765 (37.542)
2023-05-20 19:55:13,171 | Val: [20/34]	Time  0.100 ( 0.271)	Loss (L1) 7.557 (7.062)	Loss (EDL) 4.283 (4.162)	Loss (NIG_NLL) 3.882 (3.787)	Loss (NIG_Reg) 40.058 (37.442)
2023-05-20 19:55:14,175 | Val: [30/34]	Time  0.100 ( 0.216)	Loss (L1) 8.091 (7.046)	Loss (EDL) 4.371 (4.153)	Loss (NIG_NLL) 3.942 (3.779)	Loss (NIG_Reg) 42.892 (37.354)
2023-05-20 19:55:14,835 |  * Overall: MSE 81.797	L1 6.993	G-Mean 4.450	EDL 4.136	NIG_NLL 3.765	NIG_Reg 37.077
2023-05-20 19:55:14,835 |  * Many: MSE 70.288	L1 6.428	G-Mean 4.046	EDL 3.995	NIG_NLL 3.654	NIG_Reg 34.078
2023-05-20 19:55:14,835 |  * Median: MSE 96.964	L1 7.837	G-Mean 5.158	EDL 4.357	NIG_NLL 3.941	NIG_Reg 41.544
2023-05-20 19:55:14,835 |  * Low: MSE 148.547	L1 10.004	G-Mean 7.263	EDL 4.863	NIG_NLL 4.332	NIG_Reg 53.053
2023-05-20 19:55:14,835 | Best EDL Loss: 6.963
2023-05-20 19:55:14,839 | Epoch #62: Train loss [3.3876]; Val loss: MSE [81.7969], L1 [6.9934], G-Mean [4.4496], EDL [4.1363], NIG_NLL [3.765], NIG_Reg [37.077]
2023-05-20 19:55:14,839 | this_lr: 
2023-05-20 19:55:14,839 | 0.0001
2023-05-20 19:55:19,442 | Epoch: [63][  0/191]	Time   4.60 (  4.60)	Data 3.6411 (3.6411)	Loss (EDL) 3.551 (3.551)
2023-05-20 19:55:25,047 | Epoch: [63][ 10/191]	Time   0.55 (  0.93)	Data 0.0001 (0.3312)	Loss (EDL) 3.216 (3.303)
2023-05-20 19:55:30,667 | Epoch: [63][ 20/191]	Time   0.55 (  0.75)	Data 0.0002 (0.1736)	Loss (EDL) 3.279 (3.334)
2023-05-20 19:55:36,392 | Epoch: [63][ 30/191]	Time   0.58 (  0.70)	Data 0.0002 (0.1177)	Loss (EDL) 3.191 (3.340)
2023-05-20 19:55:42,035 | Epoch: [63][ 40/191]	Time   0.57 (  0.66)	Data 0.0001 (0.0891)	Loss (EDL) 3.576 (3.355)
2023-05-20 19:55:47,605 | Epoch: [63][ 50/191]	Time   0.53 (  0.64)	Data 0.0003 (0.0716)	Loss (EDL) 3.165 (3.358)
2023-05-20 19:55:53,401 | Epoch: [63][ 60/191]	Time   0.56 (  0.63)	Data 0.0002 (0.0599)	Loss (EDL) 3.223 (3.361)
2023-05-20 19:55:59,090 | Epoch: [63][ 70/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0515)	Loss (EDL) 3.337 (3.363)
2023-05-20 19:56:04,724 | Epoch: [63][ 80/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0452)	Loss (EDL) 3.383 (3.358)
2023-05-20 19:56:10,346 | Epoch: [63][ 90/191]	Time   0.57 (  0.61)	Data 0.0004 (0.0403)	Loss (EDL) 3.343 (3.358)
2023-05-20 19:56:15,897 | Epoch: [63][100/191]	Time   0.55 (  0.60)	Data 0.0004 (0.0363)	Loss (EDL) 3.168 (3.359)
2023-05-20 19:56:21,559 | Epoch: [63][110/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0331)	Loss (EDL) 3.411 (3.362)
2023-05-20 19:56:27,203 | Epoch: [63][120/191]	Time   0.55 (  0.60)	Data 0.0003 (0.0304)	Loss (EDL) 3.480 (3.367)
2023-05-20 19:56:33,320 | Epoch: [63][130/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0281)	Loss (EDL) 3.138 (3.366)
2023-05-20 19:56:38,779 | Epoch: [63][140/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0261)	Loss (EDL) 3.370 (3.363)
2023-05-20 19:56:44,250 | Epoch: [63][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0244)	Loss (EDL) 3.491 (3.370)
2023-05-20 19:56:49,761 | Epoch: [63][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0229)	Loss (EDL) 3.396 (3.370)
2023-05-20 19:56:55,255 | Epoch: [63][170/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0216)	Loss (EDL) 3.432 (3.372)
2023-05-20 19:57:00,725 | Epoch: [63][180/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0204)	Loss (EDL) 4.246 (3.379)
2023-05-20 19:57:06,070 | Epoch: [63][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0193)	Loss (EDL) 3.269 (3.380)
2023-05-20 19:57:06,416 | Create Epoch [63] features of all training data...
2023-05-20 19:57:36,278 | Updated smoothed statistics on Epoch [63]!
2023-05-20 19:57:36,345 | Updated running statistics with Epoch [63] features!
2023-05-20 19:57:40,208 | Val: [ 0/34]	Time  3.540 ( 3.540)	Loss (L1) 6.420 (6.420)	Loss (EDL) 4.031 (4.031)	Loss (NIG_NLL) 3.690 (3.690)	Loss (NIG_Reg) 34.047 (34.047)
2023-05-20 19:57:41,376 | Val: [10/34]	Time  0.100 ( 0.428)	Loss (L1) 7.298 (7.104)	Loss (EDL) 4.154 (4.160)	Loss (NIG_NLL) 3.767 (3.783)	Loss (NIG_Reg) 38.692 (37.662)
2023-05-20 19:57:42,381 | Val: [20/34]	Time  0.100 ( 0.272)	Loss (L1) 7.682 (7.011)	Loss (EDL) 4.312 (4.144)	Loss (NIG_NLL) 3.905 (3.772)	Loss (NIG_Reg) 40.724 (37.169)
2023-05-20 19:57:43,387 | Val: [30/34]	Time  0.100 ( 0.217)	Loss (L1) 7.957 (6.987)	Loss (EDL) 4.352 (4.133)	Loss (NIG_NLL) 3.930 (3.763)	Loss (NIG_Reg) 42.179 (37.040)
2023-05-20 19:57:44,047 |  * Overall: MSE 82.272	L1 6.941	G-Mean 4.307	EDL 4.118	NIG_NLL 3.750	NIG_Reg 36.801
2023-05-20 19:57:44,047 |  * Many: MSE 72.322	L1 6.472	G-Mean 3.956	EDL 3.999	NIG_NLL 3.656	NIG_Reg 34.312
2023-05-20 19:57:44,047 |  * Median: MSE 91.100	L1 7.502	G-Mean 4.976	EDL 4.266	NIG_NLL 3.868	NIG_Reg 39.767
2023-05-20 19:57:44,047 |  * Low: MSE 151.832	L1 9.825	G-Mean 6.447	EDL 4.833	NIG_NLL 4.311	NIG_Reg 52.104
2023-05-20 19:57:44,048 | Best EDL Loss: 6.941
2023-05-20 19:57:44,051 | ===> Saving current best checkpoint...
2023-05-20 19:57:51,310 | Epoch #63: Train loss [3.3799]; Val loss: MSE [82.2718], L1 [6.9415], G-Mean [4.3072], EDL [4.1178], NIG_NLL [3.750], NIG_Reg [36.801]
2023-05-20 19:57:51,311 | this_lr: 
2023-05-20 19:57:51,311 | 0.0001
2023-05-20 19:57:55,498 | Epoch: [64][  0/191]	Time   4.18 (  4.18)	Data 3.1979 (3.1979)	Loss (EDL) 3.370 (3.370)
2023-05-20 19:58:01,158 | Epoch: [64][ 10/191]	Time   0.56 (  0.89)	Data 0.0002 (0.2909)	Loss (EDL) 3.074 (3.304)
2023-05-20 19:58:07,141 | Epoch: [64][ 20/191]	Time   0.56 (  0.75)	Data 0.0002 (0.1525)	Loss (EDL) 3.088 (3.297)
2023-05-20 19:58:12,927 | Epoch: [64][ 30/191]	Time   0.60 (  0.70)	Data 0.0002 (0.1034)	Loss (EDL) 3.330 (3.275)
2023-05-20 19:58:18,580 | Epoch: [64][ 40/191]	Time   0.58 (  0.67)	Data 0.0002 (0.0782)	Loss (EDL) 3.251 (3.269)
2023-05-20 19:58:24,313 | Epoch: [64][ 50/191]	Time   0.59 (  0.65)	Data 0.0002 (0.0629)	Loss (EDL) 3.567 (3.276)
2023-05-20 19:58:29,963 | Epoch: [64][ 60/191]	Time   0.54 (  0.63)	Data 0.0006 (0.0526)	Loss (EDL) 3.289 (3.291)
2023-05-20 19:58:35,553 | Epoch: [64][ 70/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0453)	Loss (EDL) 3.347 (3.301)
2023-05-20 19:58:41,458 | Epoch: [64][ 80/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0397)	Loss (EDL) 3.509 (3.316)
2023-05-20 19:58:47,097 | Epoch: [64][ 90/191]	Time   0.57 (  0.61)	Data 0.0003 (0.0354)	Loss (EDL) 3.292 (3.316)
2023-05-20 19:58:52,812 | Epoch: [64][100/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0319)	Loss (EDL) 3.270 (3.317)
2023-05-20 19:58:58,400 | Epoch: [64][110/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0290)	Loss (EDL) 3.113 (3.316)
2023-05-20 19:59:03,968 | Epoch: [64][120/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0267)	Loss (EDL) 3.238 (3.329)
2023-05-20 19:59:09,496 | Epoch: [64][130/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0247)	Loss (EDL) 3.272 (3.328)
2023-05-20 19:59:14,926 | Epoch: [64][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0229)	Loss (EDL) 3.203 (3.331)
2023-05-20 19:59:20,350 | Epoch: [64][150/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0214)	Loss (EDL) 3.170 (3.333)
2023-05-20 19:59:26,070 | Epoch: [64][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0201)	Loss (EDL) 3.202 (3.333)
2023-05-20 19:59:31,549 | Epoch: [64][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0189)	Loss (EDL) 3.391 (3.337)
2023-05-20 19:59:36,963 | Epoch: [64][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0179)	Loss (EDL) 3.246 (3.334)
2023-05-20 19:59:42,285 | Epoch: [64][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0170)	Loss (EDL) 3.370 (3.337)
2023-05-20 19:59:42,615 | Create Epoch [64] features of all training data...
2023-05-20 20:00:12,133 | Updated smoothed statistics on Epoch [64]!
2023-05-20 20:00:12,200 | Updated running statistics with Epoch [64] features!
2023-05-20 20:00:15,943 | Val: [ 0/34]	Time  3.458 ( 3.458)	Loss (L1) 6.500 (6.500)	Loss (EDL) 4.093 (4.093)	Loss (NIG_NLL) 3.748 (3.748)	Loss (NIG_Reg) 34.470 (34.470)
2023-05-20 20:00:17,117 | Val: [10/34]	Time  0.100 ( 0.421)	Loss (L1) 7.147 (7.129)	Loss (EDL) 4.163 (4.208)	Loss (NIG_NLL) 3.784 (3.830)	Loss (NIG_Reg) 37.889 (37.796)
2023-05-20 20:00:18,118 | Val: [20/34]	Time  0.100 ( 0.268)	Loss (L1) 7.619 (7.059)	Loss (EDL) 4.355 (4.197)	Loss (NIG_NLL) 3.951 (3.823)	Loss (NIG_Reg) 40.387 (37.426)
2023-05-20 20:00:19,121 | Val: [30/34]	Time  0.100 ( 0.214)	Loss (L1) 8.300 (7.043)	Loss (EDL) 4.489 (4.191)	Loss (NIG_NLL) 4.049 (3.818)	Loss (NIG_Reg) 43.996 (37.337)
2023-05-20 20:00:19,743 |  * Overall: MSE 82.321	L1 6.997	G-Mean 4.524	EDL 4.176	NIG_NLL 3.805	NIG_Reg 37.094
2023-05-20 20:00:19,743 |  * Many: MSE 69.593	L1 6.395	G-Mean 4.094	EDL 4.020	NIG_NLL 3.681	NIG_Reg 33.906
2023-05-20 20:00:19,743 |  * Median: MSE 98.663	L1 7.880	G-Mean 5.292	EDL 4.415	NIG_NLL 3.998	NIG_Reg 41.770
2023-05-20 20:00:19,743 |  * Low: MSE 157.333	L1 10.234	G-Mean 7.534	EDL 4.982	NIG_NLL 4.439	NIG_Reg 54.272
2023-05-20 20:00:19,744 | Best EDL Loss: 6.941
2023-05-20 20:00:19,747 | Epoch #64: Train loss [3.3367]; Val loss: MSE [82.3207], L1 [6.9967], G-Mean [4.5243], EDL [4.1756], NIG_NLL [3.805], NIG_Reg [37.094]
2023-05-20 20:00:19,747 | this_lr: 
2023-05-20 20:00:19,747 | 0.0001
2023-05-20 20:00:24,132 | Epoch: [65][  0/191]	Time   4.38 (  4.38)	Data 3.4866 (3.4866)	Loss (EDL) 3.052 (3.052)
2023-05-20 20:00:29,834 | Epoch: [65][ 10/191]	Time   0.55 (  0.92)	Data 0.0001 (0.3172)	Loss (EDL) 3.268 (3.291)
2023-05-20 20:00:35,366 | Epoch: [65][ 20/191]	Time   0.56 (  0.74)	Data 0.0004 (0.1663)	Loss (EDL) 3.289 (3.303)
2023-05-20 20:00:40,954 | Epoch: [65][ 30/191]	Time   0.57 (  0.68)	Data 0.0001 (0.1128)	Loss (EDL) 3.340 (3.311)
2023-05-20 20:00:46,571 | Epoch: [65][ 40/191]	Time   0.56 (  0.65)	Data 0.0002 (0.0853)	Loss (EDL) 3.269 (3.309)
2023-05-20 20:00:52,235 | Epoch: [65][ 50/191]	Time   0.56 (  0.64)	Data 0.0002 (0.0686)	Loss (EDL) 3.429 (3.303)
2023-05-20 20:00:58,151 | Epoch: [65][ 60/191]	Time   0.55 (  0.63)	Data 0.0002 (0.0574)	Loss (EDL) 3.334 (3.315)
2023-05-20 20:01:03,727 | Epoch: [65][ 70/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0494)	Loss (EDL) 3.588 (3.317)
2023-05-20 20:01:09,329 | Epoch: [65][ 80/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0433)	Loss (EDL) 3.337 (3.328)
2023-05-20 20:01:14,962 | Epoch: [65][ 90/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0386)	Loss (EDL) 3.360 (3.326)
2023-05-20 20:01:20,591 | Epoch: [65][100/191]	Time   0.55 (  0.60)	Data 0.0003 (0.0348)	Loss (EDL) 3.336 (3.319)
2023-05-20 20:01:26,194 | Epoch: [65][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0317)	Loss (EDL) 3.290 (3.312)
2023-05-20 20:01:31,825 | Epoch: [65][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0291)	Loss (EDL) 3.908 (3.315)
2023-05-20 20:01:37,538 | Epoch: [65][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0269)	Loss (EDL) 3.227 (3.308)
2023-05-20 20:01:42,959 | Epoch: [65][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0250)	Loss (EDL) 3.218 (3.312)
2023-05-20 20:01:48,426 | Epoch: [65][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0234)	Loss (EDL) 3.295 (3.316)
2023-05-20 20:01:53,893 | Epoch: [65][160/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0219)	Loss (EDL) 3.393 (3.315)
2023-05-20 20:01:59,407 | Epoch: [65][170/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0206)	Loss (EDL) 3.284 (3.313)
2023-05-20 20:02:04,941 | Epoch: [65][180/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0195)	Loss (EDL) 3.485 (3.315)
2023-05-20 20:02:10,296 | Epoch: [65][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0185)	Loss (EDL) 3.262 (3.311)
2023-05-20 20:02:10,669 | Create Epoch [65] features of all training data...
2023-05-20 20:02:40,269 | Updated smoothed statistics on Epoch [65]!
2023-05-20 20:02:40,341 | Updated running statistics with Epoch [65] features!
2023-05-20 20:02:43,967 | Val: [ 0/34]	Time  3.311 ( 3.311)	Loss (L1) 6.489 (6.489)	Loss (EDL) 4.083 (4.083)	Loss (NIG_NLL) 3.739 (3.739)	Loss (NIG_Reg) 34.413 (34.413)
2023-05-20 20:02:45,312 | Val: [10/34]	Time  0.100 ( 0.423)	Loss (L1) 7.307 (7.172)	Loss (EDL) 4.199 (4.224)	Loss (NIG_NLL) 3.812 (3.844)	Loss (NIG_Reg) 38.737 (38.025)
2023-05-20 20:02:46,313 | Val: [20/34]	Time  0.100 ( 0.269)	Loss (L1) 7.712 (7.115)	Loss (EDL) 4.384 (4.218)	Loss (NIG_NLL) 3.975 (3.841)	Loss (NIG_Reg) 40.883 (37.725)
2023-05-20 20:02:47,313 | Val: [30/34]	Time  0.100 ( 0.215)	Loss (L1) 8.149 (7.091)	Loss (EDL) 4.491 (4.212)	Loss (NIG_NLL) 4.059 (3.836)	Loss (NIG_Reg) 43.199 (37.596)
2023-05-20 20:02:47,969 |  * Overall: MSE 83.421	L1 7.049	G-Mean 4.559	EDL 4.197	NIG_NLL 3.823	NIG_Reg 37.373
2023-05-20 20:02:47,969 |  * Many: MSE 72.245	L1 6.538	G-Mean 4.231	EDL 4.069	NIG_NLL 3.723	NIG_Reg 34.666
2023-05-20 20:02:47,970 |  * Median: MSE 99.442	L1 7.843	G-Mean 5.111	EDL 4.398	NIG_NLL 3.983	NIG_Reg 41.576
2023-05-20 20:02:47,970 |  * Low: MSE 144.672	L1 9.676	G-Mean 6.732	EDL 4.844	NIG_NLL 4.330	NIG_Reg 51.317
2023-05-20 20:02:47,970 | Best EDL Loss: 6.941
2023-05-20 20:02:47,973 | Epoch #65: Train loss [3.3112]; Val loss: MSE [83.4215], L1 [7.0490], G-Mean [4.5593], EDL [4.1969], NIG_NLL [3.823], NIG_Reg [37.373]
2023-05-20 20:02:47,974 | this_lr: 
2023-05-20 20:02:47,974 | 0.0001
2023-05-20 20:02:52,839 | Epoch: [66][  0/191]	Time   4.86 (  4.86)	Data 4.0338 (4.0338)	Loss (EDL) 3.291 (3.291)
2023-05-20 20:02:58,390 | Epoch: [66][ 10/191]	Time   0.57 (  0.95)	Data 0.0002 (0.3670)	Loss (EDL) 3.133 (3.250)
2023-05-20 20:03:04,137 | Epoch: [66][ 20/191]	Time   0.56 (  0.77)	Data 0.0001 (0.1923)	Loss (EDL) 3.199 (3.244)
2023-05-20 20:03:09,983 | Epoch: [66][ 30/191]	Time   0.57 (  0.71)	Data 0.0001 (0.1303)	Loss (EDL) 3.074 (3.276)
2023-05-20 20:03:15,701 | Epoch: [66][ 40/191]	Time   0.59 (  0.68)	Data 0.0002 (0.0986)	Loss (EDL) 3.181 (3.276)
2023-05-20 20:03:21,351 | Epoch: [66][ 50/191]	Time   0.59 (  0.65)	Data 0.0002 (0.0793)	Loss (EDL) 3.222 (3.289)
2023-05-20 20:03:27,050 | Epoch: [66][ 60/191]	Time   0.58 (  0.64)	Data 0.0002 (0.0663)	Loss (EDL) 3.410 (3.297)
2023-05-20 20:03:32,706 | Epoch: [66][ 70/191]	Time   0.57 (  0.63)	Data 0.0002 (0.0570)	Loss (EDL) 3.207 (3.294)
2023-05-20 20:03:38,264 | Epoch: [66][ 80/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0500)	Loss (EDL) 3.457 (3.289)
2023-05-20 20:03:44,178 | Epoch: [66][ 90/191]	Time   0.81 (  0.62)	Data 0.0002 (0.0445)	Loss (EDL) 3.125 (3.278)
2023-05-20 20:03:49,835 | Epoch: [66][100/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0402)	Loss (EDL) 3.068 (3.286)
2023-05-20 20:03:55,357 | Epoch: [66][110/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0366)	Loss (EDL) 3.218 (3.289)
2023-05-20 20:04:00,952 | Epoch: [66][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0336)	Loss (EDL) 3.336 (3.287)
2023-05-20 20:04:06,468 | Epoch: [66][130/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0310)	Loss (EDL) 3.053 (3.285)
2023-05-20 20:04:11,974 | Epoch: [66][140/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0288)	Loss (EDL) 2.995 (3.283)
2023-05-20 20:04:17,447 | Epoch: [66][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0269)	Loss (EDL) 3.138 (3.279)
2023-05-20 20:04:22,942 | Epoch: [66][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0253)	Loss (EDL) 3.502 (3.285)
2023-05-20 20:04:28,635 | Epoch: [66][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0238)	Loss (EDL) 3.605 (3.290)
2023-05-20 20:04:34,092 | Epoch: [66][180/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0225)	Loss (EDL) 3.270 (3.286)
2023-05-20 20:04:39,437 | Epoch: [66][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0213)	Loss (EDL) 3.450 (3.288)
2023-05-20 20:04:39,800 | Create Epoch [66] features of all training data...
2023-05-20 20:05:09,472 | Updated smoothed statistics on Epoch [66]!
2023-05-20 20:05:09,542 | Updated running statistics with Epoch [66] features!
2023-05-20 20:05:13,619 | Val: [ 0/34]	Time  3.789 ( 3.789)	Loss (L1) 6.805 (6.805)	Loss (EDL) 4.188 (4.188)	Loss (NIG_NLL) 3.827 (3.827)	Loss (NIG_Reg) 36.086 (36.086)
2023-05-20 20:05:14,661 | Val: [10/34]	Time  0.101 ( 0.439)	Loss (L1) 7.165 (7.200)	Loss (EDL) 4.206 (4.261)	Loss (NIG_NLL) 3.826 (3.880)	Loss (NIG_Reg) 37.985 (38.171)
2023-05-20 20:05:15,667 | Val: [20/34]	Time  0.100 ( 0.278)	Loss (L1) 7.816 (7.152)	Loss (EDL) 4.458 (4.254)	Loss (NIG_NLL) 4.044 (3.875)	Loss (NIG_Reg) 41.433 (37.919)
2023-05-20 20:05:16,675 | Val: [30/34]	Time  0.100 ( 0.221)	Loss (L1) 8.285 (7.134)	Loss (EDL) 4.549 (4.249)	Loss (NIG_NLL) 4.110 (3.870)	Loss (NIG_Reg) 43.916 (37.821)
2023-05-20 20:05:17,326 |  * Overall: MSE 84.069	L1 7.084	G-Mean 4.541	EDL 4.232	NIG_NLL 3.856	NIG_Reg 37.555
2023-05-20 20:05:17,326 |  * Many: MSE 68.130	L1 6.323	G-Mean 4.053	EDL 4.023	NIG_NLL 3.688	NIG_Reg 33.523
2023-05-20 20:05:17,326 |  * Median: MSE 106.986	L1 8.325	G-Mean 5.519	EDL 4.597	NIG_NLL 4.156	NIG_Reg 44.129
2023-05-20 20:05:17,327 |  * Low: MSE 171.226	L1 10.835	G-Mean 7.752	EDL 5.195	NIG_NLL 4.620	NIG_Reg 57.456
2023-05-20 20:05:17,328 | Best EDL Loss: 6.941
2023-05-20 20:05:17,333 | Epoch #66: Train loss [3.2878]; Val loss: MSE [84.0685], L1 [7.0838], G-Mean [4.5410], EDL [4.2320], NIG_NLL [3.856], NIG_Reg [37.555]
2023-05-20 20:05:17,334 | this_lr: 
2023-05-20 20:05:17,334 | 0.0001
2023-05-20 20:05:21,695 | Epoch: [67][  0/191]	Time   4.36 (  4.36)	Data 3.3864 (3.3864)	Loss (EDL) 3.273 (3.273)
2023-05-20 20:05:27,328 | Epoch: [67][ 10/191]	Time   0.55 (  0.91)	Data 0.0003 (0.3081)	Loss (EDL) 3.332 (3.242)
2023-05-20 20:05:32,866 | Epoch: [67][ 20/191]	Time   0.55 (  0.74)	Data 0.0001 (0.1615)	Loss (EDL) 3.308 (3.287)
2023-05-20 20:05:38,450 | Epoch: [67][ 30/191]	Time   0.54 (  0.68)	Data 0.0001 (0.1095)	Loss (EDL) 3.292 (3.265)
2023-05-20 20:05:44,003 | Epoch: [67][ 40/191]	Time   0.54 (  0.65)	Data 0.0001 (0.0828)	Loss (EDL) 3.295 (3.255)
2023-05-20 20:05:49,607 | Epoch: [67][ 50/191]	Time   0.56 (  0.63)	Data 0.0001 (0.0666)	Loss (EDL) 3.073 (3.268)
2023-05-20 20:05:55,198 | Epoch: [67][ 60/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0557)	Loss (EDL) 3.120 (3.275)
2023-05-20 20:06:00,867 | Epoch: [67][ 70/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0479)	Loss (EDL) 3.129 (3.270)
2023-05-20 20:06:06,653 | Epoch: [67][ 80/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0420)	Loss (EDL) 3.535 (3.272)
2023-05-20 20:06:12,278 | Epoch: [67][ 90/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0374)	Loss (EDL) 2.999 (3.267)
2023-05-20 20:06:17,876 | Epoch: [67][100/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0338)	Loss (EDL) 3.270 (3.264)
2023-05-20 20:06:23,435 | Epoch: [67][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0307)	Loss (EDL) 3.292 (3.259)
2023-05-20 20:06:29,044 | Epoch: [67][120/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0282)	Loss (EDL) 3.507 (3.261)
2023-05-20 20:06:34,635 | Epoch: [67][130/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0261)	Loss (EDL) 3.285 (3.263)
2023-05-20 20:06:40,090 | Epoch: [67][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0242)	Loss (EDL) 3.197 (3.266)
2023-05-20 20:06:45,805 | Epoch: [67][150/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0227)	Loss (EDL) 3.473 (3.266)
2023-05-20 20:06:51,299 | Epoch: [67][160/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0213)	Loss (EDL) 3.006 (3.264)
2023-05-20 20:06:56,811 | Epoch: [67][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0200)	Loss (EDL) 3.281 (3.259)
2023-05-20 20:07:02,259 | Epoch: [67][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0189)	Loss (EDL) 3.322 (3.258)
2023-05-20 20:07:07,658 | Epoch: [67][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0179)	Loss (EDL) 3.461 (3.262)
2023-05-20 20:07:07,990 | Create Epoch [67] features of all training data...
2023-05-20 20:07:37,489 | Updated smoothed statistics on Epoch [67]!
2023-05-20 20:07:37,555 | Updated running statistics with Epoch [67] features!
2023-05-20 20:07:41,297 | Val: [ 0/34]	Time  3.460 ( 3.460)	Loss (L1) 6.527 (6.527)	Loss (EDL) 4.134 (4.134)	Loss (NIG_NLL) 3.788 (3.788)	Loss (NIG_Reg) 34.614 (34.614)
2023-05-20 20:07:42,306 | Val: [10/34]	Time  0.100 ( 0.406)	Loss (L1) 6.992 (7.060)	Loss (EDL) 4.163 (4.233)	Loss (NIG_NLL) 3.792 (3.859)	Loss (NIG_Reg) 37.069 (37.432)
2023-05-20 20:07:43,308 | Val: [20/34]	Time  0.100 ( 0.261)	Loss (L1) 7.761 (6.954)	Loss (EDL) 4.462 (4.213)	Loss (NIG_NLL) 4.050 (3.845)	Loss (NIG_Reg) 41.144 (36.869)
2023-05-20 20:07:44,309 | Val: [30/34]	Time  0.100 ( 0.209)	Loss (L1) 7.818 (6.944)	Loss (EDL) 4.464 (4.210)	Loss (NIG_NLL) 4.050 (3.842)	Loss (NIG_Reg) 41.445 (36.817)
2023-05-20 20:07:44,954 |  * Overall: MSE 81.479	L1 6.899	G-Mean 4.312	EDL 4.193	NIG_NLL 3.828	NIG_Reg 36.575
2023-05-20 20:07:44,954 |  * Many: MSE 73.128	L1 6.516	G-Mean 4.052	EDL 4.096	NIG_NLL 3.751	NIG_Reg 34.544
2023-05-20 20:07:44,954 |  * Median: MSE 89.483	L1 7.353	G-Mean 4.673	EDL 4.309	NIG_NLL 3.919	NIG_Reg 38.977
2023-05-20 20:07:44,954 |  * Low: MSE 138.216	L1 9.262	G-Mean 6.214	EDL 4.789	NIG_NLL 4.298	NIG_Reg 49.123
2023-05-20 20:07:44,955 | Best EDL Loss: 6.899
2023-05-20 20:07:44,959 | ===> Saving current best checkpoint...
2023-05-20 20:07:51,977 | Epoch #67: Train loss [3.2617]; Val loss: MSE [81.4791], L1 [6.8987], G-Mean [4.3122], EDL [4.1934], NIG_NLL [3.828], NIG_Reg [36.575]
2023-05-20 20:07:51,978 | this_lr: 
2023-05-20 20:07:51,978 | 0.0001
2023-05-20 20:07:56,483 | Epoch: [68][  0/191]	Time   4.50 (  4.50)	Data 3.5219 (3.5219)	Loss (EDL) 3.317 (3.317)
2023-05-20 20:08:02,102 | Epoch: [68][ 10/191]	Time   0.55 (  0.92)	Data 0.0002 (0.3204)	Loss (EDL) 3.254 (3.303)
2023-05-20 20:08:07,659 | Epoch: [68][ 20/191]	Time   0.56 (  0.75)	Data 0.0002 (0.1680)	Loss (EDL) 3.206 (3.275)
2023-05-20 20:08:13,263 | Epoch: [68][ 30/191]	Time   0.56 (  0.69)	Data 0.0002 (0.1139)	Loss (EDL) 3.394 (3.244)
2023-05-20 20:08:18,882 | Epoch: [68][ 40/191]	Time   0.56 (  0.66)	Data 0.0003 (0.0862)	Loss (EDL) 3.094 (3.227)
2023-05-20 20:08:24,755 | Epoch: [68][ 50/191]	Time   0.56 (  0.64)	Data 0.0003 (0.0693)	Loss (EDL) 3.155 (3.218)
2023-05-20 20:08:30,390 | Epoch: [68][ 60/191]	Time   0.54 (  0.63)	Data 0.0001 (0.0580)	Loss (EDL) 3.376 (3.228)
2023-05-20 20:08:35,963 | Epoch: [68][ 70/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0498)	Loss (EDL) 3.142 (3.223)
2023-05-20 20:08:41,482 | Epoch: [68][ 80/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0437)	Loss (EDL) 3.372 (3.230)
2023-05-20 20:08:47,079 | Epoch: [68][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0389)	Loss (EDL) 3.237 (3.233)
2023-05-20 20:08:52,603 | Epoch: [68][100/191]	Time   0.60 (  0.60)	Data 0.0002 (0.0351)	Loss (EDL) 3.400 (3.234)
2023-05-20 20:08:58,287 | Epoch: [68][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0320)	Loss (EDL) 3.310 (3.228)
2023-05-20 20:09:04,122 | Epoch: [68][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0293)	Loss (EDL) 3.148 (3.230)
2023-05-20 20:09:09,720 | Epoch: [68][130/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0271)	Loss (EDL) 3.205 (3.223)
2023-05-20 20:09:15,235 | Epoch: [68][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0252)	Loss (EDL) 3.075 (3.225)
2023-05-20 20:09:20,679 | Epoch: [68][150/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0236)	Loss (EDL) 3.410 (3.229)
2023-05-20 20:09:26,104 | Epoch: [68][160/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0221)	Loss (EDL) 3.548 (3.229)
2023-05-20 20:09:31,678 | Epoch: [68][170/191]	Time   0.56 (  0.58)	Data 0.0002 (0.0208)	Loss (EDL) 3.487 (3.236)
2023-05-20 20:09:37,084 | Epoch: [68][180/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0197)	Loss (EDL) 3.325 (3.239)
2023-05-20 20:09:42,531 | Epoch: [68][190/191]	Time   0.45 (  0.58)	Data 0.0002 (0.0187)	Loss (EDL) 3.104 (3.241)
2023-05-20 20:09:42,871 | Create Epoch [68] features of all training data...
2023-05-20 20:10:12,580 | Updated smoothed statistics on Epoch [68]!
2023-05-20 20:10:12,648 | Updated running statistics with Epoch [68] features!
2023-05-20 20:10:16,771 | Val: [ 0/34]	Time  3.816 ( 3.816)	Loss (L1) 6.587 (6.587)	Loss (EDL) 4.135 (4.135)	Loss (NIG_NLL) 3.786 (3.786)	Loss (NIG_Reg) 34.930 (34.930)
2023-05-20 20:10:17,777 | Val: [10/34]	Time  0.100 ( 0.438)	Loss (L1) 7.004 (7.111)	Loss (EDL) 4.160 (4.236)	Loss (NIG_NLL) 3.789 (3.859)	Loss (NIG_Reg) 37.132 (37.698)
2023-05-20 20:10:18,782 | Val: [20/34]	Time  0.100 ( 0.277)	Loss (L1) 7.842 (7.112)	Loss (EDL) 4.456 (4.245)	Loss (NIG_NLL) 4.040 (3.868)	Loss (NIG_Reg) 41.569 (37.703)
2023-05-20 20:10:19,786 | Val: [30/34]	Time  0.100 ( 0.220)	Loss (L1) 8.053 (7.106)	Loss (EDL) 4.502 (4.243)	Loss (NIG_NLL) 4.075 (3.866)	Loss (NIG_Reg) 42.686 (37.673)
2023-05-20 20:10:20,427 |  * Overall: MSE 83.914	L1 7.060	G-Mean 4.508	EDL 4.226	NIG_NLL 3.852	NIG_Reg 37.426
2023-05-20 20:10:20,427 |  * Many: MSE 69.281	L1 6.401	G-Mean 4.103	EDL 4.052	NIG_NLL 3.712	NIG_Reg 33.936
2023-05-20 20:10:20,427 |  * Median: MSE 104.005	L1 8.070	G-Mean 5.227	EDL 4.505	NIG_NLL 4.077	NIG_Reg 42.781
2023-05-20 20:10:20,427 |  * Low: MSE 166.546	L1 10.480	G-Mean 7.283	EDL 5.100	NIG_NLL 4.544	NIG_Reg 55.574
2023-05-20 20:10:20,427 | Best EDL Loss: 6.899
2023-05-20 20:10:20,431 | Epoch #68: Train loss [3.2406]; Val loss: MSE [83.9136], L1 [7.0595], G-Mean [4.5082], EDL [4.2259], NIG_NLL [3.852], NIG_Reg [37.426]
2023-05-20 20:10:20,431 | this_lr: 
2023-05-20 20:10:20,431 | 0.0001
2023-05-20 20:10:25,043 | Epoch: [69][  0/191]	Time   4.61 (  4.61)	Data 3.6348 (3.6348)	Loss (EDL) 3.187 (3.187)
2023-05-20 20:10:30,768 | Epoch: [69][ 10/191]	Time   0.55 (  0.94)	Data 0.0002 (0.3307)	Loss (EDL) 3.302 (3.223)
2023-05-20 20:10:36,294 | Epoch: [69][ 20/191]	Time   0.56 (  0.76)	Data 0.0001 (0.1733)	Loss (EDL) 3.148 (3.205)
2023-05-20 20:10:41,886 | Epoch: [69][ 30/191]	Time   0.56 (  0.69)	Data 0.0001 (0.1175)	Loss (EDL) 3.084 (3.212)
2023-05-20 20:10:47,458 | Epoch: [69][ 40/191]	Time   0.55 (  0.66)	Data 0.0001 (0.0889)	Loss (EDL) 3.407 (3.212)
2023-05-20 20:10:53,068 | Epoch: [69][ 50/191]	Time   0.57 (  0.64)	Data 0.0002 (0.0715)	Loss (EDL) 3.270 (3.225)
2023-05-20 20:10:58,722 | Epoch: [69][ 60/191]	Time   0.56 (  0.63)	Data 0.0001 (0.0598)	Loss (EDL) 3.144 (3.230)
2023-05-20 20:11:04,545 | Epoch: [69][ 70/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0514)	Loss (EDL) 3.612 (3.238)
2023-05-20 20:11:10,150 | Epoch: [69][ 80/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0451)	Loss (EDL) 3.485 (3.248)
2023-05-20 20:11:15,701 | Epoch: [69][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0402)	Loss (EDL) 3.397 (3.249)
2023-05-20 20:11:21,371 | Epoch: [69][100/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0362)	Loss (EDL) 3.401 (3.255)
2023-05-20 20:11:27,068 | Epoch: [69][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0330)	Loss (EDL) 3.181 (3.250)
2023-05-20 20:11:32,672 | Epoch: [69][120/191]	Time   0.55 (  0.60)	Data 0.0003 (0.0303)	Loss (EDL) 3.117 (3.247)
2023-05-20 20:11:38,195 | Epoch: [69][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0280)	Loss (EDL) 3.190 (3.241)
2023-05-20 20:11:43,896 | Epoch: [69][140/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0260)	Loss (EDL) 3.029 (3.237)
2023-05-20 20:11:49,374 | Epoch: [69][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0243)	Loss (EDL) 3.323 (3.234)
2023-05-20 20:11:54,812 | Epoch: [69][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0228)	Loss (EDL) 3.325 (3.234)
2023-05-20 20:12:00,291 | Epoch: [69][170/191]	Time   0.56 (  0.58)	Data 0.0002 (0.0215)	Loss (EDL) 3.213 (3.232)
2023-05-20 20:12:05,773 | Epoch: [69][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0203)	Loss (EDL) 3.347 (3.234)
2023-05-20 20:12:11,150 | Epoch: [69][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0192)	Loss (EDL) 3.272 (3.233)
2023-05-20 20:12:11,488 | Create Epoch [69] features of all training data...
2023-05-20 20:12:40,945 | Updated smoothed statistics on Epoch [69]!
2023-05-20 20:12:41,019 | Updated running statistics with Epoch [69] features!
2023-05-20 20:12:44,796 | Val: [ 0/34]	Time  3.492 ( 3.492)	Loss (L1) 6.594 (6.594)	Loss (EDL) 4.183 (4.183)	Loss (NIG_NLL) 3.833 (3.833)	Loss (NIG_Reg) 34.967 (34.967)
2023-05-20 20:12:45,983 | Val: [10/34]	Time  0.101 ( 0.425)	Loss (L1) 7.291 (7.206)	Loss (EDL) 4.285 (4.304)	Loss (NIG_NLL) 3.899 (3.922)	Loss (NIG_Reg) 38.654 (38.204)
2023-05-20 20:12:46,993 | Val: [20/34]	Time  0.100 ( 0.271)	Loss (L1) 7.837 (7.195)	Loss (EDL) 4.535 (4.307)	Loss (NIG_NLL) 4.120 (3.926)	Loss (NIG_Reg) 41.547 (38.145)
2023-05-20 20:12:48,001 | Val: [30/34]	Time  0.100 ( 0.216)	Loss (L1) 8.410 (7.196)	Loss (EDL) 4.658 (4.310)	Loss (NIG_NLL) 4.212 (3.929)	Loss (NIG_Reg) 44.580 (38.152)
2023-05-20 20:12:48,696 |  * Overall: MSE 85.347	L1 7.141	G-Mean 4.617	EDL 4.291	NIG_NLL 3.912	NIG_Reg 37.862
2023-05-20 20:12:48,697 |  * Many: MSE 70.173	L1 6.470	G-Mean 4.202	EDL 4.111	NIG_NLL 3.768	NIG_Reg 34.302
2023-05-20 20:12:48,697 |  * Median: MSE 109.091	L1 8.261	G-Mean 5.389	EDL 4.597	NIG_NLL 4.159	NIG_Reg 43.792
2023-05-20 20:12:48,697 |  * Low: MSE 162.994	L1 10.388	G-Mean 7.343	EDL 5.144	NIG_NLL 4.594	NIG_Reg 55.090
2023-05-20 20:12:48,697 | Best EDL Loss: 6.899
2023-05-20 20:12:48,700 | Epoch #69: Train loss [3.2333]; Val loss: MSE [85.3466], L1 [7.1415], G-Mean [4.6174], EDL [4.2908], NIG_NLL [3.912], NIG_Reg [37.862]
2023-05-20 20:12:48,701 | this_lr: 
2023-05-20 20:12:48,701 | 0.0001
2023-05-20 20:12:53,269 | Epoch: [70][  0/191]	Time   4.57 (  4.57)	Data 3.5897 (3.5897)	Loss (EDL) 3.207 (3.207)
2023-05-20 20:12:58,871 | Epoch: [70][ 10/191]	Time   0.56 (  0.92)	Data 0.0001 (0.3265)	Loss (EDL) 3.231 (3.254)
2023-05-20 20:13:04,430 | Epoch: [70][ 20/191]	Time   0.55 (  0.75)	Data 0.0002 (0.1711)	Loss (EDL) 3.029 (3.239)
2023-05-20 20:13:10,102 | Epoch: [70][ 30/191]	Time   0.58 (  0.69)	Data 0.0001 (0.1160)	Loss (EDL) 3.093 (3.235)
2023-05-20 20:13:16,046 | Epoch: [70][ 40/191]	Time   0.57 (  0.67)	Data 0.0001 (0.0878)	Loss (EDL) 3.170 (3.205)
2023-05-20 20:13:21,710 | Epoch: [70][ 50/191]	Time   0.57 (  0.65)	Data 0.0002 (0.0706)	Loss (EDL) 3.030 (3.215)
2023-05-20 20:13:27,330 | Epoch: [70][ 60/191]	Time   0.57 (  0.63)	Data 0.0001 (0.0590)	Loss (EDL) 2.982 (3.205)
2023-05-20 20:13:32,908 | Epoch: [70][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0508)	Loss (EDL) 3.699 (3.229)
2023-05-20 20:13:38,569 | Epoch: [70][ 80/191]	Time   0.54 (  0.62)	Data 0.0002 (0.0445)	Loss (EDL) 3.142 (3.229)
2023-05-20 20:13:44,174 | Epoch: [70][ 90/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0397)	Loss (EDL) 3.037 (3.221)
2023-05-20 20:13:49,754 | Epoch: [70][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0358)	Loss (EDL) 2.939 (3.216)
2023-05-20 20:13:55,723 | Epoch: [70][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0326)	Loss (EDL) 3.087 (3.227)
2023-05-20 20:14:01,422 | Epoch: [70][120/191]	Time   0.59 (  0.60)	Data 0.0002 (0.0299)	Loss (EDL) 3.219 (3.223)
2023-05-20 20:14:07,002 | Epoch: [70][130/191]	Time   0.56 (  0.60)	Data 0.0001 (0.0276)	Loss (EDL) 3.023 (3.216)
2023-05-20 20:14:12,539 | Epoch: [70][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0257)	Loss (EDL) 3.177 (3.215)
2023-05-20 20:14:18,054 | Epoch: [70][150/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0240)	Loss (EDL) 3.602 (3.221)
2023-05-20 20:14:23,489 | Epoch: [70][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0225)	Loss (EDL) 3.338 (3.220)
2023-05-20 20:14:28,912 | Epoch: [70][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0212)	Loss (EDL) 3.224 (3.224)
2023-05-20 20:14:34,442 | Epoch: [70][180/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0201)	Loss (EDL) 3.393 (3.225)
2023-05-20 20:14:40,191 | Epoch: [70][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0190)	Loss (EDL) 3.339 (3.224)
2023-05-20 20:14:40,560 | Create Epoch [70] features of all training data...
2023-05-20 20:15:09,901 | Updated smoothed statistics on Epoch [70]!
2023-05-20 20:15:09,979 | Updated running statistics with Epoch [70] features!
2023-05-20 20:15:13,480 | Val: [ 0/34]	Time  3.184 ( 3.184)	Loss (L1) 6.463 (6.463)	Loss (EDL) 4.131 (4.131)	Loss (NIG_NLL) 3.788 (3.788)	Loss (NIG_Reg) 34.270 (34.270)
2023-05-20 20:15:14,517 | Val: [10/34]	Time  0.100 ( 0.384)	Loss (L1) 7.891 (7.207)	Loss (EDL) 4.411 (4.265)	Loss (NIG_NLL) 3.992 (3.883)	Loss (NIG_Reg) 41.831 (38.206)
2023-05-20 20:15:15,519 | Val: [20/34]	Time  0.100 ( 0.249)	Loss (L1) 8.099 (7.054)	Loss (EDL) 4.537 (4.235)	Loss (NIG_NLL) 4.108 (3.861)	Loss (NIG_Reg) 42.931 (37.397)
2023-05-20 20:15:16,522 | Val: [30/34]	Time  0.100 ( 0.201)	Loss (L1) 7.793 (7.047)	Loss (EDL) 4.460 (4.232)	Loss (NIG_NLL) 4.047 (3.859)	Loss (NIG_Reg) 41.311 (37.358)
2023-05-20 20:15:17,168 |  * Overall: MSE 84.532	L1 7.015	G-Mean 4.342	EDL 4.220	NIG_NLL 3.848	NIG_Reg 37.188
2023-05-20 20:15:17,168 |  * Many: MSE 78.015	L1 6.751	G-Mean 4.166	EDL 4.159	NIG_NLL 3.801	NIG_Reg 35.790
2023-05-20 20:15:17,168 |  * Median: MSE 85.378	L1 7.101	G-Mean 4.549	EDL 4.218	NIG_NLL 3.841	NIG_Reg 37.643
2023-05-20 20:15:17,168 |  * Low: MSE 143.745	L1 9.264	G-Mean 5.649	EDL 4.807	NIG_NLL 4.316	NIG_Reg 49.133
2023-05-20 20:15:17,169 | Best EDL Loss: 6.899
2023-05-20 20:15:17,172 | Epoch #70: Train loss [3.2245]; Val loss: MSE [84.5322], L1 [7.0145], G-Mean [4.3422], EDL [4.2201], NIG_NLL [3.848], NIG_Reg [37.188]
2023-05-20 20:15:17,172 | this_lr: 
2023-05-20 20:15:17,172 | 0.0001
2023-05-20 20:15:21,652 | Epoch: [71][  0/191]	Time   4.48 (  4.48)	Data 3.4369 (3.4369)	Loss (EDL) 3.554 (3.554)
2023-05-20 20:15:27,195 | Epoch: [71][ 10/191]	Time   0.55 (  0.91)	Data 0.0001 (0.3126)	Loss (EDL) 3.313 (3.318)
2023-05-20 20:15:32,745 | Epoch: [71][ 20/191]	Time   0.54 (  0.74)	Data 0.0001 (0.1639)	Loss (EDL) 3.139 (3.215)
2023-05-20 20:15:38,270 | Epoch: [71][ 30/191]	Time   0.55 (  0.68)	Data 0.0001 (0.1111)	Loss (EDL) 3.124 (3.215)
2023-05-20 20:15:43,861 | Epoch: [71][ 40/191]	Time   0.57 (  0.65)	Data 0.0001 (0.0840)	Loss (EDL) 2.982 (3.193)
2023-05-20 20:15:49,527 | Epoch: [71][ 50/191]	Time   0.59 (  0.63)	Data 0.0004 (0.0676)	Loss (EDL) 3.185 (3.203)
2023-05-20 20:15:55,114 | Epoch: [71][ 60/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0566)	Loss (EDL) 3.216 (3.203)
2023-05-20 20:16:00,763 | Epoch: [71][ 70/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0486)	Loss (EDL) 2.982 (3.189)
2023-05-20 20:16:06,376 | Epoch: [71][ 80/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0427)	Loss (EDL) 3.080 (3.177)
2023-05-20 20:16:12,003 | Epoch: [71][ 90/191]	Time   0.57 (  0.60)	Data 0.0003 (0.0380)	Loss (EDL) 3.257 (3.170)
2023-05-20 20:16:18,297 | Epoch: [71][100/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0343)	Loss (EDL) 3.241 (3.175)
2023-05-20 20:16:23,884 | Epoch: [71][110/191]	Time   0.56 (  0.60)	Data 0.0003 (0.0312)	Loss (EDL) 3.191 (3.177)
2023-05-20 20:16:29,523 | Epoch: [71][120/191]	Time   0.58 (  0.60)	Data 0.0004 (0.0286)	Loss (EDL) 3.272 (3.185)
2023-05-20 20:16:35,130 | Epoch: [71][130/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0265)	Loss (EDL) 2.992 (3.184)
2023-05-20 20:16:40,643 | Epoch: [71][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0246)	Loss (EDL) 3.186 (3.186)
2023-05-20 20:16:46,211 | Epoch: [71][150/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0230)	Loss (EDL) 3.296 (3.187)
2023-05-20 20:16:51,675 | Epoch: [71][160/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0216)	Loss (EDL) 3.192 (3.189)
2023-05-20 20:16:57,127 | Epoch: [71][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0203)	Loss (EDL) 3.102 (3.190)
2023-05-20 20:17:03,072 | Epoch: [71][180/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0192)	Loss (EDL) 3.188 (3.192)
2023-05-20 20:17:08,451 | Epoch: [71][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0182)	Loss (EDL) 3.281 (3.195)
2023-05-20 20:17:08,808 | Create Epoch [71] features of all training data...
2023-05-20 20:17:37,951 | Updated smoothed statistics on Epoch [71]!
2023-05-20 20:17:38,018 | Updated running statistics with Epoch [71] features!
2023-05-20 20:17:41,656 | Val: [ 0/34]	Time  3.350 ( 3.350)	Loss (L1) 6.561 (6.561)	Loss (EDL) 4.173 (4.173)	Loss (NIG_NLL) 3.825 (3.825)	Loss (NIG_Reg) 34.788 (34.788)
2023-05-20 20:17:42,755 | Val: [10/34]	Time  0.103 ( 0.404)	Loss (L1) 7.332 (7.136)	Loss (EDL) 4.291 (4.271)	Loss (NIG_NLL) 3.902 (3.893)	Loss (NIG_Reg) 38.868 (37.833)
2023-05-20 20:17:43,757 | Val: [20/34]	Time  0.100 ( 0.260)	Loss (L1) 7.761 (7.026)	Loss (EDL) 4.491 (4.247)	Loss (NIG_NLL) 4.080 (3.875)	Loss (NIG_Reg) 41.138 (37.249)
2023-05-20 20:17:44,759 | Val: [30/34]	Time  0.100 ( 0.208)	Loss (L1) 8.164 (7.050)	Loss (EDL) 4.591 (4.255)	Loss (NIG_NLL) 4.159 (3.881)	Loss (NIG_Reg) 43.274 (37.379)
2023-05-20 20:17:45,399 |  * Overall: MSE 83.184	L1 7.004	G-Mean 4.464	EDL 4.239	NIG_NLL 3.868	NIG_Reg 37.130
2023-05-20 20:17:45,399 |  * Many: MSE 72.292	L1 6.521	G-Mean 4.172	EDL 4.112	NIG_NLL 3.766	NIG_Reg 34.574
2023-05-20 20:17:45,399 |  * Median: MSE 93.495	L1 7.526	G-Mean 4.771	EDL 4.379	NIG_NLL 3.980	NIG_Reg 39.896
2023-05-20 20:17:45,399 |  * Low: MSE 157.532	L1 10.113	G-Mean 7.044	EDL 5.049	NIG_NLL 4.512	NIG_Reg 53.629
2023-05-20 20:17:45,399 | Best EDL Loss: 6.899
2023-05-20 20:17:45,402 | Epoch #71: Train loss [3.1950]; Val loss: MSE [83.1836], L1 [7.0037], G-Mean [4.4640], EDL [4.2389], NIG_NLL [3.868], NIG_Reg [37.130]
2023-05-20 20:17:45,403 | this_lr: 
2023-05-20 20:17:45,403 | 0.0001
2023-05-20 20:17:49,654 | Epoch: [72][  0/191]	Time   4.25 (  4.25)	Data 3.3472 (3.3472)	Loss (EDL) 3.474 (3.474)
2023-05-20 20:17:55,418 | Epoch: [72][ 10/191]	Time   0.57 (  0.91)	Data 0.0001 (0.3045)	Loss (EDL) 3.478 (3.319)
2023-05-20 20:18:01,013 | Epoch: [72][ 20/191]	Time   0.57 (  0.74)	Data 0.0002 (0.1596)	Loss (EDL) 3.003 (3.197)
2023-05-20 20:18:06,683 | Epoch: [72][ 30/191]	Time   0.56 (  0.69)	Data 0.0001 (0.1082)	Loss (EDL) 3.185 (3.186)
2023-05-20 20:18:12,345 | Epoch: [72][ 40/191]	Time   0.56 (  0.66)	Data 0.0003 (0.0819)	Loss (EDL) 2.921 (3.188)
2023-05-20 20:18:18,024 | Epoch: [72][ 50/191]	Time   0.59 (  0.64)	Data 0.0001 (0.0658)	Loss (EDL) 3.083 (3.183)
2023-05-20 20:18:23,666 | Epoch: [72][ 60/191]	Time   0.55 (  0.63)	Data 0.0001 (0.0551)	Loss (EDL) 3.068 (3.178)
2023-05-20 20:18:29,323 | Epoch: [72][ 70/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0474)	Loss (EDL) 3.173 (3.184)
2023-05-20 20:18:35,512 | Epoch: [72][ 80/191]	Time   0.55 (  0.62)	Data 0.0003 (0.0415)	Loss (EDL) 3.115 (3.185)
2023-05-20 20:18:41,137 | Epoch: [72][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0370)	Loss (EDL) 3.740 (3.183)
2023-05-20 20:18:46,811 | Epoch: [72][100/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0334)	Loss (EDL) 3.116 (3.191)
2023-05-20 20:18:52,425 | Epoch: [72][110/191]	Time   0.58 (  0.60)	Data 0.0004 (0.0304)	Loss (EDL) 2.990 (3.189)
2023-05-20 20:18:57,991 | Epoch: [72][120/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0279)	Loss (EDL) 3.239 (3.190)
2023-05-20 20:19:03,642 | Epoch: [72][130/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0258)	Loss (EDL) 3.314 (3.184)
2023-05-20 20:19:09,143 | Epoch: [72][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0240)	Loss (EDL) 3.703 (3.187)
2023-05-20 20:19:14,601 | Epoch: [72][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0224)	Loss (EDL) 3.080 (3.189)
2023-05-20 20:19:20,478 | Epoch: [72][160/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0210)	Loss (EDL) 3.109 (3.187)
2023-05-20 20:19:25,906 | Epoch: [72][170/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0198)	Loss (EDL) 3.341 (3.184)
2023-05-20 20:19:31,372 | Epoch: [72][180/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0187)	Loss (EDL) 3.383 (3.182)
2023-05-20 20:19:36,738 | Epoch: [72][190/191]	Time   0.46 (  0.58)	Data 0.0002 (0.0178)	Loss (EDL) 3.140 (3.182)
2023-05-20 20:19:37,073 | Create Epoch [72] features of all training data...
2023-05-20 20:20:06,803 | Updated smoothed statistics on Epoch [72]!
2023-05-20 20:20:06,869 | Updated running statistics with Epoch [72] features!
2023-05-20 20:20:10,606 | Val: [ 0/34]	Time  3.456 ( 3.456)	Loss (L1) 6.361 (6.361)	Loss (EDL) 4.136 (4.136)	Loss (NIG_NLL) 3.799 (3.799)	Loss (NIG_Reg) 33.730 (33.730)
2023-05-20 20:20:11,835 | Val: [10/34]	Time  0.100 ( 0.426)	Loss (L1) 7.277 (7.137)	Loss (EDL) 4.310 (4.311)	Loss (NIG_NLL) 3.924 (3.932)	Loss (NIG_Reg) 38.577 (37.838)
2023-05-20 20:20:12,842 | Val: [20/34]	Time  0.101 ( 0.271)	Loss (L1) 7.984 (7.044)	Loss (EDL) 4.599 (4.294)	Loss (NIG_NLL) 4.175 (3.920)	Loss (NIG_Reg) 42.321 (37.345)
2023-05-20 20:20:13,846 | Val: [30/34]	Time  0.100 ( 0.216)	Loss (L1) 8.182 (7.068)	Loss (EDL) 4.644 (4.301)	Loss (NIG_NLL) 4.210 (3.926)	Loss (NIG_Reg) 43.369 (37.472)
2023-05-20 20:20:14,497 |  * Overall: MSE 83.368	L1 7.025	G-Mean 4.508	EDL 4.285	NIG_NLL 3.913	NIG_Reg 37.242
2023-05-20 20:20:14,497 |  * Many: MSE 70.880	L1 6.464	G-Mean 4.164	EDL 4.133	NIG_NLL 3.790	NIG_Reg 34.269
2023-05-20 20:20:14,497 |  * Median: MSE 99.137	L1 7.807	G-Mean 5.045	EDL 4.503	NIG_NLL 4.090	NIG_Reg 41.384
2023-05-20 20:20:14,497 |  * Low: MSE 157.702	L1 10.158	G-Mean 6.993	EDL 5.116	NIG_NLL 4.578	NIG_Reg 53.869
2023-05-20 20:20:14,498 | Best EDL Loss: 6.899
2023-05-20 20:20:14,502 | Epoch #72: Train loss [3.1824]; Val loss: MSE [83.3679], L1 [7.0248], G-Mean [4.5080], EDL [4.2851], NIG_NLL [3.913], NIG_Reg [37.242]
2023-05-20 20:20:14,502 | this_lr: 
2023-05-20 20:20:14,502 | 0.0001
2023-05-20 20:20:18,957 | Epoch: [73][  0/191]	Time   4.45 (  4.45)	Data 3.4764 (3.4764)	Loss (EDL) 3.168 (3.168)
2023-05-20 20:20:24,597 | Epoch: [73][ 10/191]	Time   0.56 (  0.92)	Data 0.0002 (0.3162)	Loss (EDL) 3.171 (3.116)
2023-05-20 20:20:30,318 | Epoch: [73][ 20/191]	Time   0.58 (  0.75)	Data 0.0003 (0.1658)	Loss (EDL) 2.873 (3.102)
2023-05-20 20:20:35,833 | Epoch: [73][ 30/191]	Time   0.55 (  0.69)	Data 0.0001 (0.1124)	Loss (EDL) 3.282 (3.151)
2023-05-20 20:20:41,441 | Epoch: [73][ 40/191]	Time   0.56 (  0.66)	Data 0.0001 (0.0850)	Loss (EDL) 2.972 (3.139)
2023-05-20 20:20:47,164 | Epoch: [73][ 50/191]	Time   0.58 (  0.64)	Data 0.0003 (0.0684)	Loss (EDL) 3.105 (3.138)
2023-05-20 20:20:53,126 | Epoch: [73][ 60/191]	Time   0.56 (  0.63)	Data 0.0002 (0.0572)	Loss (EDL) 3.151 (3.131)
2023-05-20 20:20:58,660 | Epoch: [73][ 70/191]	Time   0.56 (  0.62)	Data 0.0003 (0.0492)	Loss (EDL) 3.135 (3.129)
2023-05-20 20:21:04,311 | Epoch: [73][ 80/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0432)	Loss (EDL) 3.207 (3.133)
2023-05-20 20:21:09,825 | Epoch: [73][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0385)	Loss (EDL) 3.207 (3.136)
2023-05-20 20:21:15,334 | Epoch: [73][100/191]	Time   0.54 (  0.60)	Data 0.0003 (0.0347)	Loss (EDL) 3.002 (3.139)
2023-05-20 20:21:20,901 | Epoch: [73][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0316)	Loss (EDL) 2.982 (3.142)
2023-05-20 20:21:26,559 | Epoch: [73][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0290)	Loss (EDL) 3.205 (3.143)
2023-05-20 20:21:32,408 | Epoch: [73][130/191]	Time   0.79 (  0.59)	Data 0.0001 (0.0268)	Loss (EDL) 3.104 (3.147)
2023-05-20 20:21:37,938 | Epoch: [73][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0249)	Loss (EDL) 3.080 (3.147)
2023-05-20 20:21:43,343 | Epoch: [73][150/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0233)	Loss (EDL) 2.981 (3.149)
2023-05-20 20:21:48,834 | Epoch: [73][160/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0218)	Loss (EDL) 2.954 (3.150)
2023-05-20 20:21:54,287 | Epoch: [73][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0206)	Loss (EDL) 3.049 (3.149)
2023-05-20 20:21:59,769 | Epoch: [73][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0194)	Loss (EDL) 3.174 (3.155)
2023-05-20 20:22:05,140 | Epoch: [73][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0184)	Loss (EDL) 3.266 (3.155)
2023-05-20 20:22:05,468 | Create Epoch [73] features of all training data...
2023-05-20 20:22:35,019 | Updated smoothed statistics on Epoch [73]!
2023-05-20 20:22:35,091 | Updated running statistics with Epoch [73] features!
2023-05-20 20:22:38,835 | Val: [ 0/34]	Time  3.455 ( 3.455)	Loss (L1) 6.585 (6.585)	Loss (EDL) 4.188 (4.188)	Loss (NIG_NLL) 3.838 (3.838)	Loss (NIG_Reg) 34.918 (34.918)
2023-05-20 20:22:39,991 | Val: [10/34]	Time  0.100 ( 0.419)	Loss (L1) 7.331 (7.116)	Loss (EDL) 4.322 (4.297)	Loss (NIG_NLL) 3.933 (3.919)	Loss (NIG_Reg) 38.865 (37.722)
2023-05-20 20:22:40,995 | Val: [20/34]	Time  0.101 ( 0.267)	Loss (L1) 8.015 (7.053)	Loss (EDL) 4.588 (4.286)	Loss (NIG_NLL) 4.163 (3.913)	Loss (NIG_Reg) 42.484 (37.388)
2023-05-20 20:22:41,999 | Val: [30/34]	Time  0.100 ( 0.213)	Loss (L1) 8.280 (7.058)	Loss (EDL) 4.675 (4.291)	Loss (NIG_NLL) 4.236 (3.917)	Loss (NIG_Reg) 43.889 (37.417)
2023-05-20 20:22:42,675 |  * Overall: MSE 83.329	L1 7.011	G-Mean 4.479	EDL 4.274	NIG_NLL 3.902	NIG_Reg 37.170
2023-05-20 20:22:42,675 |  * Many: MSE 70.637	L1 6.438	G-Mean 4.168	EDL 4.116	NIG_NLL 3.775	NIG_Reg 34.128
2023-05-20 20:22:42,675 |  * Median: MSE 98.047	L1 7.786	G-Mean 4.887	EDL 4.493	NIG_NLL 4.080	NIG_Reg 41.273
2023-05-20 20:22:42,675 |  * Low: MSE 162.504	L1 10.288	G-Mean 6.947	EDL 5.154	NIG_NLL 4.608	NIG_Reg 54.554
2023-05-20 20:22:42,676 | Best EDL Loss: 6.899
2023-05-20 20:22:42,680 | Epoch #73: Train loss [3.1552]; Val loss: MSE [83.3295], L1 [7.0115], G-Mean [4.4791], EDL [4.2736], NIG_NLL [3.902], NIG_Reg [37.170]
2023-05-20 20:22:42,680 | this_lr: 
2023-05-20 20:22:42,680 | 0.0001
2023-05-20 20:22:47,430 | Epoch: [74][  0/191]	Time   4.75 (  4.75)	Data 3.7415 (3.7415)	Loss (EDL) 3.061 (3.061)
2023-05-20 20:22:53,153 | Epoch: [74][ 10/191]	Time   0.57 (  0.95)	Data 0.0002 (0.3404)	Loss (EDL) 2.874 (3.112)
2023-05-20 20:22:58,779 | Epoch: [74][ 20/191]	Time   0.55 (  0.77)	Data 0.0001 (0.1785)	Loss (EDL) 3.086 (3.121)
2023-05-20 20:23:04,571 | Epoch: [74][ 30/191]	Time   0.58 (  0.71)	Data 0.0002 (0.1210)	Loss (EDL) 2.855 (3.118)
2023-05-20 20:23:10,226 | Epoch: [74][ 40/191]	Time   0.57 (  0.67)	Data 0.0001 (0.0915)	Loss (EDL) 3.523 (3.139)
2023-05-20 20:23:15,867 | Epoch: [74][ 50/191]	Time   0.58 (  0.65)	Data 0.0001 (0.0736)	Loss (EDL) 3.003 (3.140)
2023-05-20 20:23:21,521 | Epoch: [74][ 60/191]	Time   0.55 (  0.64)	Data 0.0001 (0.0616)	Loss (EDL) 3.357 (3.127)
2023-05-20 20:23:27,149 | Epoch: [74][ 70/191]	Time   0.57 (  0.63)	Data 0.0002 (0.0530)	Loss (EDL) 3.175 (3.128)
2023-05-20 20:23:32,824 | Epoch: [74][ 80/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0464)	Loss (EDL) 3.194 (3.132)
2023-05-20 20:23:38,479 | Epoch: [74][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0414)	Loss (EDL) 2.946 (3.127)
2023-05-20 20:23:44,382 | Epoch: [74][100/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0373)	Loss (EDL) 3.082 (3.117)
2023-05-20 20:23:49,993 | Epoch: [74][110/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0340)	Loss (EDL) 3.022 (3.125)
2023-05-20 20:23:55,606 | Epoch: [74][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0312)	Loss (EDL) 3.418 (3.129)
2023-05-20 20:24:01,242 | Epoch: [74][130/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0288)	Loss (EDL) 3.168 (3.134)
2023-05-20 20:24:06,631 | Epoch: [74][140/191]	Time   0.53 (  0.60)	Data 0.0001 (0.0268)	Loss (EDL) 3.187 (3.128)
2023-05-20 20:24:12,097 | Epoch: [74][150/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0250)	Loss (EDL) 3.228 (3.131)
2023-05-20 20:24:17,601 | Epoch: [74][160/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0235)	Loss (EDL) 2.947 (3.131)
2023-05-20 20:24:23,087 | Epoch: [74][170/191]	Time   0.57 (  0.59)	Data 0.0002 (0.0221)	Loss (EDL) 3.022 (3.128)
2023-05-20 20:24:28,817 | Epoch: [74][180/191]	Time   0.82 (  0.59)	Data 0.0002 (0.0209)	Loss (EDL) 3.122 (3.129)
2023-05-20 20:24:34,184 | Epoch: [74][190/191]	Time   0.47 (  0.58)	Data 0.0002 (0.0198)	Loss (EDL) 3.157 (3.134)
2023-05-20 20:24:34,502 | Create Epoch [74] features of all training data...
2023-05-20 20:25:03,389 | Updated smoothed statistics on Epoch [74]!
2023-05-20 20:25:03,456 | Updated running statistics with Epoch [74] features!
2023-05-20 20:25:07,085 | Val: [ 0/34]	Time  3.344 ( 3.344)	Loss (L1) 6.457 (6.457)	Loss (EDL) 4.163 (4.163)	Loss (NIG_NLL) 3.820 (3.820)	Loss (NIG_Reg) 34.238 (34.238)
2023-05-20 20:25:08,355 | Val: [10/34]	Time  0.100 ( 0.420)	Loss (L1) 7.119 (7.127)	Loss (EDL) 4.263 (4.308)	Loss (NIG_NLL) 3.885 (3.930)	Loss (NIG_Reg) 37.741 (37.786)
2023-05-20 20:25:09,360 | Val: [20/34]	Time  0.101 ( 0.268)	Loss (L1) 7.946 (7.016)	Loss (EDL) 4.580 (4.283)	Loss (NIG_NLL) 4.159 (3.911)	Loss (NIG_Reg) 42.125 (37.198)
2023-05-20 20:25:10,367 | Val: [30/34]	Time  0.103 ( 0.214)	Loss (L1) 7.934 (6.971)	Loss (EDL) 4.591 (4.274)	Loss (NIG_NLL) 4.170 (3.904)	Loss (NIG_Reg) 42.059 (36.958)
2023-05-20 20:25:11,018 |  * Overall: MSE 82.714	L1 6.947	G-Mean 4.371	EDL 4.264	NIG_NLL 3.896	NIG_Reg 36.832
2023-05-20 20:25:11,018 |  * Many: MSE 73.513	L1 6.529	G-Mean 4.036	EDL 4.158	NIG_NLL 3.812	NIG_Reg 34.613
2023-05-20 20:25:11,018 |  * Median: MSE 93.663	L1 7.523	G-Mean 5.006	EDL 4.404	NIG_NLL 4.006	NIG_Reg 39.879
2023-05-20 20:25:11,018 |  * Low: MSE 139.334	L1 9.308	G-Mean 6.368	EDL 4.878	NIG_NLL 4.385	NIG_Reg 49.362
2023-05-20 20:25:11,019 | Best EDL Loss: 6.899
2023-05-20 20:25:11,023 | Epoch #74: Train loss [3.1342]; Val loss: MSE [82.7142], L1 [6.9472], G-Mean [4.3708], EDL [4.2640], NIG_NLL [3.896], NIG_Reg [36.832]
2023-05-20 20:25:11,023 | this_lr: 
2023-05-20 20:25:11,023 | 0.0001
2023-05-20 20:25:15,355 | Epoch: [75][  0/191]	Time   4.33 (  4.33)	Data 3.3539 (3.3539)	Loss (EDL) 2.995 (2.995)
2023-05-20 20:25:21,034 | Epoch: [75][ 10/191]	Time   0.55 (  0.91)	Data 0.0002 (0.3051)	Loss (EDL) 3.115 (3.033)
2023-05-20 20:25:26,575 | Epoch: [75][ 20/191]	Time   0.55 (  0.74)	Data 0.0001 (0.1599)	Loss (EDL) 2.935 (3.038)
2023-05-20 20:25:32,176 | Epoch: [75][ 30/191]	Time   0.57 (  0.68)	Data 0.0001 (0.1084)	Loss (EDL) 3.187 (3.092)
2023-05-20 20:25:37,804 | Epoch: [75][ 40/191]	Time   0.57 (  0.65)	Data 0.0001 (0.0820)	Loss (EDL) 3.113 (3.109)
2023-05-20 20:25:43,482 | Epoch: [75][ 50/191]	Time   0.56 (  0.64)	Data 0.0002 (0.0660)	Loss (EDL) 3.198 (3.119)
2023-05-20 20:25:49,144 | Epoch: [75][ 60/191]	Time   0.57 (  0.62)	Data 0.0001 (0.0552)	Loss (EDL) 3.294 (3.115)
2023-05-20 20:25:54,780 | Epoch: [75][ 70/191]	Time   0.57 (  0.62)	Data 0.0003 (0.0475)	Loss (EDL) 2.818 (3.112)
2023-05-20 20:26:00,446 | Epoch: [75][ 80/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0416)	Loss (EDL) 2.959 (3.104)
2023-05-20 20:26:06,364 | Epoch: [75][ 90/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0371)	Loss (EDL) 3.132 (3.105)
2023-05-20 20:26:11,981 | Epoch: [75][100/191]	Time   0.54 (  0.60)	Data 0.0003 (0.0334)	Loss (EDL) 3.316 (3.114)
2023-05-20 20:26:17,587 | Epoch: [75][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0305)	Loss (EDL) 3.032 (3.121)
2023-05-20 20:26:23,241 | Epoch: [75][120/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0280)	Loss (EDL) 2.916 (3.122)
2023-05-20 20:26:28,820 | Epoch: [75][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0259)	Loss (EDL) 2.987 (3.126)
2023-05-20 20:26:34,314 | Epoch: [75][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0240)	Loss (EDL) 3.043 (3.129)
2023-05-20 20:26:39,788 | Epoch: [75][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0225)	Loss (EDL) 3.073 (3.127)
2023-05-20 20:26:45,184 | Epoch: [75][160/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0211)	Loss (EDL) 3.286 (3.126)
2023-05-20 20:26:50,958 | Epoch: [75][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0198)	Loss (EDL) 3.043 (3.122)
2023-05-20 20:26:56,392 | Epoch: [75][180/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0188)	Loss (EDL) 3.081 (3.128)
2023-05-20 20:27:01,858 | Epoch: [75][190/191]	Time   0.48 (  0.58)	Data 0.0001 (0.0178)	Loss (EDL) 3.076 (3.130)
2023-05-20 20:27:02,170 | Create Epoch [75] features of all training data...
2023-05-20 20:27:31,334 | Updated smoothed statistics on Epoch [75]!
2023-05-20 20:27:31,399 | Updated running statistics with Epoch [75] features!
2023-05-20 20:27:35,166 | Val: [ 0/34]	Time  3.471 ( 3.471)	Loss (L1) 6.410 (6.410)	Loss (EDL) 4.174 (4.174)	Loss (NIG_NLL) 3.834 (3.834)	Loss (NIG_Reg) 33.985 (33.985)
2023-05-20 20:27:36,558 | Val: [10/34]	Time  0.100 ( 0.442)	Loss (L1) 7.058 (7.109)	Loss (EDL) 4.261 (4.322)	Loss (NIG_NLL) 3.887 (3.945)	Loss (NIG_Reg) 37.414 (37.686)
2023-05-20 20:27:37,560 | Val: [20/34]	Time  0.100 ( 0.279)	Loss (L1) 8.069 (7.021)	Loss (EDL) 4.645 (4.300)	Loss (NIG_NLL) 4.218 (3.928)	Loss (NIG_Reg) 42.774 (37.219)
2023-05-20 20:27:38,564 | Val: [30/34]	Time  0.101 ( 0.222)	Loss (L1) 7.867 (7.011)	Loss (EDL) 4.578 (4.299)	Loss (NIG_NLL) 4.161 (3.928)	Loss (NIG_Reg) 41.703 (37.165)
2023-05-20 20:27:39,203 |  * Overall: MSE 83.280	L1 6.971	G-Mean 4.378	EDL 4.284	NIG_NLL 3.914	NIG_Reg 36.953
2023-05-20 20:27:39,203 |  * Many: MSE 72.761	L1 6.513	G-Mean 4.101	EDL 4.160	NIG_NLL 3.815	NIG_Reg 34.528
2023-05-20 20:27:39,203 |  * Median: MSE 93.016	L1 7.470	G-Mean 4.729	EDL 4.419	NIG_NLL 4.023	NIG_Reg 39.597
2023-05-20 20:27:39,203 |  * Low: MSE 155.699	L1 9.909	G-Mean 6.553	EDL 5.075	NIG_NLL 4.549	NIG_Reg 52.543
2023-05-20 20:27:39,203 | Best EDL Loss: 6.899
2023-05-20 20:27:39,207 | Epoch #75: Train loss [3.1300]; Val loss: MSE [83.2799], L1 [6.9705], G-Mean [4.3779], EDL [4.2837], NIG_NLL [3.914], NIG_Reg [36.953]
2023-05-20 20:27:39,207 | this_lr: 
2023-05-20 20:27:39,207 | 0.0001
2023-05-20 20:27:43,584 | Epoch: [76][  0/191]	Time   4.38 (  4.38)	Data 3.3840 (3.3840)	Loss (EDL) 2.948 (2.948)
2023-05-20 20:27:49,264 | Epoch: [76][ 10/191]	Time   0.57 (  0.91)	Data 0.0001 (0.3078)	Loss (EDL) 3.117 (3.095)
2023-05-20 20:27:54,926 | Epoch: [76][ 20/191]	Time   0.56 (  0.75)	Data 0.0002 (0.1613)	Loss (EDL) 2.905 (3.091)
2023-05-20 20:28:00,494 | Epoch: [76][ 30/191]	Time   0.55 (  0.69)	Data 0.0002 (0.1094)	Loss (EDL) 3.267 (3.103)
2023-05-20 20:28:06,132 | Epoch: [76][ 40/191]	Time   0.57 (  0.66)	Data 0.0001 (0.0828)	Loss (EDL) 3.278 (3.134)
2023-05-20 20:28:11,695 | Epoch: [76][ 50/191]	Time   0.55 (  0.64)	Data 0.0001 (0.0666)	Loss (EDL) 2.902 (3.149)
2023-05-20 20:28:17,506 | Epoch: [76][ 60/191]	Time   0.62 (  0.63)	Data 0.0002 (0.0557)	Loss (EDL) 3.176 (3.134)
2023-05-20 20:28:23,472 | Epoch: [76][ 70/191]	Time   0.55 (  0.62)	Data 0.0003 (0.0479)	Loss (EDL) 3.711 (3.135)
2023-05-20 20:28:29,148 | Epoch: [76][ 80/191]	Time   0.58 (  0.62)	Data 0.0002 (0.0420)	Loss (EDL) 3.022 (3.136)
2023-05-20 20:28:34,724 | Epoch: [76][ 90/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0374)	Loss (EDL) 2.976 (3.134)
2023-05-20 20:28:40,378 | Epoch: [76][100/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0337)	Loss (EDL) 3.102 (3.138)
2023-05-20 20:28:46,020 | Epoch: [76][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0307)	Loss (EDL) 3.015 (3.137)
2023-05-20 20:28:51,626 | Epoch: [76][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0282)	Loss (EDL) 3.053 (3.130)
2023-05-20 20:28:57,126 | Epoch: [76][130/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0261)	Loss (EDL) 3.178 (3.127)
2023-05-20 20:29:02,607 | Epoch: [76][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0242)	Loss (EDL) 2.997 (3.120)
2023-05-20 20:29:08,358 | Epoch: [76][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0226)	Loss (EDL) 3.293 (3.121)
2023-05-20 20:29:13,801 | Epoch: [76][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0212)	Loss (EDL) 3.096 (3.119)
2023-05-20 20:29:19,279 | Epoch: [76][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0200)	Loss (EDL) 3.010 (3.117)
2023-05-20 20:29:24,779 | Epoch: [76][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0189)	Loss (EDL) 3.356 (3.119)
2023-05-20 20:29:30,161 | Epoch: [76][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0179)	Loss (EDL) 3.143 (3.119)
2023-05-20 20:29:30,522 | Create Epoch [76] features of all training data...
2023-05-20 20:30:00,394 | Updated smoothed statistics on Epoch [76]!
2023-05-20 20:30:00,461 | Updated running statistics with Epoch [76] features!
2023-05-20 20:30:04,584 | Val: [ 0/34]	Time  3.840 ( 3.840)	Loss (L1) 6.647 (6.647)	Loss (EDL) 4.259 (4.259)	Loss (NIG_NLL) 3.906 (3.906)	Loss (NIG_Reg) 35.238 (35.238)
2023-05-20 20:30:05,926 | Val: [10/34]	Time  0.103 ( 0.471)	Loss (L1) 7.048 (7.103)	Loss (EDL) 4.281 (4.345)	Loss (NIG_NLL) 3.907 (3.968)	Loss (NIG_Reg) 37.363 (37.652)
2023-05-20 20:30:06,928 | Val: [20/34]	Time  0.100 ( 0.295)	Loss (L1) 7.887 (7.048)	Loss (EDL) 4.624 (4.333)	Loss (NIG_NLL) 4.206 (3.960)	Loss (NIG_Reg) 41.806 (37.359)
2023-05-20 20:30:07,932 | Val: [30/34]	Time  0.101 ( 0.232)	Loss (L1) 8.337 (7.033)	Loss (EDL) 4.756 (4.332)	Loss (NIG_NLL) 4.314 (3.959)	Loss (NIG_Reg) 44.191 (37.280)
2023-05-20 20:30:08,580 |  * Overall: MSE 83.101	L1 6.993	G-Mean 4.414	EDL 4.317	NIG_NLL 3.947	NIG_Reg 37.072
2023-05-20 20:30:08,580 |  * Many: MSE 69.802	L1 6.363	G-Mean 3.985	EDL 4.136	NIG_NLL 3.798	NIG_Reg 33.728
2023-05-20 20:30:08,580 |  * Median: MSE 99.479	L1 7.874	G-Mean 5.150	EDL 4.583	NIG_NLL 4.166	NIG_Reg 41.739
2023-05-20 20:30:08,580 |  * Low: MSE 163.415	L1 10.514	G-Mean 7.553	EDL 5.298	NIG_NLL 4.740	NIG_Reg 55.750
2023-05-20 20:30:08,581 | Best EDL Loss: 6.899
2023-05-20 20:30:08,585 | Epoch #76: Train loss [3.1193]; Val loss: MSE [83.1013], L1 [6.9933], G-Mean [4.4138], EDL [4.3174], NIG_NLL [3.947], NIG_Reg [37.072]
2023-05-20 20:30:08,586 | this_lr: 
2023-05-20 20:30:08,586 | 0.0001
2023-05-20 20:30:13,071 | Epoch: [77][  0/191]	Time   4.48 (  4.48)	Data 3.5154 (3.5154)	Loss (EDL) 3.280 (3.280)
2023-05-20 20:30:18,668 | Epoch: [77][ 10/191]	Time   0.59 (  0.92)	Data 0.0002 (0.3198)	Loss (EDL) 3.024 (3.089)
2023-05-20 20:30:24,218 | Epoch: [77][ 20/191]	Time   0.56 (  0.74)	Data 0.0001 (0.1676)	Loss (EDL) 3.398 (3.147)
2023-05-20 20:30:29,867 | Epoch: [77][ 30/191]	Time   0.55 (  0.69)	Data 0.0001 (0.1136)	Loss (EDL) 3.167 (3.121)
2023-05-20 20:30:35,516 | Epoch: [77][ 40/191]	Time   0.55 (  0.66)	Data 0.0001 (0.0860)	Loss (EDL) 2.789 (3.097)
2023-05-20 20:30:41,278 | Epoch: [77][ 50/191]	Time   0.57 (  0.64)	Data 0.0002 (0.0691)	Loss (EDL) 2.922 (3.077)
2023-05-20 20:30:46,891 | Epoch: [77][ 60/191]	Time   0.57 (  0.63)	Data 0.0002 (0.0578)	Loss (EDL) 3.470 (3.074)
2023-05-20 20:30:52,458 | Epoch: [77][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0497)	Loss (EDL) 3.028 (3.089)
2023-05-20 20:30:58,053 | Epoch: [77][ 80/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0436)	Loss (EDL) 3.184 (3.085)
2023-05-20 20:31:03,639 | Epoch: [77][ 90/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0388)	Loss (EDL) 3.410 (3.087)
2023-05-20 20:31:09,267 | Epoch: [77][100/191]	Time   0.58 (  0.60)	Data 0.0003 (0.0350)	Loss (EDL) 2.955 (3.077)
2023-05-20 20:31:14,975 | Epoch: [77][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0319)	Loss (EDL) 3.170 (3.080)
2023-05-20 20:31:20,855 | Epoch: [77][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0293)	Loss (EDL) 3.348 (3.088)
2023-05-20 20:31:26,454 | Epoch: [77][130/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0271)	Loss (EDL) 3.071 (3.088)
2023-05-20 20:31:31,978 | Epoch: [77][140/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0252)	Loss (EDL) 2.773 (3.084)
2023-05-20 20:31:37,425 | Epoch: [77][150/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0235)	Loss (EDL) 3.008 (3.082)
2023-05-20 20:31:42,920 | Epoch: [77][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0221)	Loss (EDL) 3.154 (3.083)
2023-05-20 20:31:48,430 | Epoch: [77][170/191]	Time   0.54 (  0.58)	Data 0.0002 (0.0208)	Loss (EDL) 2.915 (3.085)
2023-05-20 20:31:53,885 | Epoch: [77][180/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0196)	Loss (EDL) 3.226 (3.087)
2023-05-20 20:31:59,156 | Epoch: [77][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0186)	Loss (EDL) 2.901 (3.087)
2023-05-20 20:31:59,484 | Create Epoch [77] features of all training data...
2023-05-20 20:32:28,891 | Updated smoothed statistics on Epoch [77]!
2023-05-20 20:32:28,956 | Updated running statistics with Epoch [77] features!
2023-05-20 20:32:32,525 | Val: [ 0/34]	Time  3.278 ( 3.278)	Loss (L1) 7.023 (7.023)	Loss (EDL) 4.406 (4.406)	Loss (NIG_NLL) 4.034 (4.034)	Loss (NIG_Reg) 37.232 (37.232)
2023-05-20 20:32:33,816 | Val: [10/34]	Time  0.100 ( 0.415)	Loss (L1) 7.294 (7.190)	Loss (EDL) 4.387 (4.385)	Loss (NIG_NLL) 4.000 (4.004)	Loss (NIG_Reg) 38.665 (38.117)
2023-05-20 20:32:34,820 | Val: [20/34]	Time  0.100 ( 0.265)	Loss (L1) 7.940 (7.163)	Loss (EDL) 4.638 (4.380)	Loss (NIG_NLL) 4.217 (4.000)	Loss (NIG_Reg) 42.085 (37.969)
2023-05-20 20:32:35,830 | Val: [30/34]	Time  0.101 ( 0.212)	Loss (L1) 8.396 (7.170)	Loss (EDL) 4.775 (4.385)	Loss (NIG_NLL) 4.330 (4.005)	Loss (NIG_Reg) 44.504 (38.010)
2023-05-20 20:32:36,464 |  * Overall: MSE 85.783	L1 7.114	G-Mean 4.456	EDL 4.364	NIG_NLL 3.987	NIG_Reg 37.713
2023-05-20 20:32:36,464 |  * Many: MSE 70.367	L1 6.434	G-Mean 4.037	EDL 4.175	NIG_NLL 3.834	NIG_Reg 34.108
2023-05-20 20:32:36,464 |  * Median: MSE 108.106	L1 8.216	G-Mean 5.203	EDL 4.678	NIG_NLL 4.242	NIG_Reg 43.551
2023-05-20 20:32:36,464 |  * Low: MSE 169.649	L1 10.488	G-Mean 7.375	EDL 5.280	NIG_NLL 4.724	NIG_Reg 55.611
2023-05-20 20:32:36,465 | Best EDL Loss: 6.899
2023-05-20 20:32:36,469 | Epoch #77: Train loss [3.0868]; Val loss: MSE [85.7830], L1 [7.1141], G-Mean [4.4557], EDL [4.3641], NIG_NLL [3.987], NIG_Reg [37.713]
2023-05-20 20:32:36,469 | this_lr: 
2023-05-20 20:32:36,469 | 0.0001
2023-05-20 20:32:41,384 | Epoch: [78][  0/191]	Time   4.91 (  4.91)	Data 4.0526 (4.0526)	Loss (EDL) 2.931 (2.931)
2023-05-20 20:32:47,170 | Epoch: [78][ 10/191]	Time   0.54 (  0.97)	Data 0.0001 (0.3687)	Loss (EDL) 2.788 (3.036)
2023-05-20 20:32:52,770 | Epoch: [78][ 20/191]	Time   0.56 (  0.78)	Data 0.0002 (0.1932)	Loss (EDL) 2.826 (3.028)
2023-05-20 20:32:58,402 | Epoch: [78][ 30/191]	Time   0.56 (  0.71)	Data 0.0001 (0.1309)	Loss (EDL) 3.126 (3.043)
2023-05-20 20:33:03,974 | Epoch: [78][ 40/191]	Time   0.56 (  0.67)	Data 0.0001 (0.0991)	Loss (EDL) 3.022 (3.060)
2023-05-20 20:33:09,801 | Epoch: [78][ 50/191]	Time   0.59 (  0.65)	Data 0.0002 (0.0797)	Loss (EDL) 3.116 (3.060)
2023-05-20 20:33:15,534 | Epoch: [78][ 60/191]	Time   0.58 (  0.64)	Data 0.0002 (0.0667)	Loss (EDL) 3.123 (3.058)
2023-05-20 20:33:21,285 | Epoch: [78][ 70/191]	Time   0.62 (  0.63)	Data 0.0002 (0.0573)	Loss (EDL) 3.002 (3.051)
2023-05-20 20:33:27,194 | Epoch: [78][ 80/191]	Time   0.57 (  0.63)	Data 0.0003 (0.0502)	Loss (EDL) 2.894 (3.045)
2023-05-20 20:33:32,849 | Epoch: [78][ 90/191]	Time   0.55 (  0.62)	Data 0.0002 (0.0448)	Loss (EDL) 3.052 (3.047)
2023-05-20 20:33:38,466 | Epoch: [78][100/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0404)	Loss (EDL) 2.906 (3.047)
2023-05-20 20:33:43,997 | Epoch: [78][110/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0367)	Loss (EDL) 3.163 (3.051)
2023-05-20 20:33:49,617 | Epoch: [78][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0337)	Loss (EDL) 2.923 (3.053)
2023-05-20 20:33:55,169 | Epoch: [78][130/191]	Time   0.53 (  0.60)	Data 0.0001 (0.0312)	Loss (EDL) 2.988 (3.054)
2023-05-20 20:34:00,671 | Epoch: [78][140/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0290)	Loss (EDL) 3.020 (3.055)
2023-05-20 20:34:06,519 | Epoch: [78][150/191]	Time   0.57 (  0.60)	Data 0.0001 (0.0271)	Loss (EDL) 3.113 (3.057)
2023-05-20 20:34:11,971 | Epoch: [78][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0254)	Loss (EDL) 2.834 (3.056)
2023-05-20 20:34:17,419 | Epoch: [78][170/191]	Time   0.52 (  0.59)	Data 0.0001 (0.0239)	Loss (EDL) 3.102 (3.060)
2023-05-20 20:34:22,896 | Epoch: [78][180/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0226)	Loss (EDL) 3.340 (3.064)
2023-05-20 20:34:28,319 | Epoch: [78][190/191]	Time   0.46 (  0.59)	Data 0.0001 (0.0214)	Loss (EDL) 3.084 (3.068)
2023-05-20 20:34:28,665 | Create Epoch [78] features of all training data...
2023-05-20 20:34:58,159 | Updated smoothed statistics on Epoch [78]!
2023-05-20 20:34:58,225 | Updated running statistics with Epoch [78] features!
2023-05-20 20:35:01,652 | Val: [ 0/34]	Time  3.121 ( 3.121)	Loss (L1) 6.731 (6.731)	Loss (EDL) 4.309 (4.309)	Loss (NIG_NLL) 3.952 (3.952)	Loss (NIG_Reg) 35.688 (35.688)
2023-05-20 20:35:03,046 | Val: [10/34]	Time  0.101 ( 0.410)	Loss (L1) 7.123 (7.033)	Loss (EDL) 4.299 (4.324)	Loss (NIG_NLL) 3.921 (3.951)	Loss (NIG_Reg) 37.760 (37.282)
2023-05-20 20:35:04,057 | Val: [20/34]	Time  0.100 ( 0.263)	Loss (L1) 7.851 (6.982)	Loss (EDL) 4.628 (4.316)	Loss (NIG_NLL) 4.212 (3.945)	Loss (NIG_Reg) 41.616 (37.014)
2023-05-20 20:35:05,063 | Val: [30/34]	Time  0.100 ( 0.211)	Loss (L1) 8.433 (6.982)	Loss (EDL) 4.798 (4.320)	Loss (NIG_NLL) 4.351 (3.950)	Loss (NIG_Reg) 44.700 (37.015)
2023-05-20 20:35:05,711 |  * Overall: MSE 82.942	L1 6.953	G-Mean 4.350	EDL 4.309	NIG_NLL 3.941	NIG_Reg 36.858
2023-05-20 20:35:05,711 |  * Many: MSE 72.008	L1 6.455	G-Mean 3.997	EDL 4.171	NIG_NLL 3.829	NIG_Reg 34.219
2023-05-20 20:35:05,711 |  * Median: MSE 95.395	L1 7.570	G-Mean 4.881	EDL 4.486	NIG_NLL 4.085	NIG_Reg 40.125
2023-05-20 20:35:05,711 |  * Low: MSE 151.773	L1 9.947	G-Mean 7.039	EDL 5.125	NIG_NLL 4.597	NIG_Reg 52.743
2023-05-20 20:35:05,712 | Best EDL Loss: 6.899
2023-05-20 20:35:05,715 | Epoch #78: Train loss [3.0680]; Val loss: MSE [82.9421], L1 [6.9529], G-Mean [4.3499], EDL [4.3093], NIG_NLL [3.941], NIG_Reg [36.858]
2023-05-20 20:35:05,716 | this_lr: 
2023-05-20 20:35:05,716 | 0.0001
2023-05-20 20:35:09,996 | Epoch: [79][  0/191]	Time   4.28 (  4.28)	Data 3.3800 (3.3800)	Loss (EDL) 3.120 (3.120)
2023-05-20 20:35:15,797 | Epoch: [79][ 10/191]	Time   0.57 (  0.92)	Data 0.0003 (0.3075)	Loss (EDL) 2.831 (3.049)
2023-05-20 20:35:21,419 | Epoch: [79][ 20/191]	Time   0.56 (  0.75)	Data 0.0001 (0.1612)	Loss (EDL) 3.471 (3.089)
2023-05-20 20:35:27,047 | Epoch: [79][ 30/191]	Time   0.58 (  0.69)	Data 0.0003 (0.1093)	Loss (EDL) 3.170 (3.056)
2023-05-20 20:35:32,569 | Epoch: [79][ 40/191]	Time   0.54 (  0.65)	Data 0.0003 (0.0827)	Loss (EDL) 3.254 (3.055)
2023-05-20 20:35:38,443 | Epoch: [79][ 50/191]	Time   0.57 (  0.64)	Data 0.0001 (0.0665)	Loss (EDL) 3.374 (3.060)
2023-05-20 20:35:44,079 | Epoch: [79][ 60/191]	Time   0.57 (  0.63)	Data 0.0001 (0.0556)	Loss (EDL) 3.023 (3.056)
2023-05-20 20:35:49,746 | Epoch: [79][ 70/191]	Time   0.57 (  0.62)	Data 0.0006 (0.0478)	Loss (EDL) 3.135 (3.054)
2023-05-20 20:35:55,244 | Epoch: [79][ 80/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0420)	Loss (EDL) 2.813 (3.057)
2023-05-20 20:36:00,824 | Epoch: [79][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0374)	Loss (EDL) 2.918 (3.056)
2023-05-20 20:36:06,336 | Epoch: [79][100/191]	Time   0.53 (  0.60)	Data 0.0002 (0.0337)	Loss (EDL) 3.030 (3.055)
2023-05-20 20:36:11,868 | Epoch: [79][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0307)	Loss (EDL) 3.395 (3.058)
2023-05-20 20:36:17,437 | Epoch: [79][120/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0282)	Loss (EDL) 3.034 (3.058)
2023-05-20 20:36:23,137 | Epoch: [79][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0260)	Loss (EDL) 3.250 (3.060)
2023-05-20 20:36:28,594 | Epoch: [79][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0242)	Loss (EDL) 2.931 (3.060)
2023-05-20 20:36:34,059 | Epoch: [79][150/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0226)	Loss (EDL) 3.114 (3.060)
2023-05-20 20:36:39,492 | Epoch: [79][160/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0212)	Loss (EDL) 2.984 (3.060)
2023-05-20 20:36:44,971 | Epoch: [79][170/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0200)	Loss (EDL) 2.765 (3.053)
2023-05-20 20:36:50,432 | Epoch: [79][180/191]	Time   0.54 (  0.58)	Data 0.0002 (0.0189)	Loss (EDL) 2.963 (3.048)
2023-05-20 20:36:55,835 | Epoch: [79][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0179)	Loss (EDL) 3.178 (3.048)
2023-05-20 20:36:56,180 | Create Epoch [79] features of all training data...
2023-05-20 20:37:25,982 | Updated smoothed statistics on Epoch [79]!
2023-05-20 20:37:26,055 | Updated running statistics with Epoch [79] features!
2023-05-20 20:37:29,613 | Val: [ 0/34]	Time  3.270 ( 3.270)	Loss (L1) 6.412 (6.412)	Loss (EDL) 4.279 (4.279)	Loss (NIG_NLL) 3.939 (3.939)	Loss (NIG_Reg) 33.994 (33.994)
2023-05-20 20:37:31,006 | Val: [10/34]	Time  0.101 ( 0.424)	Loss (L1) 7.502 (7.084)	Loss (EDL) 4.484 (4.406)	Loss (NIG_NLL) 4.087 (4.030)	Loss (NIG_Reg) 39.766 (37.555)
2023-05-20 20:37:32,022 | Val: [20/34]	Time  0.100 ( 0.270)	Loss (L1) 8.029 (7.029)	Loss (EDL) 4.761 (4.395)	Loss (NIG_NLL) 4.335 (4.022)	Loss (NIG_Reg) 42.560 (37.263)
2023-05-20 20:37:33,028 | Val: [30/34]	Time  0.101 ( 0.216)	Loss (L1) 8.312 (7.027)	Loss (EDL) 4.805 (4.398)	Loss (NIG_NLL) 4.365 (4.026)	Loss (NIG_Reg) 44.060 (37.249)
2023-05-20 20:37:33,654 |  * Overall: MSE 83.407	L1 6.997	G-Mean 4.432	EDL 4.387	NIG_NLL 4.016	NIG_Reg 37.090
2023-05-20 20:37:33,654 |  * Many: MSE 71.907	L1 6.485	G-Mean 4.105	EDL 4.245	NIG_NLL 3.901	NIG_Reg 34.377
2023-05-20 20:37:33,654 |  * Median: MSE 96.050	L1 7.632	G-Mean 4.875	EDL 4.569	NIG_NLL 4.165	NIG_Reg 40.452
2023-05-20 20:37:33,654 |  * Low: MSE 157.045	L1 10.073	G-Mean 7.019	EDL 5.232	NIG_NLL 4.698	NIG_Reg 53.412
2023-05-20 20:37:33,655 | Best EDL Loss: 6.899
2023-05-20 20:37:33,658 | Epoch #79: Train loss [3.0478]; Val loss: MSE [83.4067], L1 [6.9967], G-Mean [4.4316], EDL [4.3873], NIG_NLL [4.016], NIG_Reg [37.090]
2023-05-20 20:37:33,658 | this_lr: 
2023-05-20 20:37:33,658 | 1e-05
2023-05-20 20:37:37,954 | Epoch: [80][  0/191]	Time   4.29 (  4.29)	Data 3.4197 (3.4197)	Loss (EDL) 3.038 (3.038)
2023-05-20 20:37:43,727 | Epoch: [80][ 10/191]	Time   0.54 (  0.92)	Data 0.0001 (0.3111)	Loss (EDL) 3.276 (3.073)
2023-05-20 20:37:49,483 | Epoch: [80][ 20/191]	Time   0.55 (  0.75)	Data 0.0003 (0.1630)	Loss (EDL) 3.167 (3.057)
2023-05-20 20:37:55,061 | Epoch: [80][ 30/191]	Time   0.57 (  0.69)	Data 0.0003 (0.1105)	Loss (EDL) 2.874 (3.029)
2023-05-20 20:38:00,632 | Epoch: [80][ 40/191]	Time   0.55 (  0.66)	Data 0.0002 (0.0836)	Loss (EDL) 3.051 (3.027)
2023-05-20 20:38:06,277 | Epoch: [80][ 50/191]	Time   0.54 (  0.64)	Data 0.0002 (0.0673)	Loss (EDL) 2.763 (3.009)
2023-05-20 20:38:11,940 | Epoch: [80][ 60/191]	Time   0.56 (  0.63)	Data 0.0002 (0.0563)	Loss (EDL) 3.078 (3.015)
2023-05-20 20:38:17,573 | Epoch: [80][ 70/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0484)	Loss (EDL) 3.072 (3.015)
2023-05-20 20:38:23,462 | Epoch: [80][ 80/191]	Time   0.55 (  0.61)	Data 0.0001 (0.0424)	Loss (EDL) 2.886 (3.014)
2023-05-20 20:38:29,082 | Epoch: [80][ 90/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0378)	Loss (EDL) 3.099 (3.011)
2023-05-20 20:38:34,894 | Epoch: [80][100/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0341)	Loss (EDL) 3.087 (3.008)
2023-05-20 20:38:40,545 | Epoch: [80][110/191]	Time   0.60 (  0.60)	Data 0.0002 (0.0310)	Loss (EDL) 3.051 (3.008)
2023-05-20 20:38:46,171 | Epoch: [80][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0285)	Loss (EDL) 2.992 (3.007)
2023-05-20 20:38:51,782 | Epoch: [80][130/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0264)	Loss (EDL) 2.826 (3.009)
2023-05-20 20:38:57,283 | Epoch: [80][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0245)	Loss (EDL) 3.011 (3.007)
2023-05-20 20:39:02,787 | Epoch: [80][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0229)	Loss (EDL) 2.962 (3.011)
2023-05-20 20:39:08,551 | Epoch: [80][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0215)	Loss (EDL) 3.066 (3.018)
2023-05-20 20:39:13,983 | Epoch: [80][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0202)	Loss (EDL) 3.216 (3.023)
2023-05-20 20:39:19,482 | Epoch: [80][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0191)	Loss (EDL) 3.622 (3.022)
2023-05-20 20:39:24,897 | Epoch: [80][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0181)	Loss (EDL) 3.000 (3.019)
2023-05-20 20:39:25,229 | Create Epoch [80] features of all training data...
2023-05-20 20:39:54,725 | Updated smoothed statistics on Epoch [80]!
2023-05-20 20:39:54,792 | Updated running statistics with Epoch [80] features!
2023-05-20 20:39:58,668 | Val: [ 0/34]	Time  3.594 ( 3.594)	Loss (L1) 6.458 (6.458)	Loss (EDL) 4.294 (4.294)	Loss (NIG_NLL) 3.952 (3.952)	Loss (NIG_Reg) 34.240 (34.240)
2023-05-20 20:40:00,011 | Val: [10/34]	Time  0.100 ( 0.449)	Loss (L1) 7.337 (7.079)	Loss (EDL) 4.440 (4.408)	Loss (NIG_NLL) 4.052 (4.032)	Loss (NIG_Reg) 38.893 (37.525)
2023-05-20 20:40:01,021 | Val: [20/34]	Time  0.100 ( 0.283)	Loss (L1) 7.954 (7.023)	Loss (EDL) 4.728 (4.394)	Loss (NIG_NLL) 4.306 (4.022)	Loss (NIG_Reg) 42.162 (37.231)
2023-05-20 20:40:02,032 | Val: [30/34]	Time  0.102 ( 0.224)	Loss (L1) 8.291 (7.013)	Loss (EDL) 4.828 (4.398)	Loss (NIG_NLL) 4.389 (4.026)	Loss (NIG_Reg) 43.944 (37.176)
2023-05-20 20:40:02,732 |  * Overall: MSE 83.156	L1 6.981	G-Mean 4.419	EDL 4.386	NIG_NLL 4.016	NIG_Reg 37.005
2023-05-20 20:40:02,733 |  * Many: MSE 70.978	L1 6.435	G-Mean 4.092	EDL 4.231	NIG_NLL 3.890	NIG_Reg 34.114
2023-05-20 20:40:02,733 |  * Median: MSE 99.259	L1 7.767	G-Mean 4.822	EDL 4.620	NIG_NLL 4.208	NIG_Reg 41.170
2023-05-20 20:40:02,733 |  * Low: MSE 153.640	L1 9.958	G-Mean 7.187	EDL 5.197	NIG_NLL 4.669	NIG_Reg 52.800
2023-05-20 20:40:02,734 | Best EDL Loss: 6.899
2023-05-20 20:40:02,737 | Epoch #80: Train loss [3.0186]; Val loss: MSE [83.1565], L1 [6.9807], G-Mean [4.4194], EDL [4.3859], NIG_NLL [4.016], NIG_Reg [37.005]
2023-05-20 20:40:02,738 | this_lr: 
2023-05-20 20:40:02,738 | 1e-05
2023-05-20 20:40:07,205 | Epoch: [81][  0/191]	Time   4.47 (  4.47)	Data 3.4830 (3.4830)	Loss (EDL) 2.852 (2.852)
2023-05-20 20:40:12,787 | Epoch: [81][ 10/191]	Time   0.56 (  0.91)	Data 0.0003 (0.3169)	Loss (EDL) 2.879 (3.027)
2023-05-20 20:40:18,389 | Epoch: [81][ 20/191]	Time   0.57 (  0.75)	Data 0.0001 (0.1661)	Loss (EDL) 2.775 (2.995)
2023-05-20 20:40:23,969 | Epoch: [81][ 30/191]	Time   0.56 (  0.68)	Data 0.0003 (0.1126)	Loss (EDL) 2.983 (2.962)
2023-05-20 20:40:29,665 | Epoch: [81][ 40/191]	Time   0.59 (  0.66)	Data 0.0002 (0.0852)	Loss (EDL) 3.131 (2.959)
2023-05-20 20:40:35,287 | Epoch: [81][ 50/191]	Time   0.58 (  0.64)	Data 0.0003 (0.0686)	Loss (EDL) 3.126 (2.981)
2023-05-20 20:40:41,186 | Epoch: [81][ 60/191]	Time   0.59 (  0.63)	Data 0.0001 (0.0574)	Loss (EDL) 2.990 (2.983)
2023-05-20 20:40:46,871 | Epoch: [81][ 70/191]	Time   0.58 (  0.62)	Data 0.0002 (0.0493)	Loss (EDL) 3.058 (2.974)
2023-05-20 20:40:52,525 | Epoch: [81][ 80/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0433)	Loss (EDL) 2.977 (2.975)
2023-05-20 20:40:58,103 | Epoch: [81][ 90/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0385)	Loss (EDL) 2.800 (2.975)
2023-05-20 20:41:03,746 | Epoch: [81][100/191]	Time   0.58 (  0.60)	Data 0.0003 (0.0348)	Loss (EDL) 3.495 (2.983)
2023-05-20 20:41:09,319 | Epoch: [81][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0316)	Loss (EDL) 2.824 (2.980)
2023-05-20 20:41:14,905 | Epoch: [81][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0291)	Loss (EDL) 3.054 (2.986)
2023-05-20 20:41:20,468 | Epoch: [81][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0269)	Loss (EDL) 2.901 (2.988)
2023-05-20 20:41:26,095 | Epoch: [81][140/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0250)	Loss (EDL) 2.795 (2.989)
2023-05-20 20:41:31,544 | Epoch: [81][150/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0233)	Loss (EDL) 3.027 (2.992)
2023-05-20 20:41:37,036 | Epoch: [81][160/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0219)	Loss (EDL) 2.779 (2.991)
2023-05-20 20:41:42,486 | Epoch: [81][170/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0206)	Loss (EDL) 3.243 (2.989)
2023-05-20 20:41:48,020 | Epoch: [81][180/191]	Time   0.58 (  0.58)	Data 0.0001 (0.0195)	Loss (EDL) 3.023 (2.991)
2023-05-20 20:41:53,383 | Epoch: [81][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0185)	Loss (EDL) 2.672 (2.992)
2023-05-20 20:41:53,705 | Create Epoch [81] features of all training data...
2023-05-20 20:42:23,163 | Updated smoothed statistics on Epoch [81]!
2023-05-20 20:42:23,234 | Updated running statistics with Epoch [81] features!
2023-05-20 20:42:26,763 | Val: [ 0/34]	Time  3.245 ( 3.245)	Loss (L1) 6.447 (6.447)	Loss (EDL) 4.303 (4.303)	Loss (NIG_NLL) 3.961 (3.961)	Loss (NIG_Reg) 34.181 (34.181)
2023-05-20 20:42:28,129 | Val: [10/34]	Time  0.100 ( 0.419)	Loss (L1) 7.377 (7.073)	Loss (EDL) 4.478 (4.424)	Loss (NIG_NLL) 4.087 (4.049)	Loss (NIG_Reg) 39.105 (37.496)
2023-05-20 20:42:29,139 | Val: [20/34]	Time  0.102 ( 0.268)	Loss (L1) 7.905 (6.985)	Loss (EDL) 4.742 (4.399)	Loss (NIG_NLL) 4.323 (4.029)	Loss (NIG_Reg) 41.902 (37.028)
2023-05-20 20:42:30,154 | Val: [30/34]	Time  0.101 ( 0.214)	Loss (L1) 8.246 (6.983)	Loss (EDL) 4.842 (4.403)	Loss (NIG_NLL) 4.405 (4.033)	Loss (NIG_Reg) 43.705 (37.015)
2023-05-20 20:42:30,778 |  * Overall: MSE 82.669	L1 6.951	G-Mean 4.345	EDL 4.391	NIG_NLL 4.023	NIG_Reg 36.845
2023-05-20 20:42:30,778 |  * Many: MSE 70.879	L1 6.420	G-Mean 3.986	EDL 4.240	NIG_NLL 3.900	NIG_Reg 34.034
2023-05-20 20:42:30,778 |  * Median: MSE 95.802	L1 7.626	G-Mean 4.860	EDL 4.594	NIG_NLL 4.190	NIG_Reg 40.424
2023-05-20 20:42:30,778 |  * Low: MSE 157.696	L1 10.091	G-Mean 7.211	EDL 5.258	NIG_NLL 4.723	NIG_Reg 53.506
2023-05-20 20:42:30,778 | Best EDL Loss: 6.899
2023-05-20 20:42:30,782 | Epoch #81: Train loss [2.9919]; Val loss: MSE [82.6690], L1 [6.9506], G-Mean [4.3453], EDL [4.3913], NIG_NLL [4.023], NIG_Reg [36.845]
2023-05-20 20:42:30,782 | this_lr: 
2023-05-20 20:42:30,782 | 1e-05
2023-05-20 20:42:35,225 | Epoch: [82][  0/191]	Time   4.44 (  4.44)	Data 3.5066 (3.5066)	Loss (EDL) 3.037 (3.037)
2023-05-20 20:42:40,785 | Epoch: [82][ 10/191]	Time   0.55 (  0.91)	Data 0.0002 (0.3190)	Loss (EDL) 2.995 (3.039)
2023-05-20 20:42:46,442 | Epoch: [82][ 20/191]	Time   0.61 (  0.75)	Data 0.0001 (0.1672)	Loss (EDL) 3.136 (3.012)
2023-05-20 20:42:52,218 | Epoch: [82][ 30/191]	Time   0.57 (  0.69)	Data 0.0001 (0.1133)	Loss (EDL) 2.844 (3.001)
2023-05-20 20:42:57,730 | Epoch: [82][ 40/191]	Time   0.56 (  0.66)	Data 0.0001 (0.0857)	Loss (EDL) 3.082 (2.997)
2023-05-20 20:43:03,344 | Epoch: [82][ 50/191]	Time   0.54 (  0.64)	Data 0.0007 (0.0690)	Loss (EDL) 2.764 (2.983)
2023-05-20 20:43:09,115 | Epoch: [82][ 60/191]	Time   0.57 (  0.63)	Data 0.0002 (0.0577)	Loss (EDL) 2.953 (2.971)
2023-05-20 20:43:14,860 | Epoch: [82][ 70/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0496)	Loss (EDL) 2.808 (2.975)
2023-05-20 20:43:20,594 | Epoch: [82][ 80/191]	Time   0.56 (  0.61)	Data 0.0003 (0.0435)	Loss (EDL) 2.889 (2.974)
2023-05-20 20:43:26,268 | Epoch: [82][ 90/191]	Time   0.56 (  0.61)	Data 0.0001 (0.0388)	Loss (EDL) 3.039 (2.984)
2023-05-20 20:43:32,163 | Epoch: [82][100/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0349)	Loss (EDL) 2.855 (2.988)
2023-05-20 20:43:37,810 | Epoch: [82][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0318)	Loss (EDL) 2.877 (2.982)
2023-05-20 20:43:43,380 | Epoch: [82][120/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0292)	Loss (EDL) 2.810 (2.978)
2023-05-20 20:43:48,939 | Epoch: [82][130/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0270)	Loss (EDL) 3.213 (2.979)
2023-05-20 20:43:54,469 | Epoch: [82][140/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0251)	Loss (EDL) 2.915 (2.980)
2023-05-20 20:43:59,912 | Epoch: [82][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0234)	Loss (EDL) 3.202 (2.983)
2023-05-20 20:44:05,561 | Epoch: [82][160/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0220)	Loss (EDL) 2.868 (2.980)
2023-05-20 20:44:11,094 | Epoch: [82][170/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0207)	Loss (EDL) 3.040 (2.978)
2023-05-20 20:44:16,842 | Epoch: [82][180/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0196)	Loss (EDL) 2.979 (2.979)
2023-05-20 20:44:22,231 | Epoch: [82][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0186)	Loss (EDL) 2.857 (2.977)
2023-05-20 20:44:22,577 | Create Epoch [82] features of all training data...
2023-05-20 20:44:51,964 | Updated smoothed statistics on Epoch [82]!
2023-05-20 20:44:52,038 | Updated running statistics with Epoch [82] features!
2023-05-20 20:44:55,783 | Val: [ 0/34]	Time  3.441 ( 3.441)	Loss (L1) 6.576 (6.576)	Loss (EDL) 4.368 (4.368)	Loss (NIG_NLL) 4.019 (4.019)	Loss (NIG_Reg) 34.861 (34.861)
2023-05-20 20:44:56,937 | Val: [10/34]	Time  0.100 ( 0.418)	Loss (L1) 7.415 (7.123)	Loss (EDL) 4.507 (4.460)	Loss (NIG_NLL) 4.114 (4.083)	Loss (NIG_Reg) 39.307 (37.760)
2023-05-20 20:44:57,956 | Val: [20/34]	Time  0.104 ( 0.267)	Loss (L1) 7.913 (7.029)	Loss (EDL) 4.763 (4.431)	Loss (NIG_NLL) 4.343 (4.058)	Loss (NIG_Reg) 41.945 (37.258)
2023-05-20 20:44:58,963 | Val: [30/34]	Time  0.101 ( 0.214)	Loss (L1) 8.246 (7.016)	Loss (EDL) 4.864 (4.432)	Loss (NIG_NLL) 4.427 (4.060)	Loss (NIG_Reg) 43.708 (37.194)
2023-05-20 20:44:59,615 |  * Overall: MSE 83.166	L1 6.983	G-Mean 4.427	EDL 4.418	NIG_NLL 4.048	NIG_Reg 37.014
2023-05-20 20:44:59,615 |  * Many: MSE 70.722	L1 6.421	G-Mean 4.063	EDL 4.254	NIG_NLL 3.914	NIG_Reg 34.038
2023-05-20 20:44:59,615 |  * Median: MSE 97.370	L1 7.721	G-Mean 4.935	EDL 4.649	NIG_NLL 4.240	NIG_Reg 40.924
2023-05-20 20:44:59,615 |  * Low: MSE 161.415	L1 10.244	G-Mean 7.360	EDL 5.329	NIG_NLL 4.786	NIG_Reg 54.314
2023-05-20 20:44:59,616 | Best EDL Loss: 6.899
2023-05-20 20:44:59,619 | Epoch #82: Train loss [2.9770]; Val loss: MSE [83.1659], L1 [6.9826], G-Mean [4.4266], EDL [4.4182], NIG_NLL [4.048], NIG_Reg [37.014]
2023-05-20 20:44:59,620 | this_lr: 
2023-05-20 20:44:59,620 | 1e-05
2023-05-20 20:45:03,994 | Epoch: [83][  0/191]	Time   4.37 (  4.37)	Data 3.3793 (3.3793)	Loss (EDL) 2.963 (2.963)
2023-05-20 20:45:09,716 | Epoch: [83][ 10/191]	Time   0.58 (  0.92)	Data 0.0002 (0.3075)	Loss (EDL) 3.024 (2.947)
2023-05-20 20:45:15,346 | Epoch: [83][ 20/191]	Time   0.55 (  0.75)	Data 0.0001 (0.1612)	Loss (EDL) 3.146 (2.994)
2023-05-20 20:45:20,882 | Epoch: [83][ 30/191]	Time   0.55 (  0.69)	Data 0.0002 (0.1093)	Loss (EDL) 2.941 (2.965)
2023-05-20 20:45:26,464 | Epoch: [83][ 40/191]	Time   0.56 (  0.65)	Data 0.0001 (0.0827)	Loss (EDL) 2.974 (2.956)
2023-05-20 20:45:32,042 | Epoch: [83][ 50/191]	Time   0.56 (  0.64)	Data 0.0003 (0.0665)	Loss (EDL) 2.891 (2.956)
2023-05-20 20:45:37,729 | Epoch: [83][ 60/191]	Time   0.58 (  0.62)	Data 0.0001 (0.0557)	Loss (EDL) 3.046 (2.961)
2023-05-20 20:45:43,394 | Epoch: [83][ 70/191]	Time   0.55 (  0.62)	Data 0.0003 (0.0479)	Loss (EDL) 2.937 (2.961)
2023-05-20 20:45:48,932 | Epoch: [83][ 80/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0420)	Loss (EDL) 3.062 (2.961)
2023-05-20 20:45:54,757 | Epoch: [83][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0374)	Loss (EDL) 2.955 (2.963)
2023-05-20 20:46:00,459 | Epoch: [83][100/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0337)	Loss (EDL) 2.927 (2.972)
2023-05-20 20:46:06,200 | Epoch: [83][110/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0307)	Loss (EDL) 2.967 (2.976)
2023-05-20 20:46:11,815 | Epoch: [83][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0282)	Loss (EDL) 2.901 (2.974)
2023-05-20 20:46:17,482 | Epoch: [83][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0261)	Loss (EDL) 2.884 (2.976)
2023-05-20 20:46:22,994 | Epoch: [83][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0242)	Loss (EDL) 3.268 (2.980)
2023-05-20 20:46:28,512 | Epoch: [83][150/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0226)	Loss (EDL) 2.990 (2.974)
2023-05-20 20:46:34,318 | Epoch: [83][160/191]	Time   0.88 (  0.59)	Data 0.0002 (0.0212)	Loss (EDL) 2.906 (2.976)
2023-05-20 20:46:39,830 | Epoch: [83][170/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0200)	Loss (EDL) 3.255 (2.978)
2023-05-20 20:46:45,315 | Epoch: [83][180/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0189)	Loss (EDL) 2.897 (2.982)
2023-05-20 20:46:50,694 | Epoch: [83][190/191]	Time   0.47 (  0.58)	Data 0.0001 (0.0179)	Loss (EDL) 2.773 (2.978)
2023-05-20 20:46:51,037 | Create Epoch [83] features of all training data...
2023-05-20 20:47:20,621 | Updated smoothed statistics on Epoch [83]!
2023-05-20 20:47:20,687 | Updated running statistics with Epoch [83] features!
2023-05-20 20:47:24,307 | Val: [ 0/34]	Time  3.325 ( 3.325)	Loss (L1) 6.552 (6.552)	Loss (EDL) 4.359 (4.359)	Loss (NIG_NLL) 4.012 (4.012)	Loss (NIG_Reg) 34.736 (34.736)
2023-05-20 20:47:25,710 | Val: [10/34]	Time  0.100 ( 0.430)	Loss (L1) 7.405 (7.157)	Loss (EDL) 4.516 (4.485)	Loss (NIG_NLL) 4.124 (4.106)	Loss (NIG_Reg) 39.250 (37.940)
2023-05-20 20:47:26,717 | Val: [20/34]	Time  0.100 ( 0.273)	Loss (L1) 8.015 (7.085)	Loss (EDL) 4.813 (4.466)	Loss (NIG_NLL) 4.389 (4.090)	Loss (NIG_Reg) 42.486 (37.557)
2023-05-20 20:47:27,723 | Val: [30/34]	Time  0.101 ( 0.217)	Loss (L1) 8.361 (7.077)	Loss (EDL) 4.926 (4.470)	Loss (NIG_NLL) 4.483 (4.094)	Loss (NIG_Reg) 44.316 (37.517)
2023-05-20 20:47:28,374 |  * Overall: MSE 84.144	L1 7.044	G-Mean 4.514	EDL 4.456	NIG_NLL 4.082	NIG_Reg 37.339
2023-05-20 20:47:28,374 |  * Many: MSE 70.062	L1 6.406	G-Mean 4.097	EDL 4.268	NIG_NLL 3.928	NIG_Reg 33.961
2023-05-20 20:47:28,374 |  * Median: MSE 103.366	L1 7.993	G-Mean 5.222	EDL 4.752	NIG_NLL 4.328	NIG_Reg 42.366
2023-05-20 20:47:28,374 |  * Low: MSE 163.979	L1 10.438	G-Mean 7.546	EDL 5.413	NIG_NLL 4.859	NIG_Reg 55.342
2023-05-20 20:47:28,374 | Best EDL Loss: 6.899
2023-05-20 20:47:28,378 | Epoch #83: Train loss [2.9784]; Val loss: MSE [84.1439], L1 [7.0437], G-Mean [4.5142], EDL [4.4556], NIG_NLL [4.082], NIG_Reg [37.339]
2023-05-20 20:47:28,378 | this_lr: 
2023-05-20 20:47:28,378 | 1e-05
2023-05-20 20:47:32,793 | Epoch: [84][  0/191]	Time   4.41 (  4.41)	Data 3.4350 (3.4350)	Loss (EDL) 2.807 (2.807)
2023-05-20 20:47:38,491 | Epoch: [84][ 10/191]	Time   0.56 (  0.92)	Data 0.0002 (0.3130)	Loss (EDL) 3.071 (3.028)
2023-05-20 20:47:44,121 | Epoch: [84][ 20/191]	Time   0.59 (  0.75)	Data 0.0002 (0.1641)	Loss (EDL) 2.827 (2.982)
2023-05-20 20:47:49,627 | Epoch: [84][ 30/191]	Time   0.55 (  0.69)	Data 0.0001 (0.1112)	Loss (EDL) 2.855 (2.970)
2023-05-20 20:47:55,205 | Epoch: [84][ 40/191]	Time   0.55 (  0.65)	Data 0.0001 (0.0842)	Loss (EDL) 2.970 (2.966)
2023-05-20 20:48:00,957 | Epoch: [84][ 50/191]	Time   0.62 (  0.64)	Data 0.0002 (0.0677)	Loss (EDL) 3.087 (2.970)
2023-05-20 20:48:06,627 | Epoch: [84][ 60/191]	Time   0.56 (  0.63)	Data 0.0002 (0.0566)	Loss (EDL) 2.861 (2.967)
2023-05-20 20:48:12,643 | Epoch: [84][ 70/191]	Time   0.54 (  0.62)	Data 0.0002 (0.0487)	Loss (EDL) 2.704 (2.967)
2023-05-20 20:48:18,331 | Epoch: [84][ 80/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0427)	Loss (EDL) 3.265 (2.973)
2023-05-20 20:48:23,933 | Epoch: [84][ 90/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0380)	Loss (EDL) 2.971 (2.977)
2023-05-20 20:48:29,660 | Epoch: [84][100/191]	Time   0.61 (  0.61)	Data 0.0002 (0.0343)	Loss (EDL) 2.821 (2.986)
2023-05-20 20:48:35,203 | Epoch: [84][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0312)	Loss (EDL) 2.977 (2.983)
2023-05-20 20:48:40,805 | Epoch: [84][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0287)	Loss (EDL) 2.872 (2.982)
2023-05-20 20:48:46,491 | Epoch: [84][130/191]	Time   0.55 (  0.60)	Data 0.0003 (0.0265)	Loss (EDL) 3.441 (2.987)
2023-05-20 20:48:52,226 | Epoch: [84][140/191]	Time   0.56 (  0.59)	Data 0.0001 (0.0247)	Loss (EDL) 3.143 (2.982)
2023-05-20 20:48:57,678 | Epoch: [84][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0230)	Loss (EDL) 2.917 (2.980)
2023-05-20 20:49:03,116 | Epoch: [84][160/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0216)	Loss (EDL) 2.716 (2.976)
2023-05-20 20:49:08,538 | Epoch: [84][170/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0204)	Loss (EDL) 2.958 (2.974)
2023-05-20 20:49:13,950 | Epoch: [84][180/191]	Time   0.56 (  0.58)	Data 0.0001 (0.0192)	Loss (EDL) 2.919 (2.974)
2023-05-20 20:49:19,271 | Epoch: [84][190/191]	Time   0.45 (  0.58)	Data 0.0001 (0.0182)	Loss (EDL) 2.620 (2.982)
2023-05-20 20:49:19,615 | Create Epoch [84] features of all training data...
2023-05-20 20:49:49,120 | Updated smoothed statistics on Epoch [84]!
2023-05-20 20:49:49,190 | Updated running statistics with Epoch [84] features!
2023-05-20 20:49:52,931 | Val: [ 0/34]	Time  3.458 ( 3.458)	Loss (L1) 6.551 (6.551)	Loss (EDL) 4.353 (4.353)	Loss (NIG_NLL) 4.006 (4.006)	Loss (NIG_Reg) 34.733 (34.733)
2023-05-20 20:49:54,217 | Val: [10/34]	Time  0.100 ( 0.431)	Loss (L1) 7.411 (7.116)	Loss (EDL) 4.498 (4.450)	Loss (NIG_NLL) 4.105 (4.072)	Loss (NIG_Reg) 39.283 (37.722)
2023-05-20 20:49:55,227 | Val: [20/34]	Time  0.101 ( 0.274)	Loss (L1) 7.942 (7.007)	Loss (EDL) 4.771 (4.419)	Loss (NIG_NLL) 4.350 (4.048)	Loss (NIG_Reg) 42.100 (37.145)
2023-05-20 20:49:56,238 | Val: [30/34]	Time  0.101 ( 0.218)	Loss (L1) 8.255 (7.011)	Loss (EDL) 4.867 (4.425)	Loss (NIG_NLL) 4.430 (4.053)	Loss (NIG_Reg) 43.754 (37.162)
2023-05-20 20:49:56,916 |  * Overall: MSE 83.088	L1 6.974	G-Mean 4.393	EDL 4.411	NIG_NLL 4.041	NIG_Reg 36.970
2023-05-20 20:49:56,916 |  * Many: MSE 71.011	L1 6.425	G-Mean 4.047	EDL 4.251	NIG_NLL 3.911	NIG_Reg 34.060
2023-05-20 20:49:56,916 |  * Median: MSE 96.332	L1 7.678	G-Mean 4.913	EDL 4.627	NIG_NLL 4.220	NIG_Reg 40.699
2023-05-20 20:49:56,916 |  * Low: MSE 160.525	L1 10.212	G-Mean 7.012	EDL 5.318	NIG_NLL 4.776	NIG_Reg 54.143
2023-05-20 20:49:56,916 | Best EDL Loss: 6.899
2023-05-20 20:49:56,920 | Epoch #84: Train loss [2.9824]; Val loss: MSE [83.0884], L1 [6.9743], G-Mean [4.3934], EDL [4.4107], NIG_NLL [4.041], NIG_Reg [36.970]
2023-05-20 20:49:56,920 | this_lr: 
2023-05-20 20:49:56,920 | 1e-05
2023-05-20 20:50:01,342 | Epoch: [85][  0/191]	Time   4.42 (  4.42)	Data 3.4393 (3.4393)	Loss (EDL) 2.971 (2.971)
2023-05-20 20:50:07,126 | Epoch: [85][ 10/191]	Time   0.56 (  0.93)	Data 0.0003 (0.3130)	Loss (EDL) 3.053 (2.952)
2023-05-20 20:50:12,686 | Epoch: [85][ 20/191]	Time   0.56 (  0.75)	Data 0.0002 (0.1640)	Loss (EDL) 3.090 (2.971)
2023-05-20 20:50:18,255 | Epoch: [85][ 30/191]	Time   0.56 (  0.69)	Data 0.0004 (0.1112)	Loss (EDL) 3.121 (2.936)
2023-05-20 20:50:24,111 | Epoch: [85][ 40/191]	Time   0.57 (  0.66)	Data 0.0001 (0.0841)	Loss (EDL) 3.047 (2.946)
2023-05-20 20:50:29,808 | Epoch: [85][ 50/191]	Time   0.56 (  0.64)	Data 0.0002 (0.0677)	Loss (EDL) 3.002 (2.932)
2023-05-20 20:50:35,424 | Epoch: [85][ 60/191]	Time   0.55 (  0.63)	Data 0.0001 (0.0566)	Loss (EDL) 2.857 (2.929)
2023-05-20 20:50:41,014 | Epoch: [85][ 70/191]	Time   0.56 (  0.62)	Data 0.0002 (0.0487)	Loss (EDL) 2.942 (2.928)
2023-05-20 20:50:46,640 | Epoch: [85][ 80/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0427)	Loss (EDL) 3.086 (2.932)
2023-05-20 20:50:52,211 | Epoch: [85][ 90/191]	Time   0.54 (  0.61)	Data 0.0002 (0.0380)	Loss (EDL) 3.342 (2.946)
2023-05-20 20:50:57,871 | Epoch: [85][100/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0343)	Loss (EDL) 3.495 (2.950)
2023-05-20 20:51:03,782 | Epoch: [85][110/191]	Time   0.57 (  0.60)	Data 0.0002 (0.0312)	Loss (EDL) 2.747 (2.951)
2023-05-20 20:51:09,446 | Epoch: [85][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0286)	Loss (EDL) 2.624 (2.946)
2023-05-20 20:51:15,006 | Epoch: [85][130/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0265)	Loss (EDL) 2.875 (2.955)
2023-05-20 20:51:20,485 | Epoch: [85][140/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0246)	Loss (EDL) 3.094 (2.953)
2023-05-20 20:51:25,985 | Epoch: [85][150/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0230)	Loss (EDL) 2.894 (2.957)
2023-05-20 20:51:31,495 | Epoch: [85][160/191]	Time   0.52 (  0.59)	Data 0.0001 (0.0216)	Loss (EDL) 3.113 (2.957)
2023-05-20 20:51:36,939 | Epoch: [85][170/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0203)	Loss (EDL) 2.794 (2.958)
2023-05-20 20:51:42,423 | Epoch: [85][180/191]	Time   0.59 (  0.58)	Data 0.0001 (0.0192)	Loss (EDL) 2.947 (2.955)
2023-05-20 20:51:48,151 | Epoch: [85][190/191]	Time   0.46 (  0.58)	Data 0.0002 (0.0182)	Loss (EDL) 2.838 (2.955)
2023-05-20 20:51:48,511 | Create Epoch [85] features of all training data...
2023-05-20 20:52:17,672 | Updated smoothed statistics on Epoch [85]!
2023-05-20 20:52:17,738 | Updated running statistics with Epoch [85] features!
2023-05-20 20:52:21,234 | Val: [ 0/34]	Time  3.242 ( 3.242)	Loss (L1) 6.585 (6.585)	Loss (EDL) 4.380 (4.380)	Loss (NIG_NLL) 4.031 (4.031)	Loss (NIG_Reg) 34.908 (34.908)
2023-05-20 20:52:22,445 | Val: [10/34]	Time  0.101 ( 0.405)	Loss (L1) 7.348 (7.120)	Loss (EDL) 4.505 (4.474)	Loss (NIG_NLL) 4.116 (4.097)	Loss (NIG_Reg) 38.951 (37.745)
2023-05-20 20:52:23,451 | Val: [20/34]	Time  0.101 ( 0.260)	Loss (L1) 7.882 (7.029)	Loss (EDL) 4.776 (4.448)	Loss (NIG_NLL) 4.358 (4.076)	Loss (NIG_Reg) 41.781 (37.261)
2023-05-20 20:52:24,458 | Val: [30/34]	Time  0.101 ( 0.209)	Loss (L1) 8.298 (7.024)	Loss (EDL) 4.912 (4.452)	Loss (NIG_NLL) 4.472 (4.080)	Loss (NIG_Reg) 43.985 (37.235)
2023-05-20 20:52:25,119 |  * Overall: MSE 83.318	L1 6.987	G-Mean 4.402	EDL 4.438	NIG_NLL 4.067	NIG_Reg 37.035
2023-05-20 20:52:25,119 |  * Many: MSE 70.028	L1 6.376	G-Mean 3.989	EDL 4.253	NIG_NLL 3.915	NIG_Reg 33.797
2023-05-20 20:52:25,119 |  * Median: MSE 99.671	L1 7.843	G-Mean 5.066	EDL 4.717	NIG_NLL 4.301	NIG_Reg 41.575
2023-05-20 20:52:25,119 |  * Low: MSE 163.618	L1 10.386	G-Mean 7.564	EDL 5.406	NIG_NLL 4.855	NIG_Reg 55.067
2023-05-20 20:52:25,120 | Best EDL Loss: 6.899
2023-05-20 20:52:25,123 | Epoch #85: Train loss [2.9554]; Val loss: MSE [83.3182], L1 [6.9865], G-Mean [4.4016], EDL [4.4377], NIG_NLL [4.067], NIG_Reg [37.035]
2023-05-20 20:52:25,123 | this_lr: 
2023-05-20 20:52:25,123 | 1e-05
2023-05-20 20:52:29,621 | Epoch: [86][  0/191]	Time   4.50 (  4.50)	Data 3.4576 (3.4576)	Loss (EDL) 2.839 (2.839)
2023-05-20 20:52:35,187 | Epoch: [86][ 10/191]	Time   0.55 (  0.91)	Data 0.0001 (0.3146)	Loss (EDL) 2.802 (2.904)
2023-05-20 20:52:40,760 | Epoch: [86][ 20/191]	Time   0.55 (  0.74)	Data 0.0001 (0.1649)	Loss (EDL) 2.676 (2.885)
2023-05-20 20:52:46,310 | Epoch: [86][ 30/191]	Time   0.56 (  0.68)	Data 0.0001 (0.1117)	Loss (EDL) 3.065 (2.938)
2023-05-20 20:52:51,964 | Epoch: [86][ 40/191]	Time   0.56 (  0.65)	Data 0.0001 (0.0845)	Loss (EDL) 2.818 (2.953)
2023-05-20 20:52:57,664 | Epoch: [86][ 50/191]	Time   0.57 (  0.64)	Data 0.0001 (0.0680)	Loss (EDL) 3.008 (2.963)
2023-05-20 20:53:03,227 | Epoch: [86][ 60/191]	Time   0.56 (  0.62)	Data 0.0001 (0.0569)	Loss (EDL) 2.868 (2.960)
2023-05-20 20:53:08,766 | Epoch: [86][ 70/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0489)	Loss (EDL) 2.986 (2.971)
2023-05-20 20:53:14,366 | Epoch: [86][ 80/191]	Time   0.57 (  0.61)	Data 0.0002 (0.0429)	Loss (EDL) 2.932 (2.965)
2023-05-20 20:53:19,967 | Epoch: [86][ 90/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0382)	Loss (EDL) 2.744 (2.958)
2023-05-20 20:53:25,791 | Epoch: [86][100/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0345)	Loss (EDL) 3.163 (2.960)
2023-05-20 20:53:31,425 | Epoch: [86][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0314)	Loss (EDL) 2.983 (2.963)
2023-05-20 20:53:36,995 | Epoch: [86][120/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0288)	Loss (EDL) 3.234 (2.961)
2023-05-20 20:53:42,641 | Epoch: [86][130/191]	Time   0.54 (  0.59)	Data 0.0001 (0.0266)	Loss (EDL) 2.638 (2.960)
2023-05-20 20:53:48,114 | Epoch: [86][140/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0247)	Loss (EDL) 2.889 (2.961)
2023-05-20 20:53:53,553 | Epoch: [86][150/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0231)	Loss (EDL) 2.823 (2.957)
2023-05-20 20:53:58,986 | Epoch: [86][160/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0217)	Loss (EDL) 2.891 (2.955)
2023-05-20 20:54:04,466 | Epoch: [86][170/191]	Time   0.55 (  0.58)	Data 0.0001 (0.0204)	Loss (EDL) 2.729 (2.952)
2023-05-20 20:54:10,192 | Epoch: [86][180/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0193)	Loss (EDL) 2.914 (2.950)
2023-05-20 20:54:15,550 | Epoch: [86][190/191]	Time   0.44 (  0.58)	Data 0.0001 (0.0183)	Loss (EDL) 2.782 (2.948)
2023-05-20 20:54:15,891 | Create Epoch [86] features of all training data...
2023-05-20 20:54:45,355 | Updated smoothed statistics on Epoch [86]!
2023-05-20 20:54:45,421 | Updated running statistics with Epoch [86] features!
2023-05-20 20:54:49,027 | Val: [ 0/34]	Time  3.347 ( 3.347)	Loss (L1) 6.562 (6.562)	Loss (EDL) 4.387 (4.387)	Loss (NIG_NLL) 4.039 (4.039)	Loss (NIG_Reg) 34.787 (34.787)
2023-05-20 20:54:50,201 | Val: [10/34]	Time  0.101 ( 0.411)	Loss (L1) 7.374 (7.117)	Loss (EDL) 4.515 (4.480)	Loss (NIG_NLL) 4.125 (4.103)	Loss (NIG_Reg) 39.087 (37.728)
2023-05-20 20:54:51,205 | Val: [20/34]	Time  0.100 ( 0.263)	Loss (L1) 7.964 (7.016)	Loss (EDL) 4.815 (4.451)	Loss (NIG_NLL) 4.393 (4.079)	Loss (NIG_Reg) 42.212 (37.192)
2023-05-20 20:54:52,208 | Val: [30/34]	Time  0.101 ( 0.211)	Loss (L1) 8.250 (7.009)	Loss (EDL) 4.905 (4.454)	Loss (NIG_NLL) 4.468 (4.082)	Loss (NIG_Reg) 43.730 (37.154)
2023-05-20 20:54:52,860 |  * Overall: MSE 83.179	L1 6.974	G-Mean 4.404	EDL 4.440	NIG_NLL 4.070	NIG_Reg 36.967
2023-05-20 20:54:52,860 |  * Many: MSE 70.635	L1 6.403	G-Mean 4.031	EDL 4.269	NIG_NLL 3.930	NIG_Reg 33.942
2023-05-20 20:54:52,860 |  * Median: MSE 97.266	L1 7.715	G-Mean 4.953	EDL 4.678	NIG_NLL 4.269	NIG_Reg 40.895
2023-05-20 20:54:52,860 |  * Low: MSE 162.691	L1 10.312	G-Mean 7.354	EDL 5.393	NIG_NLL 4.846	NIG_Reg 54.674
2023-05-20 20:54:52,861 | Best EDL Loss: 6.899
2023-05-20 20:54:52,865 | Epoch #86: Train loss [2.9476]; Val loss: MSE [83.1787], L1 [6.9737], G-Mean [4.4042], EDL [4.4401], NIG_NLL [4.070], NIG_Reg [36.967]
2023-05-20 20:54:52,865 | this_lr: 
2023-05-20 20:54:52,865 | 1e-05
2023-05-20 20:54:57,379 | Epoch: [87][  0/191]	Time   4.51 (  4.51)	Data 3.5244 (3.5244)	Loss (EDL) 2.729 (2.729)
2023-05-20 20:55:03,094 | Epoch: [87][ 10/191]	Time   0.57 (  0.93)	Data 0.0005 (0.3207)	Loss (EDL) 3.320 (3.069)
2023-05-20 20:55:08,668 | Epoch: [87][ 20/191]	Time   0.54 (  0.75)	Data 0.0002 (0.1681)	Loss (EDL) 2.984 (3.018)
2023-05-20 20:55:14,299 | Epoch: [87][ 30/191]	Time   0.56 (  0.69)	Data 0.0001 (0.1139)	Loss (EDL) 2.828 (2.979)
2023-05-20 20:55:19,875 | Epoch: [87][ 40/191]	Time   0.56 (  0.66)	Data 0.0002 (0.0862)	Loss (EDL) 2.767 (2.947)
2023-05-20 20:55:25,499 | Epoch: [87][ 50/191]	Time   0.56 (  0.64)	Data 0.0001 (0.0693)	Loss (EDL) 2.890 (2.957)
2023-05-20 20:55:31,086 | Epoch: [87][ 60/191]	Time   0.56 (  0.63)	Data 0.0003 (0.0580)	Loss (EDL) 3.071 (2.958)
2023-05-20 20:55:36,729 | Epoch: [87][ 70/191]	Time   0.56 (  0.62)	Data 0.0003 (0.0499)	Loss (EDL) 2.946 (2.973)
2023-05-20 20:55:42,371 | Epoch: [87][ 80/191]	Time   0.59 (  0.61)	Data 0.0002 (0.0438)	Loss (EDL) 2.968 (2.970)
2023-05-20 20:55:48,288 | Epoch: [87][ 90/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0390)	Loss (EDL) 3.177 (2.973)
2023-05-20 20:55:53,900 | Epoch: [87][100/191]	Time   0.54 (  0.60)	Data 0.0002 (0.0352)	Loss (EDL) 2.820 (2.975)
2023-05-20 20:55:59,564 | Epoch: [87][110/191]	Time   0.56 (  0.60)	Data 0.0003 (0.0320)	Loss (EDL) 2.938 (2.966)
2023-05-20 20:56:05,316 | Epoch: [87][120/191]	Time   0.58 (  0.60)	Data 0.0002 (0.0294)	Loss (EDL) 2.905 (2.965)
2023-05-20 20:56:10,928 | Epoch: [87][130/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0272)	Loss (EDL) 3.178 (2.966)
2023-05-20 20:56:16,531 | Epoch: [87][140/191]	Time   0.55 (  0.59)	Data 0.0003 (0.0253)	Loss (EDL) 3.199 (2.969)
2023-05-20 20:56:22,001 | Epoch: [87][150/191]	Time   0.55 (  0.59)	Data 0.0003 (0.0236)	Loss (EDL) 2.952 (2.967)
2023-05-20 20:56:27,466 | Epoch: [87][160/191]	Time   0.55 (  0.59)	Data 0.0002 (0.0222)	Loss (EDL) 2.803 (2.971)
2023-05-20 20:56:33,279 | Epoch: [87][170/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0209)	Loss (EDL) 2.665 (2.968)
2023-05-20 20:56:38,775 | Epoch: [87][180/191]	Time   0.56 (  0.59)	Data 0.0002 (0.0198)	Loss (EDL) 2.910 (2.965)
2023-05-20 20:56:44,170 | Epoch: [87][190/191]	Time   0.47 (  0.58)	Data 0.0002 (0.0187)	Loss (EDL) 2.821 (2.965)
2023-05-20 20:56:44,539 | Create Epoch [87] features of all training data...
2023-05-20 20:57:13,842 | Updated smoothed statistics on Epoch [87]!
2023-05-20 20:57:13,908 | Updated running statistics with Epoch [87] features!
2023-05-20 20:57:17,587 | Val: [ 0/34]	Time  3.370 ( 3.370)	Loss (L1) 6.505 (6.505)	Loss (EDL) 4.362 (4.362)	Loss (NIG_NLL) 4.017 (4.017)	Loss (NIG_Reg) 34.487 (34.487)
2023-05-20 20:57:18,860 | Val: [10/34]	Time  0.100 ( 0.422)	Loss (L1) 7.391 (7.123)	Loss (EDL) 4.515 (4.473)	Loss (NIG_NLL) 4.123 (4.095)	Loss (NIG_Reg) 39.176 (37.759)
2023-05-20 20:57:19,863 | Val: [20/34]	Time  0.100 ( 0.269)	Loss (L1) 8.019 (7.015)	Loss (EDL) 4.823 (4.442)	Loss (NIG_NLL) 4.398 (4.071)	Loss (NIG_Reg) 42.505 (37.189)
2023-05-20 20:57:20,868 | Val: [30/34]	Time  0.102 ( 0.215)	Loss (L1) 8.163 (7.011)	Loss (EDL) 4.860 (4.445)	Loss (NIG_NLL) 4.428 (4.073)	Loss (NIG_Reg) 43.268 (37.163)
2023-05-20 20:57:21,510 |  * Overall: MSE 83.352	L1 6.973	G-Mean 4.385	EDL 4.431	NIG_NLL 4.061	NIG_Reg 36.963
2023-05-20 20:57:21,510 |  * Many: MSE 71.887	L1 6.460	G-Mean 4.044	EDL 4.283	NIG_NLL 3.941	NIG_Reg 34.241
2023-05-20 20:57:21,510 |  * Median: MSE 95.040	L1 7.602	G-Mean 4.878	EDL 4.618	NIG_NLL 4.215	NIG_Reg 40.296
2023-05-20 20:57:21,510 |  * Low: MSE 159.314	L1 10.082	G-Mean 7.016	EDL 5.306	NIG_NLL 4.772	NIG_Reg 53.458
2023-05-20 20:57:21,511 | Best EDL Loss: 6.899
2023-05-20 20:57:21,515 | Epoch #87: Train loss [2.9649]; Val loss: MSE [83.3522], L1 [6.9730], G-Mean [4.3852], EDL [4.4307], NIG_NLL [4.061], NIG_Reg [36.963]
2023-05-20 20:57:21,515 | this_lr: 
2023-05-20 20:57:21,515 | 1e-05
2023-05-20 20:57:26,136 | Epoch: [88][  0/191]	Time   4.62 (  4.62)	Data 3.7194 (3.7194)	Loss (EDL) 2.957 (2.957)
2023-05-20 20:57:31,875 | Epoch: [88][ 10/191]	Time   0.57 (  0.94)	Data 0.0001 (0.3383)	Loss (EDL) 3.002 (2.943)
2023-05-20 20:57:37,612 | Epoch: [88][ 20/191]	Time   0.59 (  0.77)	Data 0.0002 (0.1773)	Loss (EDL) 3.163 (2.969)
2023-05-20 20:57:43,211 | Epoch: [88][ 30/191]	Time   0.56 (  0.70)	Data 0.0001 (0.1202)	Loss (EDL) 2.927 (2.948)
2023-05-20 20:57:48,770 | Epoch: [88][ 40/191]	Time   0.55 (  0.66)	Data 0.0001 (0.0910)	Loss (EDL) 3.023 (2.949)
2023-05-20 20:57:54,568 | Epoch: [88][ 50/191]	Time   0.55 (  0.65)	Data 0.0001 (0.0732)	Loss (EDL) 3.016 (2.959)
2023-05-20 20:58:00,282 | Epoch: [88][ 60/191]	Time   0.59 (  0.64)	Data 0.0001 (0.0612)	Loss (EDL) 2.942 (2.949)
2023-05-20 20:58:06,235 | Epoch: [88][ 70/191]	Time   0.57 (  0.63)	Data 0.0001 (0.0526)	Loss (EDL) 2.971 (2.939)
2023-05-20 20:58:11,848 | Epoch: [88][ 80/191]	Time   0.58 (  0.62)	Data 0.0003 (0.0462)	Loss (EDL) 2.935 (2.948)
2023-05-20 20:58:17,457 | Epoch: [88][ 90/191]	Time   0.54 (  0.61)	Data 0.0001 (0.0411)	Loss (EDL) 2.753 (2.944)
2023-05-20 20:58:23,163 | Epoch: [88][100/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0371)	Loss (EDL) 3.042 (2.945)
2023-05-20 20:58:28,798 | Epoch: [88][110/191]	Time   0.56 (  0.61)	Data 0.0002 (0.0337)	Loss (EDL) 3.019 (2.955)
2023-05-20 20:58:34,414 | Epoch: [88][120/191]	Time   0.56 (  0.60)	Data 0.0001 (0.0310)	Loss (EDL) 3.032 (2.954)
2023-05-20 20:58:40,008 | Epoch: [88][130/191]	Time   0.54 (  0.60)	Data 0.0001 (0.0286)	Loss (EDL) 2.984 (2.951)
2023-05-20 20:58:45,521 | Epoch: [88][140/191]	Time   0.55 (  0.60)	Data 0.0001 (0.0266)	Loss (EDL) 3.032 (2.951)
2023-05-20 20:58:51,270 | Epoch: [88][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0249)	Loss (EDL) 2.823 (2.950)
2023-05-20 20:58:56,728 | Epoch: [88][160/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0233)	Loss (EDL) 3.246 (2.948)
2023-05-20 20:59:02,232 | Epoch: [88][170/191]	Time   0.53 (  0.59)	Data 0.0001 (0.0220)	Loss (EDL) 3.022 (2.946)
2023-05-20 20:59:07,682 | Epoch: [88][180/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0208)	Loss (EDL) 2.935 (2.946)
2023-05-20 20:59:13,134 | Epoch: [88][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0197)	Loss (EDL) 3.014 (2.952)
2023-05-20 20:59:13,478 | Create Epoch [88] features of all training data...
2023-05-20 20:59:42,810 | Updated smoothed statistics on Epoch [88]!
2023-05-20 20:59:42,888 | Updated running statistics with Epoch [88] features!
2023-05-20 20:59:46,641 | Val: [ 0/34]	Time  3.436 ( 3.436)	Loss (L1) 6.589 (6.589)	Loss (EDL) 4.400 (4.400)	Loss (NIG_NLL) 4.051 (4.051)	Loss (NIG_Reg) 34.935 (34.935)
2023-05-20 20:59:47,969 | Val: [10/34]	Time  0.101 ( 0.433)	Loss (L1) 7.398 (7.130)	Loss (EDL) 4.528 (4.490)	Loss (NIG_NLL) 4.136 (4.112)	Loss (NIG_Reg) 39.215 (37.796)
2023-05-20 20:59:48,979 | Val: [20/34]	Time  0.101 ( 0.275)	Loss (L1) 7.957 (7.035)	Loss (EDL) 4.815 (4.463)	Loss (NIG_NLL) 4.393 (4.090)	Loss (NIG_Reg) 42.175 (37.291)
2023-05-20 20:59:49,984 | Val: [30/34]	Time  0.100 ( 0.219)	Loss (L1) 8.276 (7.030)	Loss (EDL) 4.912 (4.467)	Loss (NIG_NLL) 4.474 (4.094)	Loss (NIG_Reg) 43.869 (37.264)
2023-05-20 20:59:50,608 |  * Overall: MSE 83.651	L1 6.993	G-Mean 4.404	EDL 4.452	NIG_NLL 4.082	NIG_Reg 37.071
2023-05-20 20:59:50,608 |  * Many: MSE 70.579	L1 6.403	G-Mean 4.032	EDL 4.277	NIG_NLL 3.937	NIG_Reg 33.943
2023-05-20 20:59:50,608 |  * Median: MSE 99.545	L1 7.815	G-Mean 4.949	EDL 4.714	NIG_NLL 4.299	NIG_Reg 41.425
2023-05-20 20:59:50,608 |  * Low: MSE 163.159	L1 10.292	G-Mean 7.341	EDL 5.388	NIG_NLL 4.842	NIG_Reg 54.569
2023-05-20 20:59:50,609 | Best EDL Loss: 6.899
2023-05-20 20:59:50,612 | Epoch #88: Train loss [2.9519]; Val loss: MSE [83.6514], L1 [6.9932], G-Mean [4.4041], EDL [4.4522], NIG_NLL [4.082], NIG_Reg [37.071]
2023-05-20 20:59:50,612 | this_lr: 
2023-05-20 20:59:50,612 | 1e-05
2023-05-20 20:59:55,126 | Epoch: [89][  0/191]	Time   4.51 (  4.51)	Data 3.5448 (3.5448)	Loss (EDL) 2.877 (2.877)
2023-05-20 21:00:00,761 | Epoch: [89][ 10/191]	Time   0.58 (  0.92)	Data 0.0002 (0.3225)	Loss (EDL) 3.214 (3.009)
2023-05-20 21:00:06,390 | Epoch: [89][ 20/191]	Time   0.56 (  0.75)	Data 0.0001 (0.1690)	Loss (EDL) 2.841 (2.974)
2023-05-20 21:00:11,941 | Epoch: [89][ 30/191]	Time   0.58 (  0.69)	Data 0.0001 (0.1145)	Loss (EDL) 2.908 (2.961)
2023-05-20 21:00:17,816 | Epoch: [89][ 40/191]	Time   0.76 (  0.66)	Data 0.0001 (0.0867)	Loss (EDL) 2.877 (2.973)
2023-05-20 21:00:23,490 | Epoch: [89][ 50/191]	Time   0.59 (  0.64)	Data 0.0001 (0.0697)	Loss (EDL) 2.875 (2.964)
2023-05-20 21:00:29,095 | Epoch: [89][ 60/191]	Time   0.55 (  0.63)	Data 0.0002 (0.0583)	Loss (EDL) 2.890 (2.973)
2023-05-20 21:00:34,694 | Epoch: [89][ 70/191]	Time   0.57 (  0.62)	Data 0.0002 (0.0501)	Loss (EDL) 3.192 (2.976)
2023-05-20 21:00:40,307 | Epoch: [89][ 80/191]	Time   0.55 (  0.61)	Data 0.0002 (0.0440)	Loss (EDL) 2.994 (2.978)
2023-05-20 21:00:45,940 | Epoch: [89][ 90/191]	Time   0.58 (  0.61)	Data 0.0002 (0.0392)	Loss (EDL) 3.151 (2.979)
2023-05-20 21:00:51,486 | Epoch: [89][100/191]	Time   0.55 (  0.60)	Data 0.0002 (0.0353)	Loss (EDL) 2.927 (2.971)
2023-05-20 21:00:57,347 | Epoch: [89][110/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0322)	Loss (EDL) 2.922 (2.969)
2023-05-20 21:01:02,901 | Epoch: [89][120/191]	Time   0.56 (  0.60)	Data 0.0002 (0.0295)	Loss (EDL) 3.062 (2.966)
2023-05-20 21:01:08,462 | Epoch: [89][130/191]	Time   0.57 (  0.59)	Data 0.0001 (0.0273)	Loss (EDL) 2.682 (2.962)
2023-05-20 21:01:13,926 | Epoch: [89][140/191]	Time   0.54 (  0.59)	Data 0.0002 (0.0254)	Loss (EDL) 2.987 (2.961)
2023-05-20 21:01:19,417 | Epoch: [89][150/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0237)	Loss (EDL) 3.270 (2.963)
2023-05-20 21:01:24,898 | Epoch: [89][160/191]	Time   0.55 (  0.59)	Data 0.0001 (0.0222)	Loss (EDL) 2.871 (2.963)
2023-05-20 21:01:30,371 | Epoch: [89][170/191]	Time   0.53 (  0.58)	Data 0.0001 (0.0209)	Loss (EDL) 2.855 (2.965)
2023-05-20 21:01:35,846 | Epoch: [89][180/191]	Time   0.54 (  0.58)	Data 0.0001 (0.0198)	Loss (EDL) 2.902 (2.961)
2023-05-20 21:01:41,254 | Epoch: [89][190/191]	Time   0.46 (  0.58)	Data 0.0001 (0.0188)	Loss (EDL) 2.929 (2.967)
2023-05-20 21:01:41,573 | Create Epoch [89] features of all training data...
2023-05-20 21:02:11,091 | Updated smoothed statistics on Epoch [89]!
2023-05-20 21:02:11,161 | Updated running statistics with Epoch [89] features!
2023-05-20 21:02:14,997 | Val: [ 0/34]	Time  3.555 ( 3.555)	Loss (L1) 6.595 (6.595)	Loss (EDL) 4.385 (4.385)	Loss (NIG_NLL) 4.036 (4.036)	Loss (NIG_Reg) 34.963 (34.963)
2023-05-20 21:02:16,041 | Val: [10/34]	Time  0.101 ( 0.418)	Loss (L1) 7.398 (7.119)	Loss (EDL) 4.514 (4.467)	Loss (NIG_NLL) 4.122 (4.089)	Loss (NIG_Reg) 39.214 (37.739)
2023-05-20 21:02:17,050 | Val: [20/34]	Time  0.101 ( 0.267)	Loss (L1) 8.009 (6.997)	Loss (EDL) 4.811 (4.431)	Loss (NIG_NLL) 4.387 (4.060)	Loss (NIG_Reg) 42.454 (37.089)
2023-05-20 21:02:18,060 | Val: [30/34]	Time  0.101 ( 0.213)	Loss (L1) 8.169 (6.987)	Loss (EDL) 4.859 (4.432)	Loss (NIG_NLL) 4.426 (4.062)	Loss (NIG_Reg) 43.300 (37.036)
2023-05-20 21:02:18,726 |  * Overall: MSE 83.072	L1 6.951	G-Mean 4.325	EDL 4.419	NIG_NLL 4.050	NIG_Reg 36.849
2023-05-20 21:02:18,726 |  * Many: MSE 71.891	L1 6.448	G-Mean 3.997	EDL 4.272	NIG_NLL 3.930	NIG_Reg 34.182
2023-05-20 21:02:18,726 |  * Median: MSE 93.799	L1 7.544	G-Mean 4.762	EDL 4.603	NIG_NLL 4.203	NIG_Reg 39.987
2023-05-20 21:02:18,726 |  * Low: MSE 159.002	L1 10.064	G-Mean 6.972	EDL 5.298	NIG_NLL 4.764	NIG_Reg 53.360
2023-05-20 21:02:18,726 | Best EDL Loss: 6.899
2023-05-20 21:02:18,730 | Epoch #89: Train loss [2.9670]; Val loss: MSE [83.0720], L1 [6.9515], G-Mean [4.3249], EDL [4.4189], NIG_NLL [4.050], NIG_Reg [36.849]
2023-05-20 21:02:18,730 | ========================================================================================================================
2023-05-20 21:02:18,730 | Test best model on testset...
2023-05-20 21:02:20,568 | Loaded best model, epoch 68, best val loss 6.8987
2023-05-20 21:02:24,060 | Test: [ 0/34]	Time  3.491 ( 3.491)	Loss (L1) 7.504 (7.504)	Loss (EDL) 4.420 (4.420)	Loss (NIG_NLL) 4.022 (4.022)	Loss (NIG_Reg) 39.781 (39.781)
2023-05-20 21:02:25,132 | Test: [10/34]	Time  0.100 ( 0.415)	Loss (L1) 8.119 (7.083)	Loss (EDL) 4.509 (4.253)	Loss (NIG_NLL) 4.079 (3.877)	Loss (NIG_Reg) 43.048 (37.553)
2023-05-20 21:02:26,146 | Test: [20/34]	Time  0.104 ( 0.266)	Loss (L1) 7.089 (7.074)	Loss (EDL) 4.235 (4.250)	Loss (NIG_NLL) 3.859 (3.874)	Loss (NIG_Reg) 37.592 (37.505)
2023-05-20 21:02:27,149 | Test: [30/34]	Time  0.100 ( 0.212)	Loss (L1) 6.339 (7.071)	Loss (EDL) 4.073 (4.250)	Loss (NIG_NLL) 3.737 (3.875)	Loss (NIG_Reg) 33.608 (37.490)
2023-05-20 21:02:28,318 |  * Overall: MSE 86.862	L1 7.124	G-Mean 4.555	EDL 4.265	NIG_NLL 3.887	NIG_Reg 37.769	nllgau 4.786	AUSE 0.417
2023-05-20 21:02:28,318 |  * Many: MSE 76.577	L1 6.686	G-Mean 4.255	EDL 4.152	NIG_NLL 3.797	NIG_Reg 35.449	nllgau 4.580	AUSE 0.364
2023-05-20 21:02:28,318 |  * Median: MSE 99.945	L1 7.725	G-Mean 5.114	EDL 4.417	NIG_NLL 4.007	NIG_Reg 40.951	nllgau 5.119	AUSE 0.269
2023-05-20 21:02:28,318 |  * Low: MSE 147.818	L1 9.593	G-Mean 6.292	EDL 4.909	NIG_NLL 4.401	NIG_Reg 50.878	nllgau 5.813	AUSE 0.452
2023-05-20 21:02:28,319 | Test loss: MSE [86.8624], L1 [7.1237], G-Mean [4.5549], EDL [4.2646], NIG_NLL [3.887], NIG_Reg [37.769]
Done
